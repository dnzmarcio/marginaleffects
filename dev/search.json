[{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"emmeans","dir":"Articles","previous_headings":"","what":"emmeans","title":"Alternative Software","text":"emmeans package developed Russell V. Lenth colleagues. emmeans truly incredible piece software, trailblazer R ecosystem. extremely powerful package whose functionality overlaps marginaleffects significant degree: marginal means, contrasts, slopes. Even two packages can compute many quantities, emmeans marginaleffects pretty different philosophies respect user interface computation. emmeans analysis typically starts computing “marginal means” holding numeric covariates means, averaging across balanced grid categorical predictors. , users can use contrast() function estimate difference marginal means. marginaleffects package supplies marginal_means function can replicate emmeans analyses computing marginal means. However, typical analysis squarely centered predicted/fitted values. useful starting point , many cases, analysts find easy intuitive express scientific queries terms changes predicted values. example, average predicted probability survival differ treatment control group? difference predicted wage college high school graduates? Let’s say estimate linear regression model two continuous regressors multiplicative interaction: \\[y = \\beta_0 + \\beta_1 x + \\beta_2 z + \\beta_3 x \\cdot z + \\varepsilon\\] model, effect \\(x\\) \\(y\\) depend value covariate \\(z\\). Let’s say user wants estimate happens predicted value \\(y\\) \\(x\\) increases 1 unit, \\(z \\\\{-1, 0, 1\\}\\). , use comparisons() function. variables argument determines scientific query interest, newdata argument determines grid covariate values want evaluate query: vignettes show, marginaleffects can also compute contrasts marginal means. can also compute various quantities interest like raw fitted values, slopes (partial derivatives), contrasts marginal means. also offers flexible mechanism run (non-)linear hypothesis tests using delta method, offers fully customizable strategy compute quantities like odds ratios (completely arbitrary functions predicted outcome). Thus, (Vincent’s) biased opinion, main benefits marginaleffects emmeans : Support model types. Simpler, intuitive, highly consistent user interface. Easier compute average slopes unit-level contrasts whole datasets. Easier compute slopes (aka marginal effects, trends, partial derivatives) custom grids continuous regressors. Easier implement causal inference strategies like parametric g-formula regression adjustment experiments (see vignettes). Allows computation arbitrary quantities interest via user-supplied functions automatic delta method inference. Common plots easy plot_predictions(), plot_comparisons(), plot_slopes() functions. fair, many marginaleffects advantages listed come subjective preferences user interface. Readers thus encouraged try packages see interface prefer. AFAICT, main advantages emmeans marginaleffects : Omnibus tests. Multiplicity adjustments. Marginal means (slopes contrasts) often faster compute. Please let know find features emmeans can add list. Marginal Means Vignette includes side--side comparisons emmeans marginaleffects compute marginal means. rest section compares syntax contrasts marginaleffects.","code":"model <- lm(y ~ x * z, data)  comparisons(   model,   variables = list(x = 1), # what is the effect of 1-unit change in x?   newdata = datagrid(z = -1:1) # when z is held at values -1, 0, or 1 )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"contrasts","dir":"Articles","previous_headings":"emmeans","what":"Contrasts","title":"Alternative Software","text":"far can tell, emmeans provide easy way compute unit-level contrasts every row dataset used fit model. Therefore, side--side syntax shown always include newdata=datagrid() specify want compute one contrast: mean values regressors. day--day practice slopes(), however, extra argument necessary. Fit model: Link scale, pairwise contrasts: Response scale, reference groups:","code":"library(emmeans) library(marginaleffects)  mod <- glm(vs ~ hp + factor(cyl), data = mtcars, family = binomial) emm <- emmeans(mod, specs = \"cyl\") contrast(emm, method = \"revpairwise\", adjust = \"none\", df = Inf) #>  contrast    estimate      SE  df z.ratio p.value #>  cyl6 - cyl4   -0.905    1.63 Inf  -0.555  0.5789 #>  cyl8 - cyl4  -19.542 4367.17 Inf  -0.004  0.9964 #>  cyl8 - cyl6  -18.637 4367.16 Inf  -0.004  0.9966 #>  #> Degrees-of-freedom method: user-specified  #> Results are given on the log odds ratio (not the response) scale.  comparisons(mod,             type = \"link\",             newdata = \"mean\",             variables = list(cyl = \"pairwise\")) #>  #>  Term Contrast Estimate Std. Error        z Pr(>|z|)   S   2.5 %  97.5 % #>   cyl    6 - 4   -0.905       1.63 -0.55506    0.579 0.8    -4.1    2.29 #>   cyl    8 - 4  -19.542    4367.17 -0.00447    0.996 0.0 -8579.0 8539.95 #>   cyl    8 - 6  -18.637    4367.17 -0.00427    0.997 0.0 -8578.1 8540.85 #>  #> Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, vs, hp, cyl emm <- emmeans(mod, specs = \"cyl\", regrid = \"response\") contrast(emm, method = \"trt.vs.ctrl1\", adjust = \"none\", df = Inf, ratios = FALSE) #>  contrast    estimate    SE  df z.ratio p.value #>  cyl6 - cyl4   -0.222 0.394 Inf  -0.564  0.5727 #>  cyl8 - cyl4   -0.595 0.511 Inf  -1.163  0.2447 #>  #> Degrees-of-freedom method: user-specified  comparisons(mod, newdata = \"mean\") #>  #>  Term Contrast  Estimate Std. Error         z Pr(>|z|)   S     2.5 %   97.5 % #>   hp     +1    -1.56e-10   6.80e-07 -0.000229    1.000 0.0 -1.33e-06 1.33e-06 #>   cyl    6 - 4 -2.22e-01   3.94e-01 -0.564207    0.573 0.8 -9.94e-01 5.50e-01 #>   cyl    8 - 4 -5.95e-01   5.11e-01 -1.163438    0.245 2.0 -1.60e+00 4.07e-01 #>  #> Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, vs, hp, cyl"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"contrasts-by-group","dir":"Articles","previous_headings":"emmeans","what":"Contrasts by group","title":"Alternative Software","text":"slightly complicated example contrasts estimated subgroup lme4 mixed effects model. First estimate model compute pairwise contrasts subgroup using emmeans: emmeans obtain results? Roughly speaking: Create prediction grid one cell combination categorical predictors model, numeric variables held means. Make adjusted predictions cell prediction grid. Take average predictions (marginal means) combination btype (focal variable) resp (group variable). Compute pairwise differences (contrasts) marginal means across different levels focal variable btype. short, emmeans computes pairwise contrasts marginal means, averages adjusted predictions. different default types contrasts produced comparisons(), reports contrasts adjusted predictions, without averaging across pre-specified grid predictors. comparisons() instead? Let newdata data frame supplied user (original data frame used fit model), : Create new data frame called newdata2, identical newdata except focal variable incremented one level. predict(model, newdata = newdata2) - predict(model, newdata = newdata) Although idiomatic, can use still use comparisons() emulate emmeans results. First, create prediction grid one cell combination categorical predictor model: grid 18 rows, one combination levels resp (3), situ (2), btype (3) variables (3 * 2 * 3 = 18). compute pairwise contrasts grid: 3 pairwise contrasts, corresponding 3 pairwise comparisons possible 3 levels focal variable btype: scold-curse, shout-scold, shout-curse. comparisons() function estimates 3 contrasts row newdata, get \\(18 \\times 3 = 54\\) rows. Finally, wanted contrasts averaged subgroup resp variable, can use avg_comparisons() function argument: results identical produced emmeans (except \\(t\\) vs. \\(z\\)).","code":"library(dplyr) library(lme4) library(emmeans)  dat <- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/lme4/VerbAgg.csv\") dat$woman <- as.numeric(dat$Gender == \"F\")  mod <- glmer(     woman ~ btype * resp + situ + (1 + Anger | item),     family = binomial,     data = dat)  emmeans(mod, specs = \"btype\", by = \"resp\") |>     contrast(method = \"revpairwise\", adjust = \"none\") #> resp = no: #>  contrast      estimate     SE  df z.ratio p.value #>  scold - curse  -0.0152 0.1097 Inf  -0.139  0.8898 #>  shout - curse  -0.2533 0.1022 Inf  -2.478  0.0132 #>  shout - scold  -0.2381 0.0886 Inf  -2.686  0.0072 #>  #> resp = perhaps: #>  contrast      estimate     SE  df z.ratio p.value #>  scold - curse  -0.2393 0.1178 Inf  -2.031  0.0422 #>  shout - curse  -0.0834 0.1330 Inf  -0.627  0.5309 #>  shout - scold   0.1559 0.1358 Inf   1.148  0.2510 #>  #> resp = yes: #>  contrast      estimate     SE  df z.ratio p.value #>  scold - curse   0.0391 0.1292 Inf   0.302  0.7624 #>  shout - curse   0.5802 0.1784 Inf   3.252  0.0011 #>  shout - scold   0.5411 0.1888 Inf   2.866  0.0042 #>  #> Results are averaged over the levels of: situ  #> Results are given on the log odds ratio (not the response) scale. nd <- datagrid(     model = mod,     resp = dat$resp,     situ = dat$situ,     btype = dat$btype) nrow(nd) #> [1] 18 cmp <- comparisons(mod,     variables = list(\"btype\" = \"pairwise\"),     newdata = nd,     type = \"link\") nrow(cmp) #> [1] 54 avg_comparisons(mod,     by = \"resp\",     variables = list(\"btype\" = \"pairwise\"),     newdata = nd,     type = \"link\") #>  #>   Term                  Contrast    resp Estimate Std. Error      z Pr(>|z|)   S  2.5 %   97.5 % #>  btype mean(scold) - mean(curse) no       -0.0152     0.1097 -0.139  0.88977 0.2 -0.230  0.19975 #>  btype mean(scold) - mean(curse) perhaps  -0.2393     0.1178 -2.031  0.04222 4.6 -0.470 -0.00841 #>  btype mean(scold) - mean(curse) yes       0.0391     0.1292  0.302  0.76239 0.4 -0.214  0.29235 #>  btype mean(shout) - mean(curse) no       -0.2533     0.1022 -2.478  0.01320 6.2 -0.454 -0.05297 #>  btype mean(shout) - mean(curse) perhaps  -0.0834     0.1330 -0.627  0.53092 0.9 -0.344  0.17738 #>  btype mean(shout) - mean(curse) yes       0.5802     0.1784  3.252  0.00115 9.8  0.230  0.92987 #>  btype mean(shout) - mean(scold) no       -0.2381     0.0886 -2.686  0.00723 7.1 -0.412 -0.06435 #>  btype mean(shout) - mean(scold) perhaps   0.1559     0.1358  1.148  0.25103 2.0 -0.110  0.42215 #>  btype mean(shout) - mean(scold) yes       0.5411     0.1888  2.866  0.00416 7.9  0.171  0.91116 #>  #> Columns: term, contrast, resp, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"marginal-effects","dir":"Articles","previous_headings":"emmeans","what":"Marginal Effects","title":"Alternative Software","text":"far can tell, emmeans::emtrends makes easier compute marginal effects user-specified values large grids full original dataset. Response scale, user-specified values: Link scale, user-specified values:","code":"mod <- glm(vs ~ hp + factor(cyl), data = mtcars, family = binomial)  emtrends(mod, ~hp, \"hp\", regrid = \"response\", at = list(cyl = 4)) #>   hp hp.trend    SE  df asymp.LCL asymp.UCL #>  147 -0.00786 0.011 Inf   -0.0294    0.0137 #>  #> Confidence level used: 0.95  slopes(mod, newdata = datagrid(cyl = 4)) #>  #>  Term Contrast Estimate Std. Error      z Pr(>|z|)   S   2.5 % 97.5 %  hp cyl #>   hp     dY/dX -0.00785      0.011 -0.713    0.476 1.1 -0.0294 0.0137 147   4 #>   cyl    6 - 4 -0.22219      0.394 -0.564    0.573 0.8 -0.9940 0.5496 147   4 #>   cyl    8 - 4 -0.59469      0.511 -1.163    0.245 2.0 -1.5965 0.4071 147   4 #>  #> Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, vs, hp, cyl emtrends(mod, ~hp, \"hp\", at = list(cyl = 4)) #>   hp hp.trend     SE  df asymp.LCL asymp.UCL #>  147  -0.0326 0.0339 Inf    -0.099    0.0338 #>  #> Confidence level used: 0.95  slopes(mod, type = \"link\", newdata = datagrid(cyl = 4)) #>  #>  Term Contrast Estimate Std. Error        z Pr(>|z|)   S     2.5 %   97.5 %  hp cyl #>   hp     dY/dX  -0.0326   3.39e-02 -0.96144    0.336 1.6    -0.099 3.38e-02 147   4 #>   cyl    6 - 4  -0.9049   1.63e+00 -0.55506    0.579 0.8    -4.100 2.29e+00 147   4 #>   cyl    8 - 4 -19.5418   4.37e+03 -0.00447    0.996 0.0 -8579.030 8.54e+03 147   4 #>  #> Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, vs, hp, cyl"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"more-examples","dir":"Articles","previous_headings":"emmeans","what":"More examples","title":"Alternative Software","text":"emmeans vs. marginaleffects comparisons:","code":"# Example of examining a continuous x categorical interaction using emmeans and marginaleffects # Authors: Cameron Patrick and Vincent Arel-Bundock  library(tidyverse) library(emmeans) library(marginaleffects)  # use the mtcars data, set up am as a factor data(mtcars) mc <- mtcars |> mutate(am = factor(am))  # fit a linear model to mpg with wt x am interaction m <- lm(mpg ~ wt*am, data = mc) summary(m)  # 1. means for each level of am at mean wt. emmeans(m, \"am\") marginal_means(m, variables = \"am\") predictions(m, newdata = datagrid(am = 0:1))  # 2. means for each level of am at wt = 2.5, 3, 3.5. emmeans(m, c(\"am\", \"wt\"), at = list(wt = c(2.5, 3, 3.5))) predictions(m, newdata = datagrid(am = 0:1, wt = c(2.5, 3, 3.5))  # 3. means for wt = 2.5, 3, 3.5, averaged over levels of am (implicitly!). emmeans(m, \"wt\", at = list(wt = c(2.5, 3, 3.5)))  # same thing, but the averaging is more explicit, using the `by` argument predictions(   m,   newdata = datagrid(am = 0:1, wt = c(2.5, 3, 3.5)),   by = \"wt\")  # 4. graphical version of 2. emmip(m, am ~ wt, at = list(wt = c(2.5, 3, 3.5)), CIs = TRUE) plot_predictions(m, condition = c(\"wt\", \"am\"))  # 5. compare levels of am at specific values of wt. # this is a bit ugly because the emmeans defaults for pairs() are silly. # infer = TRUE: enable confidence intervals. # adjust = \"none\": begone, Tukey. # reverse = TRUE: contrasts as (later level) - (earlier level) pairs(emmeans(m, \"am\", by = \"wt\", at = list(wt = c(2.5, 3, 3.5))),       infer = TRUE, adjust = \"none\", reverse = TRUE)  comparisons(   m,   variables = \"am\",   newdata = datagrid(wt = c(2.5, 3, 3.5)))  # 6. plot of pairswise comparisons plot(pairs(emmeans(m, \"am\", by = \"wt\", at = list(wt = c(2.5, 3, 3.5))),       infer = TRUE, adjust = \"none\", reverse = TRUE))  # Since `wt` is numeric, the default is to plot it as a continuous variable on # the x-axis.  But not that this is the **exact same info** as in the emmeans plot. plot_comparisons(m, variables = \"am\", condition = \"wt\")  # You of course customize everything, set draw=FALSE, and feed the raw data to feed to ggplot2 p <- plot_comparisons(   m,   variables = \"am\",   condition = list(wt = c(2.5, 3, 3.5)),   draw = FALSE)  ggplot(p, aes(y = wt, x = comparison, xmin = conf.low, xmax = conf.high)) +   geom_pointrange()  # 7. slope of wt for each level of am emtrends(m, \"am\", \"wt\") slopes(m, newdata = datagrid(am = 0:1))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"margins-and-prediction","dir":"Articles","previous_headings":"","what":"margins and prediction","title":"Alternative Software","text":"margins prediction packages R designed Thomas Leeper emulate behavior margins command Stata. packages trailblazers strongly influenced development marginaleffects. main benefits marginaleffects packages : Support model types Faster Memory efficient Plots using ggplot2 instead Base R extensive test suite Active development syntax two packages similar.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"average-marginal-effects","dir":"Articles","previous_headings":"margins and prediction","what":"Average Marginal Effects","title":"Alternative Software","text":"","code":"library(margins) library(marginaleffects)  mod <- lm(mpg ~ cyl + hp + wt, data = mtcars)  mar <- margins(mod) summary(mar) #>  factor     AME     SE       z      p   lower   upper #>     cyl -0.9416 0.5509 -1.7092 0.0874 -2.0214  0.1382 #>      hp -0.0180 0.0119 -1.5188 0.1288 -0.0413  0.0052 #>      wt -3.1670 0.7406 -4.2764 0.0000 -4.6185 -1.7155  mfx <- slopes(mod)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"individual-level-marginal-effects","dir":"Articles","previous_headings":"margins and prediction","what":"Individual-Level Marginal Effects","title":"Alternative Software","text":"Marginal effects user-specified data frame:","code":"head(data.frame(mar)) #>    mpg cyl disp  hp drat    wt  qsec vs am gear carb   fitted se.fitted   dydx_cyl    dydx_hp   dydx_wt Var_dydx_cyl  Var_dydx_hp Var_dydx_wt X_weights X_at_number #> 1 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4 22.82043 0.6876212 -0.9416168 -0.0180381 -3.166973    0.3035123 0.0001410453   0.5484517        NA           1 #> 2 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4 22.01285 0.6056817 -0.9416168 -0.0180381 -3.166973    0.3035123 0.0001410453   0.5484517        NA           1 #> 3 22.8   4  108  93 3.85 2.320 18.61  1  1    4    1 25.96040 0.7349593 -0.9416168 -0.0180381 -3.166973    0.3035123 0.0001410453   0.5484517        NA           1 #> 4 21.4   6  258 110 3.08 3.215 19.44  1  0    3    1 20.93608 0.5800910 -0.9416168 -0.0180381 -3.166973    0.3035123 0.0001410453   0.5484517        NA           1 #> 5 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2 17.16780 0.8322986 -0.9416168 -0.0180381 -3.166973    0.3035123 0.0001410453   0.5484517        NA           1 #> 6 18.1   6  225 105 2.76 3.460 20.22  1  0    3    1 20.25036 0.6638322 -0.9416168 -0.0180381 -3.166973    0.3035123 0.0001410453   0.5484517        NA           1  head(mfx) #>  #>  Term Estimate Std. Error     z Pr(>|z|)   S 2.5 % 97.5 % #>   cyl   -0.942      0.551 -1.71   0.0874 3.5 -2.02  0.138 #>   cyl   -0.942      0.551 -1.71   0.0874 3.5 -2.02  0.138 #>   cyl   -0.942      0.551 -1.71   0.0874 3.5 -2.02  0.138 #>   cyl   -0.942      0.551 -1.71   0.0874 3.5 -2.02  0.138 #>   cyl   -0.942      0.551 -1.71   0.0874 3.5 -2.02  0.138 #>   cyl   -0.942      0.551 -1.71   0.0874 3.5 -2.02  0.138 #>  #> Columns: rowid, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, mpg, cyl, hp, wt nd <- data.frame(cyl = 4, hp = 110, wt = 3)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"marginal-effects-at-the-mean","dir":"Articles","previous_headings":"margins and prediction","what":"Marginal Effects at the Mean","title":"Alternative Software","text":"","code":"mar <- margins(mod, data = data.frame(prediction::mean_or_mode(mtcars)), unit_ses = TRUE) data.frame(mar) #>        mpg    cyl     disp       hp     drat      wt     qsec     vs      am   gear   carb   fitted se.fitted   dydx_cyl    dydx_hp   dydx_wt Var_dydx_cyl  Var_dydx_hp Var_dydx_wt SE_dydx_cyl SE_dydx_hp SE_dydx_wt X_weights X_at_number #> 1 20.09062 6.1875 230.7219 146.6875 3.596563 3.21725 17.84875 0.4375 0.40625 3.6875 2.8125 20.09062 0.4439832 -0.9416168 -0.0180381 -3.166973    0.3035082 0.0001410452   0.5484409   0.5509157 0.01187625  0.7405679        NA           1  slopes(mod, newdata = \"mean\") #>  #>  Term Estimate Std. Error     z Pr(>|z|)    S   2.5 %   97.5 % #>   cyl   -0.942     0.5509 -1.71   0.0874  3.5 -2.0214  0.13815 #>   hp    -0.018     0.0119 -1.52   0.1288  3.0 -0.0413  0.00524 #>   wt    -3.167     0.7406 -4.28   <0.001 15.7 -4.6185 -1.71546 #>  #> Columns: rowid, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, mpg, cyl, hp, wt"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"counterfactual-average-marginal-effects","dir":"Articles","previous_headings":"margins and prediction","what":"Counterfactual Average Marginal Effects","title":"Alternative Software","text":"argument margins package emulates Stata fixing values variables user-specified values, replicating full dataset several times combination supplied values (see Stata section ). example, dataset includes 32 rows user calls =list(cyl=c(4, 6)), margins compute 64 unit-level marginal effects estimates:","code":"dat <- mtcars dat$cyl <- factor(dat$cyl) mod <- lm(mpg ~ cyl * hp + wt, data = mtcars)  mar <- margins(mod, at = list(cyl = c(4, 6, 8))) summary(mar) #>  factor    cyl     AME     SE       z      p   lower   upper #>     cyl 4.0000  0.0381 0.5998  0.0636 0.9493 -1.1374  1.2137 #>     cyl 6.0000  0.0381 0.5999  0.0636 0.9493 -1.1376  1.2139 #>     cyl 8.0000  0.0381 0.5999  0.0636 0.9493 -1.1376  1.2139 #>      hp 4.0000 -0.0878 0.0267 -3.2937 0.0010 -0.1400 -0.0355 #>      hp 6.0000 -0.0499 0.0154 -3.2397 0.0012 -0.0800 -0.0197 #>      hp 8.0000 -0.0120 0.0108 -1.1065 0.2685 -0.0332  0.0092 #>      wt 4.0000 -3.1198 0.6613 -4.7175 0.0000 -4.4160 -1.8236 #>      wt 6.0000 -3.1198 0.6613 -4.7176 0.0000 -4.4160 -1.8236 #>      wt 8.0000 -3.1198 0.6613 -4.7175 0.0000 -4.4160 -1.8236  avg_slopes(     mod,     by = \"cyl\",     newdata = datagridcf(cyl = c(4, 6, 8))) #>  #>  Term    Contrast cyl Estimate Std. Error       z Pr(>|z|)    S   2.5 %   97.5 % #>   cyl mean(dY/dX)   4   0.0381     0.5999  0.0636   0.9493  0.1 -1.1376  1.21390 #>   cyl mean(dY/dX)   6   0.0381     0.5999  0.0636   0.9493  0.1 -1.1376  1.21390 #>   cyl mean(dY/dX)   8   0.0381     0.5999  0.0636   0.9493  0.1 -1.1376  1.21390 #>   hp  mean(dY/dX)   4  -0.0878     0.0267 -3.2937   <0.001 10.0 -0.1400 -0.03554 #>   hp  mean(dY/dX)   6  -0.0499     0.0154 -3.2397   0.0012  9.7 -0.0800 -0.01970 #>   hp  mean(dY/dX)   8  -0.0120     0.0108 -1.1065   0.2685  1.9 -0.0332  0.00923 #>   wt  mean(dY/dX)   4  -3.1198     0.6613 -4.7175   <0.001 18.7 -4.4160 -1.82365 #>   wt  mean(dY/dX)   6  -3.1198     0.6613 -4.7175   <0.001 18.7 -4.4160 -1.82365 #>   wt  mean(dY/dX)   8  -3.1198     0.6613 -4.7175   <0.001 18.7 -4.4160 -1.82365 #>  #> Columns: term, contrast, cyl, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"adjusted-predictions","dir":"Articles","previous_headings":"margins and prediction","what":"Adjusted Predictions","title":"Alternative Software","text":"syntax compute adjusted predictions using predictions package marginaleffects similar:","code":"prediction::prediction(mod) |> head() #>    mpg cyl disp  hp drat    wt  qsec vs am gear carb   fitted se.fitted #> 1 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4 21.90488 0.6927034 #> 2 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4 21.10933 0.6266557 #> 3 22.8   4  108  93 3.85 2.320 18.61  1  1    4    1 25.64753 0.6652076 #> 4 21.4   6  258 110 3.08 3.215 19.44  1  0    3    1 20.04859 0.6041400 #> 5 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2 17.25445 0.7436172 #> 6 18.1   6  225 105 2.76 3.460 20.22  1  0    3    1 19.53360 0.6436862  marginaleffects::predictions(mod) |> head() #>  #>  Estimate Std. Error    z Pr(>|z|)     S 2.5 % 97.5 % #>      21.9      0.693 31.6   <0.001 726.6  20.5   23.3 #>      21.1      0.627 33.7   <0.001 823.9  19.9   22.3 #>      25.6      0.665 38.6   <0.001   Inf  24.3   27.0 #>      20.0      0.604 33.2   <0.001 799.8  18.9   21.2 #>      17.3      0.744 23.2   <0.001 393.2  15.8   18.7 #>      19.5      0.644 30.3   <0.001 669.5  18.3   20.8 #>  #> Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, mpg, cyl, hp, wt"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"stata","dir":"Articles","previous_headings":"","what":"Stata","title":"Alternative Software","text":"Stata good expensive software package statistical analysis. published StataCorp LLC. section compares Stata’s margins command marginaleffects. results produced marginaleffects extensively tested Stata. See test suite list dozens models compared estimates standard errors.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"average-marginal-effect-ames","dir":"Articles","previous_headings":"Stata","what":"Average Marginal Effect (AMEs)","title":"Alternative Software","text":"Marginal effects unit-level quantities. compute “average marginal effects”, first calculate marginal effects observation dataset. , take mean unit-level marginal effects.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"stata-1","dir":"Articles","previous_headings":"Stata > Average Marginal Effect (AMEs)","what":"Stata","title":"Alternative Software","text":"Stata’s margins command slopes function can calculate average marginal effects (AMEs). example showing estimate AMEs Stata:","code":"quietly reg mpg cyl hp wt margins, dydx(*)  Average marginal effects                        Number of obs     =         32 Model VCE    : OLS   Expression   : Linear prediction, predict() dy/dx w.r.t. : cyl hp wt   ------------------------------------------------------------------------------     |            Delta-method     |      dy/dx   Std. Err.      t    P>|t|     [95% Conf. Interval] ------------------------------------------------------------------------------ cyl |  -.9416168   .5509164    -1.71   0.098    -2.070118    .1868842  hp |  -.0180381   .0118762    -1.52   0.140    -.0423655    .0062893  wt |  -3.166973   .7405759    -4.28   0.000    -4.683974   -1.649972 ------------------------------------------------------------------------------"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"marginaleffects","dir":"Articles","previous_headings":"Stata > Average Marginal Effect (AMEs)","what":"marginaleffects","title":"Alternative Software","text":"results can obtained slopes() summary() like : Note Stata reports t statistics marginaleffects reports Z. produces slightly different p-values model low degrees freedom: mtcars 32 rows","code":"library(\"marginaleffects\") mod <- lm(mpg ~ cyl + hp + wt, data = mtcars) avg_slopes(mod) #>  #>  Term Estimate Std. Error     z Pr(>|z|)    S   2.5 %   97.5 % #>   cyl   -0.942     0.5509 -1.71   0.0874  3.5 -2.0214  0.13816 #>   hp    -0.018     0.0119 -1.52   0.1288  3.0 -0.0413  0.00524 #>   wt    -3.167     0.7406 -4.28   <0.001 15.7 -4.6185 -1.71547 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"counterfactual-marginal-effects","dir":"Articles","previous_headings":"Stata","what":"Counterfactual Marginal Effects","title":"Alternative Software","text":"“counterfactual marginal effect” special quantity obtained replicating dataset fixing regressor user-defined values. Concretely, Stata computes counterfactual marginal effects 3 steps: Duplicate whole dataset 3 times sets values cyl three specified values subsets. Calculate marginal effects observation large grid. Take average marginal effects value variable interest.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"stata-2","dir":"Articles","previous_headings":"Stata > Counterfactual Marginal Effects","what":"Stata","title":"Alternative Software","text":"argument, Stata’s margins command estimates average counterfactual marginal effects. example:","code":"quietly reg mpg i.cyl##c.hp wt margins, dydx(hp) at(cyl = (4 6 8))  Average marginal effects                        Number of obs     =         32 Model VCE    : OLS  Expression   : Linear prediction, predict() dy/dx w.r.t. : hp  1._at        : cyl             =           4  2._at        : cyl             =           6  3._at        : cyl             =           8  ------------------------------------------------------------------------------              |            Delta-method              |      dy/dx   Std. Err.      t    P>|t|     [95% Conf. Interval] -------------+---------------------------------------------------------------- hp           |          _at |           1  |   -.099466   .0348665    -2.85   0.009    -.1712749   -.0276571           2  |  -.0213768    .038822    -0.55   0.587    -.1013323    .0585787           3  |   -.013441   .0125138    -1.07   0.293    -.0392137    .0123317 ------------------------------------------------------------------------------"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"marginaleffects-1","dir":"Articles","previous_headings":"Stata > Counterfactual Marginal Effects","what":"marginaleffects","title":"Alternative Software","text":"can estimate average counterfactual marginal effects slopes() using datagridcf() create counterfactual dataset full original dataset replicated potential value cyl variable. , tell argument average within groups: equivalent taking group-wise mean observation-level marginal effects (without argument): Note following Stata, standard errors group-averaged marginal effects computed taking “Jacobian mean:”","code":"mod <- lm(mpg ~ as.factor(cyl) * hp + wt, data = mtcars)  avg_slopes(     mod,     variables = \"hp\",     by = \"cyl\",     newdata = datagridcf(cyl = c(4, 6, 8))) #>  #>  Term    Contrast cyl Estimate Std. Error      z Pr(>|z|)   S   2.5 %  97.5 % #>    hp mean(dY/dX)   4  -0.0995     0.0349 -2.853  0.00433 7.9 -0.1678 -0.0311 #>    hp mean(dY/dX)   6  -0.0214     0.0388 -0.551  0.58188 0.8 -0.0975  0.0547 #>    hp mean(dY/dX)   8  -0.0134     0.0125 -1.074  0.28278 1.8 -0.0380  0.0111 #>  #> Columns: term, contrast, cyl, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo mfx <- slopes(     mod,     variables = \"hp\",     newdata = datagridcf(cyl = c(4, 6, 8))) aggregate(estimate ~ term + cyl, data = mfx, FUN = mean) #>   term cyl    estimate #> 1   hp   4 -0.09946598 #> 2   hp   6 -0.02137679 #> 3   hp   8 -0.01344103 J <- attr(mfx, \"jacobian\") J_mean <- aggregate(J, by = list(mfx$cyl), FUN = mean) J_mean <- as.matrix(J_mean[, 2:ncol(J_mean)]) sqrt(diag(J_mean %*% vcov(mod) %*% t(J_mean))) #> [1] 0.03486650 0.03882204 0.01251382"},{"path":[]},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"stata-3","dir":"Articles","previous_headings":"Stata > Average Counterfactual Adjusted Predictions","what":"Stata","title":"Alternative Software","text":"Just like Stata’s margins command computes average counterfactual marginal effects, can also estimate average counterfactual adjusted predictions. example: , Stata background: duplicates whole dataset 3 times sets values cyl three specified values subsets. calculates predictions large grid. takes average prediction value cyl. words, average counterfactual adjusted predictions implemented Stata hybrid predictions observed values (default marginaleffects::predictions) predictions representative values.","code":"quietly reg mpg i.cyl##c.hp wt margins, at(cyl = (4 6 8))  Predictive margins                              Number of obs     =         32 Model VCE    : OLS  Expression   : Linear prediction, predict()  1._at        : cyl             =           4  2._at        : cyl             =           6  3._at        : cyl             =           8  ------------------------------------------------------------------------------              |            Delta-method              |     Margin   Std. Err.      t    P>|t|     [95% Conf. Interval] -------------+----------------------------------------------------------------          _at |           1  |   17.44233   2.372914     7.35   0.000     12.55522    22.32944           2  |    18.9149   1.291483    14.65   0.000     16.25505    21.57476           3  |   18.33318   1.123874    16.31   0.000     16.01852    20.64785 ------------------------------------------------------------------------------"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"marginaleffects-2","dir":"Articles","previous_headings":"Stata > Average Counterfactual Adjusted Predictions","what":"marginaleffects","title":"Alternative Software","text":"can estimate average counterfactual adjusted predictions predictions() , first, setting grid_type argument datagrid() \"counterfactual\" , second, averaging predictions using argument summary(), manual function like dplyr::summarise().","code":"mod <- lm(mpg ~ as.factor(cyl) * hp + wt, data = mtcars)  predictions(     mod,     by = \"cyl\",     newdata = datagridcf(cyl = c(4, 6, 8))) #>  #>  cyl Estimate Std. Error     z Pr(>|z|)     S 2.5 % 97.5 % #>    4     17.4       2.37  7.35   <0.001  42.2  12.8   22.1 #>    6     18.9       1.29 14.65   <0.001 158.9  16.4   21.4 #>    8     18.3       1.12 16.31   <0.001 196.3  16.1   20.5 #>  #> Columns: cyl, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  predictions(     mod,     newdata = datagridcf(cyl = c(4, 6, 8))) |>     group_by(cyl) |>     summarize(AAP = mean(estimate)) #> # A tibble: 3 × 2 #>   cyl     AAP #>   <fct> <dbl> #> 1 4      17.4 #> 2 6      18.9 #> 3 8      18.3"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"brmsmargins","dir":"Articles","previous_headings":"","what":"brmsmargins","title":"Alternative Software","text":"brmsmargins package developed Joshua Wiley: package functions calculate marginal effects brms models ( http://paul-buerkner.github.io/brms/ ). central motivator calculate average marginal effects (AMEs) continuous discrete predictors fixed effects mixed effects regression models including location scale models. main advantage brmsmargins marginaleffects ability compute “Marginal Coefficients” following method described Hedeker et al (2012). main advantages marginaleffects brmsmargins : Support 60+ model types, rather just brms package. Simpler user interface (subjective). time writing (2022-05-25) brmsmargins support certain brms models multivariate multinomial outcomes. also support custom outcome transformations. rest section presents side--side replications analyses brmsmargins vignettes order show highlight parallels differences syntax.","code":""},{"path":[]},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"ames-for-logistic-regression","dir":"Articles","previous_headings":"brmsmargins > Marginal Effects for Fixed Effects Models","what":"AMEs for Logistic Regression","title":"Alternative Software","text":"Estimate logistic regression model brms: Compute AMEs manually: Compute AMEs brmsmargins: Compute AMEs using marginaleffects: mpg element Effect column marginaleffects matches M column output brmsmargins.","code":"library(brms) library(brmsmargins) library(marginaleffects) library(data.table) library(withr) h <- 1e-4  void <- capture.output(     bayes.logistic <- brm(       vs ~ am + mpg, data = mtcars,       family = \"bernoulli\", seed = 1234,       silent = 2, refresh = 0,       chains = 4L, cores = 4L) ) d1 <- d2 <- mtcars d2$mpg <- d2$mpg + h p1 <- posterior_epred(bayes.logistic, newdata = d1) p2 <- posterior_epred(bayes.logistic, newdata = d2) m <- (p2 - p1) / h quantile(rowMeans(m), c(.5, .025, .975)) #>        50%       2.5%      97.5%  #> 0.07001767 0.05469002 0.09241120 bm <- brmsmargins(   bayes.logistic,   add = data.frame(mpg = c(0, 0 + h)),   contrasts = cbind(\"AME MPG\" = c(-1 / h, 1 / h)),   CI = 0.95,   CIType = \"ETI\") data.frame(bm$ContrastSummary) #>            M        Mdn         LL        UL PercentROPE PercentMID   CI CIType ROPE  MID   Label #> 1 0.07110289 0.07001767 0.05469002 0.0924112          NA         NA 0.95    ETI <NA> <NA> AME MPG avg_slopes(bayes.logistic)  #>  #>  Term Contrast Estimate   2.5 %  97.5 % #>   am     1 - 0   -0.267 -0.4188 -0.0763 #>   mpg    dY/dX    0.070  0.0547  0.0924 #>  #> Columns: term, contrast, estimate, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"marginal-effects-for-mixed-effects-models","dir":"Articles","previous_headings":"brmsmargins","what":"Marginal Effects for Mixed Effects Models","title":"Alternative Software","text":"Estimate mixed effects logistic regression model brms:","code":"d <- withr::with_seed(   seed = 12345, code = {     nGroups <- 100     nObs <- 20     theta.location <- matrix(rnorm(nGroups * 2), nrow = nGroups, ncol = 2)     theta.location[, 1] <- theta.location[, 1] - mean(theta.location[, 1])     theta.location[, 2] <- theta.location[, 2] - mean(theta.location[, 2])     theta.location[, 1] <- theta.location[, 1] / sd(theta.location[, 1])     theta.location[, 2] <- theta.location[, 2] / sd(theta.location[, 2])     theta.location <- theta.location %*% chol(matrix(c(1.5, -.25, -.25, .5^2), 2))     theta.location[, 1] <- theta.location[, 1] - 2.5     theta.location[, 2] <- theta.location[, 2] + 1     d <- data.table(       x = rep(rep(0:1, each = nObs / 2), times = nGroups))     d[, ID := rep(seq_len(nGroups), each = nObs)]      for (i in seq_len(nGroups)) {       d[ID == i, y := rbinom(         n = nObs,         size = 1,         prob = plogis(theta.location[i, 1] + theta.location[i, 2] * x))         ]     }     copy(d)   })  void <- capture.output(     mlogit <- brms::brm(       y ~ 1 + x + (1 + x | ID), family = \"bernoulli\",       data = d, seed = 1234,       silent = 2, refresh = 0,       chains = 4L, cores = 4L) ) #> Warning: There were 9 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"ame-including-random-effects","dir":"Articles","previous_headings":"brmsmargins > Marginal Effects for Mixed Effects Models","what":"AME: Including Random Effects","title":"Alternative Software","text":"","code":"bm <- brmsmargins(   mlogit,   add = data.frame(x = c(0, h)),   contrasts = cbind(\"AME x\" = c(-1 / h, 1 / h)),   effects = \"includeRE\",   CI = .95,   CIType = \"ETI\") data.frame(bm$ContrastSummary) #>           M       Mdn         LL        UL PercentROPE PercentMID   CI CIType ROPE  MID Label #> 1 0.1118585 0.1117003 0.08167159 0.1434978          NA         NA 0.95    ETI <NA> <NA> AME x  avg_slopes(mlogit) #>  #>  Term Contrast Estimate  2.5 % 97.5 % #>     x    1 - 0    0.111 0.0818  0.142 #>  #> Columns: term, contrast, estimate, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"ame-fixed-effects-only-grand-mean","dir":"Articles","previous_headings":"brmsmargins > Marginal Effects for Mixed Effects Models","what":"AME: Fixed Effects Only (Grand Mean)","title":"Alternative Software","text":"","code":"bm <- brmsmargins(   mlogit,   add = data.frame(x = c(0, h)),   contrasts = cbind(\"AME x\" = c(-1 / h, 1 / h)),   effects = \"fixedonly\",   CI = .95,   CIType = \"ETI\") data.frame(bm$ContrastSummary) #>           M       Mdn         LL        UL PercentROPE PercentMID   CI CIType ROPE  MID Label #> 1 0.1035957 0.1027827 0.06455371 0.1478527          NA         NA 0.95    ETI <NA> <NA> AME x  avg_slopes(mlogit, re_formula = NA) #>  #>  Term Contrast Estimate  2.5 % 97.5 % #>     x    1 - 0      0.1 0.0636  0.142 #>  #> Columns: term, contrast, estimate, conf.low, conf.high"},{"path":[]},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"ames-for-fixed-effects-location-scale-models","dir":"Articles","previous_headings":"brmsmargins > Marginal Effects for Location Scale Models","what":"AMEs for Fixed Effects Location Scale Models","title":"Alternative Software","text":"Estimate fixed effects location scale model brms:","code":"d <- withr::with_seed(   seed = 12345, code = {     nObs <- 1000L     d <- data.table(       grp = rep(0:1, each = nObs / 2L),       x = rnorm(nObs, mean = 0, sd = 0.25))     d[, y := rnorm(nObs,                    mean = x + grp,                    sd = exp(1 + x + grp))]     copy(d)   })  void <- capture.output(     ls.fe <- brm(bf(       y ~ 1 + x + grp,       sigma ~ 1 + x + grp),       family = \"gaussian\",       data = d, seed = 1234,       silent = 2, refresh = 0,       chains = 4L, cores = 4L) )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"fixed-effects-only","dir":"Articles","previous_headings":"brmsmargins > Marginal Effects for Location Scale Models","what":"Fixed effects only","title":"Alternative Software","text":"","code":"bm <- brmsmargins(   ls.fe,   add = data.frame(x = c(0, h)),   contrasts = cbind(\"AME x\" = c(-1 / h, 1 / h)),   CI = 0.95, CIType = \"ETI\",   effects = \"fixedonly\") data.frame(bm$ContrastSummary) #>          M      Mdn        LL       UL PercentROPE PercentMID   CI CIType ROPE  MID Label #> 1 1.616692 1.616495 0.7227972 2.466072          NA         NA 0.95    ETI <NA> <NA> AME x  avg_slopes(ls.fe, re_formula = NA) #>  #>  Term Contrast Estimate 2.5 % 97.5 % #>   grp    1 - 0     1.02 0.342   1.69 #>   x      dY/dX     1.62 0.723   2.47 #>  #> Columns: term, contrast, estimate, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"discrete-change-and-distributional-parameter-dpar","dir":"Articles","previous_headings":"brmsmargins > Marginal Effects for Location Scale Models","what":"Discrete change and distributional parameter (dpar)","title":"Alternative Software","text":"Compute contrast adjusted predictions sigma parameter, grp=0 grp=1: marginaleffects use comparisons() function variables argument:","code":"bm <- brmsmargins(   ls.fe,   at = data.frame(grp = c(0, 1)),   contrasts = cbind(\"AME grp\" = c(-1, 1)),   CI = 0.95, CIType = \"ETI\", dpar = \"sigma\",   effects = \"fixedonly\") data.frame(bm$ContrastSummary) #>          M      Mdn       LL       UL PercentROPE PercentMID   CI CIType ROPE  MID   Label #> 1 4.897214 4.888706 4.412579 5.408414          NA         NA 0.95    ETI <NA> <NA> AME grp avg_comparisons(   ls.fe,   variables = list(grp = 0:1),   dpar = \"sigma\") #>  #>  Term Contrast Estimate 2.5 % 97.5 % #>   grp    1 - 0     4.89  4.41   5.41 #>  #> Columns: term, contrast, estimate, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"marginal-effect-continuous-on-sigma","dir":"Articles","previous_headings":"brmsmargins > Marginal Effects for Location Scale Models","what":"Marginal effect (continuous) on sigma","title":"Alternative Software","text":"","code":"bm <- brmsmargins(   ls.fe,   add = data.frame(x = c(0, h)),   contrasts = cbind(\"AME x\" = c(-1 / h, 1 / h)),   CI = 0.95, CIType = \"ETI\", dpar = \"sigma\",   effects = \"fixedonly\") data.frame(bm$ContrastSummary) #>          M      Mdn      LL       UL PercentROPE PercentMID   CI CIType ROPE  MID Label #> 1 4.459865 4.452953 3.52165 5.463088          NA         NA 0.95    ETI <NA> <NA> AME x  avg_slopes(ls.fe, dpar = \"sigma\", re_formula = NA) #>  #>  Term Contrast Estimate 2.5 % 97.5 % #>   grp    1 - 0     4.89  4.41   5.41 #>   x      dY/dX     4.45  3.52   5.46 #>  #> Columns: term, contrast, estimate, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"effects","dir":"Articles","previous_headings":"","what":"effects","title":"Alternative Software","text":"effects package created John Fox colleagues. marginaleffects supports 30+ model types effects. effects focuses computation “adjusted predictions.” plots produces roughly equivalent ones produced plot_predictions predictions functions marginaleffects. effects appear support marginal effects (slopes), marginal means, contrasts effects uses Base graphics whereas marginaleffects uses ggplot2 effects includes lot powerful options customize plots. contrast, marginaleffects produces objects can customized chaining ggplot2 functions. Users can also call plot_predictions(model, draw=FALSE) create prediction grid, work raw data directly create plot need effects offers several options currently available marginaleffects, including: Partial residuals plots Many types ways plot adjusted predictions: package vignette","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"modelbased","dir":"Articles","previous_headings":"","what":"modelbased","title":"Alternative Software","text":"modelbased package developed easystats team. section incomplete; contributions welcome. Wrapper around emmeans compute marginal means marginal effects. Powerful functions create beautiful plots.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/alternative_software.html","id":"ggeffects","dir":"Articles","previous_headings":"","what":"ggeffects","title":"Alternative Software","text":"ggeffects package developed Daniel Lüdecke. section incomplete; contributions welcome. Wrapper around emmeans compute marginal means.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/bootstrap.html","id":"delta-method","dir":"Articles","previous_headings":"","what":"Delta method","title":"Bootstrap and Simulation-Based Inference (Experimental)","text":"default strategy compute standard errors confidence intervals delta method. obtain calling: Since default method, obtain results add inferences() call chain:","code":"avg_comparisons(mod, by = \"Species\", variables = \"Petal.Width\") #>  #>         Term Contrast    Species Estimate Std. Error      z Pr(>|z|)   S  2.5 % 97.5 % #>  Petal.Width mean(+1) setosa      -0.1103      0.285 -0.387    0.699 0.5 -0.669  0.449 #>  Petal.Width mean(+1) versicolor  -0.0201      0.160 -0.125    0.900 0.2 -0.334  0.293 #>  Petal.Width mean(+1) virginica    0.0216      0.169  0.128    0.898 0.2 -0.309  0.353 #>  #> Columns: term, contrast, Species, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo avg_comparisons(mod, by = \"Species\", variables = \"Petal.Width\") |>   inferences(method = \"delta\") #>  #>         Term Contrast    Species Estimate Std. Error      z Pr(>|z|)   S  2.5 % 97.5 % #>  Petal.Width mean(+1) setosa      -0.1103      0.285 -0.387    0.699 0.5 -0.669  0.449 #>  Petal.Width mean(+1) versicolor  -0.0201      0.160 -0.125    0.900 0.2 -0.334  0.293 #>  Petal.Width mean(+1) virginica    0.0216      0.169  0.128    0.898 0.2 -0.309  0.353 #>  #> Columns: term, contrast, Species, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/bootstrap.html","id":"bootstrap","dir":"Articles","previous_headings":"","what":"Bootstrap","title":"Bootstrap and Simulation-Based Inference (Experimental)","text":"marginaleffects supports three bootstrap frameworks R: well-established boot package, newer rsample package, -called “bayesian bootstrap” fwb.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/bootstrap.html","id":"boot","dir":"Articles","previous_headings":"Bootstrap","what":"boot","title":"Bootstrap and Simulation-Based Inference (Experimental)","text":"unknown arguments feed inferences() pushed forward boot::boot(): can extract original boot object attribute: can extract individual draws posterior_draws() function:","code":"avg_comparisons(mod, by = \"Species\", variables = \"Petal.Width\") |>   inferences(method = \"boot\") #>  #>         Term Contrast    Species Estimate Std. Error  2.5 % 97.5 % #>  Petal.Width mean(+1) setosa      -0.1103      0.263 -0.612  0.449 #>  Petal.Width mean(+1) versicolor  -0.0201      0.163 -0.321  0.307 #>  Petal.Width mean(+1) virginica    0.0216      0.188 -0.371  0.409 #>  #> Columns: term, contrast, Species, estimate, predicted, predicted_hi, predicted_lo, std.error, conf.low, conf.high est <- avg_comparisons(mod, by = \"Species\", variables = \"Petal.Width\") |>   inferences(method = \"boot\", sim = \"balanced\", R = 500, conf_type = \"bca\") est #>  #>         Term Contrast    Species Estimate Std. Error  2.5 % 97.5 % #>  Petal.Width mean(+1) setosa      -0.1103      0.256 -0.630  0.378 #>  Petal.Width mean(+1) versicolor  -0.0201      0.151 -0.340  0.265 #>  Petal.Width mean(+1) virginica    0.0216      0.171 -0.308  0.337 #>  #> Columns: term, contrast, Species, estimate, predicted, predicted_hi, predicted_lo, std.error, conf.low, conf.high attr(est, \"inferences\") #>  #> BALANCED BOOTSTRAP #>  #>  #> Call: #> bootstrap_boot(model = model, FUN = FUN, newdata = ..1, vcov = ..2,  #>     variables = ..3, type = ..4, by = ..5, conf_level = ..6,  #>     comparison = ..7, transform = ..8, wts = ..9, hypothesis = ..10,  #>     eps = ..11) #>  #>  #> Bootstrap Statistics : #>        original       bias    std. error #> t1* -0.11025325 0.0062280725   0.2563940 #> t2* -0.02006005 0.0025129538   0.1511767 #> t3*  0.02158742 0.0007974665   0.1710070 posterior_draws(est) |> head() #>   drawid        draw        term contrast    Species    estimate predicted predicted_hi predicted_lo std.error   conf.low conf.high #> 1      1 -0.41437873 Petal.Width mean(+1)     setosa -0.11025325  4.957514     4.901389     5.013640 0.2563940 -0.6296001 0.3776391 #> 2      1 -0.15350643 Petal.Width mean(+1) versicolor -0.02006005  6.327949     6.325011     6.330887 0.1511767 -0.3399376 0.2652499 #> 3      1 -0.03304646 Petal.Width mean(+1)  virginica  0.02158742  7.015513     7.033528     6.997499 0.1710070 -0.3084683 0.3370695 #> 4      2  0.14974471 Petal.Width mean(+1)     setosa -0.11025325  4.957514     4.901389     5.013640 0.2563940 -0.6296001 0.3776391 #> 5      2  0.15434044 Petal.Width mean(+1) versicolor -0.02006005  6.327949     6.325011     6.330887 0.1511767 -0.3399376 0.2652499 #> 6      2  0.15646256 Petal.Width mean(+1)  virginica  0.02158742  7.015513     7.033528     6.997499 0.1710070 -0.3084683 0.3370695  posterior_draws(est, shape = \"DxP\") |> dim() #> [1] 500   3"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/bootstrap.html","id":"rsample","dir":"Articles","previous_headings":"Bootstrap","what":"rsample","title":"Bootstrap and Simulation-Based Inference (Experimental)","text":", can pass arguments rsample::bootstraps() inferences(). example, stratified resampling: can extract individual draws posterior_draws() function:","code":"est <- avg_comparisons(mod, by = \"Species\", variables = \"Petal.Width\") |>   inferences(method = \"rsample\", R = 100, strata = \"Species\") est #>  #>         Term Contrast    Species Estimate  2.5 % 97.5 % #>  Petal.Width mean(+1) setosa      -0.1103 -0.656  0.264 #>  Petal.Width mean(+1) versicolor  -0.0201 -0.355  0.235 #>  Petal.Width mean(+1) virginica    0.0216 -0.304  0.397 #>  #> Columns: term, contrast, Species, estimate, predicted, predicted_hi, predicted_lo, conf.low, conf.high  attr(est, \"inferences\") #> # Bootstrap sampling using stratification with apparent sample  #> # A tibble: 101 × 3 #>    splits           id           estimates        #>    <list>           <chr>        <list>           #>  1 <split [150/55]> Bootstrap001 <tibble [3 × 7]> #>  2 <split [150/65]> Bootstrap002 <tibble [3 × 7]> #>  3 <split [150/55]> Bootstrap003 <tibble [3 × 7]> #>  4 <split [150/52]> Bootstrap004 <tibble [3 × 7]> #>  5 <split [150/47]> Bootstrap005 <tibble [3 × 7]> #>  6 <split [150/55]> Bootstrap006 <tibble [3 × 7]> #>  7 <split [150/50]> Bootstrap007 <tibble [3 × 7]> #>  8 <split [150/56]> Bootstrap008 <tibble [3 × 7]> #>  9 <split [150/57]> Bootstrap009 <tibble [3 × 7]> #> 10 <split [150/54]> Bootstrap010 <tibble [3 × 7]> #> # ℹ 91 more rows posterior_draws(est) |> head() #>   drawid      draw        term contrast    Species    estimate predicted predicted_hi predicted_lo   conf.low conf.high #> 1      1 0.1287225 Petal.Width mean(+1)     setosa -0.11025325  4.957514     4.901389     5.013640 -0.6559160 0.2639801 #> 2      1 0.1427535 Petal.Width mean(+1) versicolor -0.02006005  6.327949     6.325011     6.330887 -0.3549374 0.2354560 #> 3      1 0.1492324 Petal.Width mean(+1)  virginica  0.02158742  7.015513     7.033528     6.997499 -0.3041995 0.3969592 #> 4      2 0.3179291 Petal.Width mean(+1)     setosa -0.11025325  4.957514     4.901389     5.013640 -0.6559160 0.2639801 #> 5      2 0.3205877 Petal.Width mean(+1) versicolor -0.02006005  6.327949     6.325011     6.330887 -0.3549374 0.2354560 #> 6      2 0.3218153 Petal.Width mean(+1)  virginica  0.02158742  7.015513     7.033528     6.997499 -0.3041995 0.3969592  posterior_draws(est, shape = \"PxD\") |> dim() #> [1]   3 100"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/bootstrap.html","id":"fractional-weighted-bootstrap-aka-bayesian-bootstrap","dir":"Articles","previous_headings":"Bootstrap","what":"Fractional Weighted Bootstrap (aka Bayesian Bootstrap)","title":"Bootstrap and Simulation-Based Inference (Experimental)","text":"fwb package implements fractional weighted bootstrap (aka Bayesian bootstrap): “fwb implements fractional weighted bootstrap (FWB), also known Bayesian bootstrap, following treatment Xu et al. (2020). FWB involves generating sets weights uniform Dirichlet distribution used estimating statistics interest, yields posterior distribution can interpreted way traditional (resampling-based) bootstrap distribution can .” -Noah Greifer inferences() function makes easy apply inference strategy marginaleffects objects:","code":"avg_comparisons(mod) |> inferences(method = \"fwb\") #>  #>          Term            Contrast Estimate Std. Error  2.5 % 97.5 % #>  Petal.Width  +1                   -0.0362     0.1594 -0.329  0.295 #>  Petal.Length +1                    0.8929     0.0814  0.712  1.049 #>  Species      versicolor - setosa  -1.4629     0.3354 -2.136 -0.797 #>  Species      virginica - setosa   -1.9842     0.3885 -2.756 -1.240 #>  #> Columns: term, contrast, estimate, std.error, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/bootstrap.html","id":"simulation-based-inference","dir":"Articles","previous_headings":"","what":"Simulation-based inference","title":"Bootstrap and Simulation-Based Inference (Experimental)","text":"simulation-based strategy compute confidence intervals described Krinsky & Robb (1986) popularized King, Tomz, Wittenberg (2000). proceed 3 steps: Draw R sets simulated coefficients multivariate normal distribution mean equal original model’s estimated coefficients variance equal model’s variance-covariance matrix (classical, “HC3”, ). Use R sets coefficients compute R sets estimands: predictions, comparisons, slopes. Take quantiles resulting distribution estimands obtain confidence interval standard deviation simulated estimates estimate standard error. examples: Since simulation based inference generates R estimates quantities interest, can treat similarly draws posterior distribution bayesian models. example, can extract draws using posterior_draws() function, plot distributions using packages likeggplot2 ggdist:","code":"library(ggplot2) library(ggdist)  avg_comparisons(mod, by = \"Species\", variables = \"Petal.Width\") |>   inferences(method = \"simulation\") #>  #>         Term Contrast    Species Estimate Std. Error  2.5 % 97.5 % #>  Petal.Width mean(+1) setosa       -0.114      0.283 -0.649  0.402 #>  Petal.Width mean(+1) versicolor   -0.028      0.161 -0.325  0.304 #>  Petal.Width mean(+1) virginica     0.013      0.170 -0.290  0.366 #>  #> Columns: term, contrast, Species, estimate, std.error, conf.low, conf.high, predicted, predicted_hi, predicted_lo, tmp_idx avg_comparisons(mod, by = \"Species\", variables = \"Petal.Width\") |>   inferences(method = \"simulation\") |>   posterior_draws(\"rvar\") |>   ggplot(aes(y = Species, xdist = rvar)) +   stat_slabinterval()"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/bootstrap.html","id":"multiple-imputation-and-missing-data","dir":"Articles","previous_headings":"","what":"Multiple imputation and missing data","title":"Bootstrap and Simulation-Based Inference (Experimental)","text":"workflow inferences function can used estimate models multiple imputation missing data.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"logistic-regression-with-multiplicative-interactions","dir":"Articles","previous_headings":"","what":"Logistic regression with multiplicative interactions","title":"Bayesian Analysis with brms","text":"Load libraries download data passengers Titanic Rdatasets archive: Fit logit model multiplicative interaction:","code":"library(marginaleffects) library(brms) library(ggplot2) library(ggdist)  dat <- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/carData/TitanicSurvival.csv\") dat$survived <- ifelse(dat$survived == \"yes\", 1, 0) dat$woman <- ifelse(dat$sex == \"female\", 1, 0) mod <- brm(survived ~ woman * age + passengerClass,            family = bernoulli(link = \"logit\"),            data = dat)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"adjusted-predictions","dir":"Articles","previous_headings":"Logistic regression with multiplicative interactions","what":"Adjusted predictions","title":"Bayesian Analysis with brms","text":"can compute adjusted predicted values outcome variable (.e., probability survival aboard Titanic) using predictions function. default, function calculates predictions row dataset: visualize relationship outcome one regressors, can plot conditional adjusted predictions plot_predictions function:  Compute adjusted predictions user-specified values regressors, using newdata argument datagrid function: posterior_draws function samples posterior distribution model, produces data frame drawid draw columns. “long” format makes easy plots results:","code":"predictions(mod) #>  #>  Estimate  2.5 % 97.5 % #>    0.9367 0.9070 0.9590 #>    0.8493 0.7453 0.9187 #>    0.9433 0.8949 0.9704 #>    0.5131 0.4302 0.6000 #>    0.9375 0.9080 0.9601 #> --- 1036 rows omitted. See ?avg_predictions and ?print.marginaleffects ---  #>    0.0376 0.0235 0.0581 #>    0.5859 0.5017 0.6663 #>    0.1043 0.0801 0.1337 #>    0.1017 0.0779 0.1307 #>    0.0916 0.0691 0.1189 #> Columns: rowid, estimate, conf.low, conf.high, survived, woman, age, passengerClass plot_predictions(mod, condition = \"age\") pred <- predictions(mod,                     newdata = datagrid(woman = 0:1,                                        passengerClass = c(\"1st\", \"2nd\", \"3rd\"))) pred #>  #>  Estimate  2.5 % 97.5 %  age woman passengerClass #>    0.5149 0.4319  0.602 29.9     0            1st #>    0.2013 0.1536  0.261 29.9     0            2nd #>    0.0875 0.0656  0.114 29.9     0            3rd #>    0.9364 0.9066  0.959 29.9     1            1st #>    0.7783 0.7090  0.835 29.9     1            2nd #>    0.5701 0.4938  0.644 29.9     1            3rd #>  #> Columns: rowid, estimate, conf.low, conf.high, survived, age, woman, passengerClass pred <- posterior_draws(pred) head(pred) #>   drawid       draw rowid   estimate   conf.low conf.high  survived      age woman passengerClass #> 1      1 0.46566713     1 0.51492993 0.43192231 0.6018749 0.4082218 29.88113     0            1st #> 2      1 0.16658900     2 0.20128833 0.15362308 0.2613351 0.4082218 29.88113     0            2nd #> 3      1 0.08750961     3 0.08750369 0.06555724 0.1141134 0.4082218 29.88113     0            3rd #> 4      1 0.93735755     4 0.93641346 0.90660921 0.9587589 0.4082218 29.88113     1            1st #> 5      1 0.77437334     5 0.77829290 0.70896643 0.8346419 0.4082218 29.88113     1            2nd #> 6      1 0.62216334     6 0.57010265 0.49377997 0.6441967 0.4082218 29.88113     1            3rd ggplot(pred, aes(x = draw, fill = factor(woman))) +     geom_density() +     facet_grid(~ passengerClass, labeller = label_both) +     labs(x = \"Predicted probability of survival\", y = \"\", fill = \"Woman\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"marginal-effects","dir":"Articles","previous_headings":"Logistic regression with multiplicative interactions","what":"Marginal effects","title":"Bayesian Analysis with brms","text":"Use slopes() compute marginal effects (slopes regression equation) row dataset, use ) compute “Average Marginal Effects”, , average observation-level marginal effects: Compute marginal effects regressors fixed user-specified values, regressors held means: Compute plot conditional marginal effects:  posterior_draws produces dataset drawid draw columns: can use dataset plot results. example, plot posterior density marginal effect age woman variable equal 0 1:","code":"mfx <- slopes(mod) mfx #>  #>            Term  Contrast Estimate   2.5 % 97.5 % #>  woman          1 - 0       0.4076  0.3339  0.478 #>  woman          1 - 0       0.0919  0.0301  0.179 #>  woman          1 - 0       0.0997  0.0371  0.187 #>  woman          1 - 0       0.4220  0.3487  0.492 #>  woman          1 - 0       0.3517  0.2762  0.426 #> --- 4174 rows omitted. See ?avg_slopes and ?print.marginaleffects ---  #>  passengerClass 3rd - 1st  -0.2643 -0.3397 -0.199 #>  passengerClass 3rd - 1st  -0.3527 -0.4263 -0.282 #>  passengerClass 3rd - 1st  -0.4593 -0.5507 -0.370 #>  passengerClass 3rd - 1st  -0.4550 -0.5463 -0.365 #>  passengerClass 3rd - 1st  -0.4365 -0.5261 -0.350 #> Columns: rowid, term, contrast, estimate, conf.low, conf.high, predicted, predicted_hi, predicted_lo, tmp_idx, survived, woman, age, passengerClass slopes(     mod,     newdata = datagrid(         woman = 1,         passengerClass = \"1st\")) #>  #>            Term  Contrast  Estimate    2.5 %    97.5 %  age woman passengerClass #>  woman          1 - 0      0.420368  0.34697  0.490373 29.9     1            1st #>  age            dY/dX     -0.000238 -0.00136  0.000871 29.9     1            1st #>  passengerClass 2nd - 1st -0.157442 -0.22327 -0.102890 29.9     1            1st #>  passengerClass 3rd - 1st -0.365376 -0.43832 -0.294769 29.9     1            1st #>  #> Columns: rowid, term, contrast, estimate, conf.low, conf.high, predicted, predicted_hi, predicted_lo, tmp_idx, survived, age, woman, passengerClass plot_slopes(mod, variables = \"woman\", condition = \"age\") draws <- posterior_draws(mfx)  dim(draws) #> [1] 16736000       16  head(draws) #>   drawid       draw rowid  term contrast   estimate   conf.low conf.high predicted predicted_hi predicted_lo tmp_idx survived woman     age passengerClass #> 1      1 0.45768070     1 woman    1 - 0 0.40758806 0.33394178 0.4783255 0.9366604    0.9366604    0.5276344       1        1     1 29.0000            1st #> 2      1 0.09282294     2 woman    1 - 0 0.09190500 0.03006249 0.1788661 0.8493050    0.9436352    0.8493050       2        1     0  0.9167            1st #> 3      1 0.10179526     3 woman    1 - 0 0.09973464 0.03710637 0.1873029 0.9433293    0.9433293    0.8409878       3        0     1  2.0000            1st #> 4      1 0.47357659     4 woman    1 - 0 0.42198871 0.34867425 0.4921402 0.5131011    0.9363704    0.5131011       4        0     0 30.0000            1st #> 5      1 0.39400824     5 woman    1 - 0 0.35167800 0.27617966 0.4262480 0.9374937    0.9374937    0.5851849       5        0     1 25.0000            1st #> 6      1 0.72093817     6 woman    1 - 0 0.65665127 0.57622574 0.7297775 0.2730542    0.9320972    0.2730542       6        1     0 48.0000            1st mfx <- slopes(mod,     variables = \"age\",     newdata = datagrid(woman = 0:1)) |>     posterior_draws()  ggplot(mfx, aes(x = draw, fill = factor(woman))) +     stat_halfeye(slab_alpha = .5) +     labs(x = \"Marginal Effect of Age on Survival\",          y = \"Posterior density\",          fill = \"Woman\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"random-effects-model","dir":"Articles","previous_headings":"","what":"Random effects model","title":"Bayesian Analysis with brms","text":"section replicates analyses random effects model published Andrew Heiss’ blog post: “guide correctly calculating posterior predictions average marginal effects multilevel Bayesian models.” objective mainly illustrate use marginaleffects. Please refer original post detailed discussion quantities computed . Load libraries download data: Fit basic model:","code":"library(brms) library(ggdist) library(patchwork) library(marginaleffects)  vdem_2015 <- read.csv(\"https://github.com/vincentarelbundock/marginaleffects/raw/main/data-raw/vdem_2015.csv\")  head(vdem_2015) #>   country_name country_text_id year                           region media_index party_autonomy_ord polyarchy civil_liberties party_autonomy #> 1       Mexico             MEX 2015  Latin America and the Caribbean       0.837                  3     0.631           0.704           TRUE #> 2     Suriname             SUR 2015  Latin America and the Caribbean       0.883                  4     0.777           0.887           TRUE #> 3       Sweden             SWE 2015 Western Europe and North America       0.956                  4     0.915           0.968           TRUE #> 4  Switzerland             CHE 2015 Western Europe and North America       0.939                  4     0.901           0.960           TRUE #> 5        Ghana             GHA 2015               Sub-Saharan Africa       0.858                  4     0.724           0.921           TRUE #> 6 South Africa             ZAF 2015               Sub-Saharan Africa       0.898                  4     0.752           0.869           TRUE mod <- brm(   bf(media_index ~ party_autonomy + civil_liberties + (1 | region),      phi ~ (1 | region)),   data = vdem_2015,   family = Beta(),   control = list(adapt_delta = 0.9))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"posterior-predictions","dir":"Articles","previous_headings":"Random effects model","what":"Posterior predictions","title":"Bayesian Analysis with brms","text":"compute posterior predictions specific values regressors, use newdata argument datagrid function. also use type argument compute two types predictions: accounting residual (observation-level) residual variance (prediction) ignoring (response). Extract posterior draws plot :","code":"nd = datagrid(model = mod,               party_autonomy = c(TRUE, FALSE),               civil_liberties = .5,               region = \"Middle East and North Africa\") p1 <- predictions(mod, type = \"response\", newdata = nd) |>     posterior_draws() |>     transform(type = \"Response\") p2 <- predictions(mod, type = \"prediction\", newdata = nd) |>     posterior_draws() |>     transform(type = \"Prediction\") pred <- rbind(p1, p2) ggplot(pred, aes(x = draw, fill = party_autonomy)) +     stat_halfeye(alpha = .5) +     facet_wrap(~ type) +     labs(x = \"Media index (predicted)\",           y = \"Posterior density\",          fill = \"Party autonomy\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"marginal-effects-and-contrasts","dir":"Articles","previous_headings":"Random effects model","what":"Marginal effects and contrasts","title":"Bayesian Analysis with brms","text":"noted Marginal Effects vignette, one distinct marginal effect combination regressor values. , consider one combination regressor values, region “Middle East North Africa”, civil_liberties 0.5. , calculate mean posterior distribution marginal effects: Use posterior_draws() extract draws posterior distribution marginal effects, plot :  Plot marginal effects, conditional regressor:","code":"mfx <- slopes(mod,                        newdata = datagrid(civil_liberties = .5,                                           region = \"Middle East and North Africa\")) mfx #>  #>             Term     Contrast Estimate 2.5 % 97.5 % party_autonomy civil_liberties                       region #>  party_autonomy  TRUE - FALSE    0.252 0.166  0.336           TRUE             0.5 Middle East and North Africa #>  civil_liberties dY/dX           0.816 0.621  1.007           TRUE             0.5 Middle East and North Africa #>  #> Columns: rowid, term, contrast, estimate, conf.low, conf.high, predicted, predicted_hi, predicted_lo, tmp_idx, media_index, party_autonomy, civil_liberties, region mfx <- posterior_draws(mfx)  ggplot(mfx, aes(x = draw, y = term)) +   stat_halfeye() +   labs(x = \"Marginal effect\", y = \"\") plot_slopes(mod,          variables = \"civil_liberties\",          condition = \"party_autonomy\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"continuous-predictors","dir":"Articles","previous_headings":"Random effects model","what":"Continuous predictors","title":"Bayesian Analysis with brms","text":"slope line different values civil liberties can obtained : plotted:  slopes function can use ellipsis (...) push argument forward posterior_predict function. can alter types predictions returned. example, re_formula=NA argument posterior_predict.brmsfit method compute marginaleffects without including group-level effects:","code":"pred <- predictions(mod,                     newdata = datagrid(party_autonomy = FALSE,                                        region = \"Middle East and North Africa\",                                        civil_liberties = seq(0, 1, by = 0.05))) |>         posterior_draws()  ggplot(pred, aes(x = civil_liberties, y = draw)) +     stat_lineribbon() +     scale_fill_brewer(palette = \"Reds\") +     labs(x = \"Civil liberties\",          y = \"Media index (predicted)\",          fill = \"\") mfx <- slopes(mod,     newdata = datagrid(         civil_liberties = c(.2, .5, .8),         party_autonomy = FALSE,         region = \"Middle East and North Africa\"),     variables = \"civil_liberties\") mfx #>  #>             Term Estimate 2.5 % 97.5 % civil_liberties party_autonomy                       region #>  civil_liberties    0.490 0.361  0.639             0.2          FALSE Middle East and North Africa #>  civil_liberties    0.807 0.612  0.993             0.5          FALSE Middle East and North Africa #>  civil_liberties    0.807 0.674  0.934             0.8          FALSE Middle East and North Africa #>  #> Columns: rowid, term, estimate, conf.low, conf.high, predicted, predicted_hi, predicted_lo, tmp_idx, media_index, civil_liberties, party_autonomy, region mfx <- posterior_draws(mfx)  ggplot(mfx, aes(x = draw, fill = factor(civil_liberties))) +     stat_halfeye(slab_alpha = .5) +     labs(x = \"Marginal effect of Civil Liberties on Media Index\",          y = \"Posterior density\",          fill = \"Civil liberties\") mfx <- slopes(     mod,     newdata = datagrid(         civil_liberties = c(.2, .5, .8),         party_autonomy = FALSE,         region = \"Middle East and North Africa\"),     variables = \"civil_liberties\",     re_formula = NA) |>     posterior_draws()  ggplot(mfx, aes(x = draw, fill = factor(civil_liberties))) +     stat_halfeye(slab_alpha = .5) +     labs(x = \"Marginal effect of Civil Liberties on Media Index\",          y = \"Posterior density\",          fill = \"Civil liberties\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"global-grand-mean","dir":"Articles","previous_headings":"Random effects model","what":"Global grand mean","title":"Bayesian Analysis with brms","text":"","code":"pred <- predictions(     mod,     re_formula = NA,     newdata = datagrid(party_autonomy = c(TRUE, FALSE))) |>     posterior_draws()  mfx <- slopes(     mod,     re_formula = NA,     variables = \"party_autonomy\") |>     posterior_draws()  plot1 <- ggplot(pred, aes(x = draw, fill = party_autonomy)) +          stat_halfeye(slab_alpha = .5) +          labs(x = \"Media index (Predicted)\",               y = \"Posterior density\",               fill = \"Party autonomy\")  plot2 <- ggplot(mfx, aes(x = draw)) +          stat_halfeye(slab_alpha = .5)  +          labs(x = \"Contrast: Party autonomy TRUE - FALSE\",               y = \"\",               fill = \"Party autonomy\")  # combine plots using the `patchwork` package plot1 + plot2"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"region-specific-predictions-and-contrasts","dir":"Articles","previous_headings":"Random effects model","what":"Region-specific predictions and contrasts","title":"Bayesian Analysis with brms","text":"Predicted media index region level civil liberties:  Predicted media index region level civil liberties:  Predicted media index region party autonomy:  TRUE/FALSE contrasts (marginal effects) party autonomy region:","code":"pred <- predictions(mod,                     newdata = datagrid(region = vdem_2015$region,                                        party_autonomy = FALSE,                                         civil_liberties = seq(0, 1, length.out = 100))) |>          posterior_draws()  ggplot(pred, aes(x = civil_liberties, y = draw)) +     stat_lineribbon() +     scale_fill_brewer(palette = \"Reds\") +     facet_wrap(~ region) +     labs(x = \"Civil liberties\",          y = \"Media index (predicted)\",          fill = \"\") pred <- predictions(mod,                     newdata = datagrid(region = vdem_2015$region,                                        civil_liberties = c(.2, .8),                                       party_autonomy = FALSE)) |>         posterior_draws()  ggplot(pred, aes(x = draw, fill = factor(civil_liberties))) +     stat_halfeye(slab_alpha = .5) +     facet_wrap(~ region) +     labs(x = \"Media index (predicted)\",          y = \"Posterior density\",          fill = \"Civil liberties\") pred <- predictions(mod,                     newdata = datagrid(region = vdem_2015$region,                                        party_autonomy = c(TRUE, FALSE),                                        civil_liberties = .5)) |>         posterior_draws()  ggplot(pred, aes(x = draw, y = region , fill = party_autonomy)) +     stat_halfeye(slab_alpha = .5) +     labs(x = \"Media index (predicted)\",          y = \"\",          fill = \"Party autonomy\") mfx <- slopes(     mod,     variables = \"party_autonomy\",     newdata = datagrid(         region = vdem_2015$region,         civil_liberties = .5)) |>     posterior_draws()  ggplot(mfx, aes(x = draw, y = region , fill = party_autonomy)) +     stat_halfeye(slab_alpha = .5) +     labs(x = \"Media index (predicted)\",          y = \"\",          fill = \"Party autonomy\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"hypothetical-groups","dir":"Articles","previous_headings":"Random effects model","what":"Hypothetical groups","title":"Bayesian Analysis with brms","text":"can also obtain predictions marginal effects hypothetical group instead one observed regions. achieve , create dataset NA region column. call marginaleffects predictions functions allow_new_levels argument. argument pushed via ellipsis (...) posterior_epred function brms package:","code":"dat <- data.frame(civil_liberties = .5,                   party_autonomy = FALSE,                   region = \"New Region\")  mfx <- slopes(     mod,     variables = \"party_autonomy\",     allow_new_levels = TRUE,     newdata = dat)  draws <- posterior_draws(mfx)  ggplot(draws, aes(x = draw)) +      stat_halfeye() +      labs(x = \"Marginal effect of party autonomy in a generic world region\", y = \"\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"averaging-marginalizing-integrating-random-effects","dir":"Articles","previous_headings":"Random effects model","what":"Averaging, marginalizing, integrating random effects","title":"Bayesian Analysis with brms","text":"Consider logistic regression model random effects: can compute adjusted predictions given value x firm (random effects) follows: can average/marginalize/integrate across random effects avg_predictions() function argument: can also draw (assumed gaussian) population distribution random effects, asking predictions() make predictions new “levels” random effects. take average predictions using avg_predictions() argument, “integrated random effects”, described brmsmargins package vignette. code , make predictions 100 firm identifiers original dataset. also ask predictions() push forward allow_new_levels sample_new_levels arguments brms::posterior_epred function: can “integrate ” random effects slopes functions . instance, nearly equivalent brmsmargins command output (slight variations due different random seeds): See alternative software vignette information brmsmargins.","code":"dat <- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/plm/EmplUK.csv\") dat$x <- as.numeric(dat$output > median(dat$output)) dat$y <- as.numeric(dat$emp > median(dat$emp)) mod <- brm(y ~ x + (1 | firm), data = dat, backend = \"cmdstanr\", family = \"bernoulli\") p <- predictions(mod, newdata = datagrid(x = 0, firm = unique)) head(p) #>  #>  Estimate    2.5 % 97.5 % x firm #>   1.0e+00 9.01e-01 1.0000 0    1 #>   1.0e+00 8.95e-01 1.0000 0    2 #>   1.0e+00 9.12e-01 1.0000 0    3 #>   1.0e+00 7.97e-01 1.0000 0    4 #>   1.0e+00 9.09e-01 1.0000 0    5 #>   4.9e-08 8.42e-21 0.0019 0    6 #>  #> Columns: rowid, estimate, conf.low, conf.high, y, x, firm avg_predictions(mod, newdata = datagrid(x = 0, firm = unique)) #>  #>  Estimate 2.5 % 97.5 % #>     0.454  0.44  0.468 #>  #> Columns: estimate, conf.low, conf.high  predictions(mod, newdata = datagrid(x = 0:1, firm = unique), by = \"x\") #>  #>  x Estimate 2.5 % 97.5 % #>  0    0.454 0.440  0.468 #>  1    0.557 0.546  0.570 #>  #> Columns: x, estimate, conf.low, conf.high predictions(     mod,     newdata = datagrid(x = 0:1, firm = -1:-100),     allow_new_levels = TRUE,     sample_new_levels = \"gaussian\",     by = \"x\") #>  #>  x Estimate 2.5 % 97.5 % #>  0    0.453 0.341  0.570 #>  1    0.551 0.440  0.665 #>  #> Columns: x, estimate, conf.low, conf.high avg_comparisons(     mod,     newdata = datagrid(firm = -1:-100),     allow_new_levels = TRUE,     sample_new_levels = \"gaussian\") #>  #>  Term Contrast Estimate  2.5 % 97.5 % #>     x    1 - 0   0.0965 0.0485  0.162 #>  #> Columns: term, contrast, estimate, conf.low, conf.high library(brmsmargins) bm <- brmsmargins(   k = 100,   object = mod,   at = data.frame(x = c(0, 1)),   CI = .95,   CIType = \"ETI\",   contrasts = cbind(\"AME x\" = c(-1, 1)),   effects = \"integrateoutRE\") bm$ContrastSummary |> data.frame() #>            M        Mdn         LL        UL PercentROPE PercentMID   CI CIType ROPE  MID Label #> 1 0.09891427 0.09683349 0.04796505 0.1613612          NA         NA 0.95    ETI <NA> <NA> AME x"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"multinomial-logit","dir":"Articles","previous_headings":"","what":"Multinomial logit","title":"Bayesian Analysis with brms","text":"Fit model categorical outcome (heating system choice California houses) logit link:","code":"dat <- \"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Heating.csv\" dat <- read.csv(dat) mod <- brm(depvar ~ ic.gc + oc.gc,            data = dat,            family = categorical(link = \"logit\"))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"adjusted-predictions-1","dir":"Articles","previous_headings":"Multinomial logit","what":"Adjusted predictions","title":"Bayesian Analysis with brms","text":"Compute predicted probabilities level outcome variable: Extract posterior draws plot :  Use plot_predictions function plot conditional adjusted predictions level outcome variable gear, conditional value mpg regressor:","code":"pred <- predictions(mod)  head(pred) #>  #>  Group Estimate  2.5 % 97.5 % #>     ec   0.0663 0.0447 0.0930 #>     ec   0.0768 0.0590 0.0974 #>     ec   0.1030 0.0618 0.1585 #>     ec   0.0634 0.0459 0.0838 #>     ec   0.0745 0.0574 0.0947 #>     ec   0.0709 0.0455 0.1036 #>  #> Columns: rowid, group, estimate, conf.low, conf.high, depvar, ic.gc, oc.gc draws <- posterior_draws(pred)  ggplot(draws, aes(x = draw, fill = group)) +     geom_density(alpha = .2, color = \"white\") +     labs(x = \"Predicted probability\",          y = \"Density\",          fill = \"Heating system\") plot_predictions(mod, condition = \"oc.gc\") +     facet_wrap(~ group) +     labs(y = \"Predicted probability\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"marginal-effects-1","dir":"Articles","previous_headings":"Multinomial logit","what":"Marginal effects","title":"Bayesian Analysis with brms","text":"","code":"avg_slopes(mod) #>  #>  Group  Term  Estimate     2.5 %   97.5 % #>     ec ic.gc -1.77e-04 -3.96e-04 2.37e-05 #>     er ic.gc  1.65e-05 -2.26e-04 2.51e-04 #>     gc ic.gc  1.38e-05 -3.72e-04 4.00e-04 #>     gr ic.gc  4.24e-05 -2.37e-04 3.30e-04 #>     hp ic.gc  1.07e-04 -7.73e-05 2.97e-04 #>     ec oc.gc  4.88e-04 -4.04e-04 1.45e-03 #>     er oc.gc -1.02e-03 -2.07e-03 2.98e-05 #>     gc oc.gc  1.04e-03 -7.39e-04 2.78e-03 #>     gr oc.gc  9.46e-05 -1.19e-03 1.34e-03 #>     hp oc.gc -5.85e-04 -1.45e-03 2.30e-04 #>  #> Columns: group, term, estimate, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"hurdle-models","dir":"Articles","previous_headings":"","what":"Hurdle models","title":"Bayesian Analysis with brms","text":"section replicates analyses yet another amazing blog post Andrew Heiss. begin, estimate hurdle model brms random effects, using data gapminder package: 704G","code":"library(gapminder) library(brms) library(dplyr) library(ggplot2) library(ggdist) library(cmdstanr) library(patchwork) library(marginaleffects)  set.seed(1024)  CHAINS <- 4 ITER <- 2000 WARMUP <- 1000 BAYES_SEED <- 1234  gapminder <- gapminder::gapminder |>    filter(continent != \"Oceania\") |>    # Make a bunch of GDP values 0   mutate(prob_zero = ifelse(lifeExp < 50, 0.3, 0.02),          will_be_zero = rbinom(n(), 1, prob = prob_zero),          gdpPercap = ifelse(will_be_zero, 0, gdpPercap)) |>    select(-prob_zero, -will_be_zero) |>    # Make a logged version of GDP per capita   mutate(log_gdpPercap = log1p(gdpPercap)) |>    mutate(is_zero = gdpPercap == 0)  mod <- brm(   bf(gdpPercap ~ lifeExp + year + (1 + lifeExp + year | continent),      hu ~ lifeExp),   data = gapminder,   backend = \"cmdstanr\",   family = hurdle_lognormal(),   cores = 2,   chains = CHAINS, iter = ITER, warmup = WARMUP, seed = BAYES_SEED,   silent = 2)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"adjusted-predictions-2","dir":"Articles","previous_headings":"Hurdle models","what":"Adjusted predictions","title":"Bayesian Analysis with brms","text":"Adjusted predictions every observation original data: Adjusted predictions hu parameter: Predictions different scale: Plot adjusted predictions function lifeExp:  Predictions one condition re_formula argument brms:","code":"predictions(mod) |> head() #>  #>  Estimate 2.5 % 97.5 % #>       143   103    219 #>       168   125    256 #>       202   153    304 #>       251   197    373 #>       312   250    454 #>       398   325    567 #>  #> Columns: rowid, estimate, conf.low, conf.high, gdpPercap, lifeExp, year, continent predictions(mod, dpar = \"hu\") |> head() #>  #>  Estimate 2.5 % 97.5 % #>     0.574 0.475  0.652 #>     0.537 0.442  0.611 #>     0.496 0.407  0.566 #>     0.446 0.366  0.511 #>     0.396 0.325  0.454 #>     0.341 0.282  0.391 #>  #> Columns: rowid, estimate, conf.low, conf.high, gdpPercap, lifeExp, year, continent predictions(mod, type = \"link\", dpar = \"hu\") |> head() #>  #>  Estimate  2.5 %  97.5 % #>    0.2980 -0.101  0.6259 #>    0.1463 -0.235  0.4527 #>   -0.0178 -0.377  0.2673 #>   -0.2189 -0.551  0.0424 #>   -0.4234 -0.730 -0.1857 #>   -0.6573 -0.933 -0.4443 #>  #> Columns: rowid, estimate, conf.low, conf.high, gdpPercap, lifeExp, year, continent plot_predictions(     mod,     condition = \"lifeExp\") +     labs(y = \"mu\") + plot_predictions(     mod,     dpar = \"hu\",     condition = \"lifeExp\") +     labs(y = \"hu\") plot_predictions(     mod,     re_formula = NULL,     condition = c(\"lifeExp\", \"continent\"))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"extract-draws-with-posterior_draws","dir":"Articles","previous_headings":"Hurdle models","what":"Extract draws with posterior_draws()","title":"Bayesian Analysis with brms","text":"posterior_draws() function extract raw samples posterior objects produced marginaleffects. allows us use richer geoms summaries, ggdist package:","code":"predictions(     mod,     re_formula = NULL,     newdata = datagrid(model = mod,                        continent = gapminder$continent,                        year = c(1952, 2007),                        lifeExp = seq(30, 80, 1))) |>     posterior_draws() |>     ggplot(aes(lifeExp, draw, fill = continent, color = continent)) +     stat_lineribbon(alpha = .25) +     facet_grid(year ~ continent)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"average-contrasts","dir":"Articles","previous_headings":"Hurdle models","what":"Average Contrasts","title":"Bayesian Analysis with brms","text":"happens gdpPercap lifeExp increases one? happens gdpPercap lifeExp increases one standard deviation? happens gdpPercap lifeExp increases 50 60 year simultaneously increases min max? Plot draws posterior distribution average contrasts (thing draws posterior distribution contrasts):","code":"avg_comparisons(mod) #>  #>     Term Contrast Estimate 2.5 % 97.5 % #>  lifeExp       +1    718.9 515.6  812.0 #>  year          +1    -63.8 -84.4  -41.1 #>  #> Columns: term, contrast, estimate, conf.low, conf.high avg_comparisons(mod, variables = list(lifeExp = \"sd\")) #>  #>     Term                Contrast Estimate 2.5 % 97.5 % #>  lifeExp (x + sd/2) - (x - sd/2)     4050  3718   4741 #>  #> Columns: term, contrast, estimate, conf.low, conf.high avg_comparisons(     mod,     variables = list(lifeExp = c(50, 60), year = \"minmax\"),     cross = TRUE) #>  #>  C: lifeExp   C: year Estimate 2.5 % 97.5 % #>     60 - 50 Max - Min      835   523   1404 #>  #> Columns: term, contrast_lifeExp, contrast_year, estimate, conf.low, conf.high avg_comparisons(mod) |>     posterior_draws() |>     ggplot(aes(estimate, term)) +     stat_dotsinterval() +     labs(x = \"Posterior distribution of average contrasts\", y = \"\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"marginal-effects-slopes","dir":"Articles","previous_headings":"Hurdle models","what":"Marginal effects (slopes)","title":"Bayesian Analysis with brms","text":"Average Marginal Effect lifeExp different scales different parameters: Plot Conditional Marginal Effects  can call slopes() comparisons() posterior_draws() function even control:","code":"avg_slopes(mod) #>  #>     Term Estimate 2.5 % 97.5 % #>  lifeExp    718.7 515.6    812 #>  year       -63.8 -84.4    -41 #>  #> Columns: term, estimate, conf.low, conf.high  avg_slopes(mod, type = \"link\") #>  #>     Term Estimate   2.5 %   97.5 % #>  lifeExp  0.08249  0.0742  0.08856 #>  year    -0.00937 -0.0120 -0.00632 #>  #> Columns: term, estimate, conf.low, conf.high  avg_slopes(mod, dpar = \"hu\") #>  #>     Term Estimate    2.5 %   97.5 % #>  lifeExp -0.00817 -0.00937 -0.00669 #>  year     0.00000  0.00000  0.00000 #>  #> Columns: term, estimate, conf.low, conf.high  avg_slopes(mod, dpar = \"hu\", type = \"link\") #>  #>     Term Estimate  2.5 %  97.5 % #>  lifeExp  -0.0993 -0.113 -0.0838 #>  year      0.0000  0.000  0.0000 #>  #> Columns: term, estimate, conf.low, conf.high plot_slopes(     mod,     variables = \"lifeExp\",     condition = \"lifeExp\") +     labs(y = \"mu\") +  plot_slopes(     mod,     dpar = \"hu\",     variables = \"lifeExp\",     condition = \"lifeExp\") +     labs(y = \"hu\") comparisons(     mod,     type = \"link\",     variables = \"lifeExp\",     newdata = datagrid(lifeExp = c(40, 70), continent = gapminder$continent)) |>     posterior_draws() |>     ggplot(aes(draw, continent, fill = continent)) +     stat_dotsinterval() +     facet_grid(lifeExp ~ .) +     labs(x = \"Effect of a 1 unit change in Life Expectancy\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"bayesian-estimates-and-credible-intervals","dir":"Articles","previous_headings":"","what":"Bayesian estimates and credible intervals","title":"Bayesian Analysis with brms","text":"bayesian models like produced brms rstanarm packages, marginaleffects package functions report median posterior distribution main estimates. default credible intervals equal-tailed intervals (quantiles), default function identify center distribution median. Users can customize type intervals reported setting global options. Note reported estimate intervals change slightly:","code":"library(insight) library(marginaleffects)  mod <- insight::download_model(\"brms_1\")  options(marginaleffects_posterior_interval = \"hdi\") options(marginaleffects_posterior_center = mean) avg_comparisons(mod) #>  #>  Term Contrast Estimate 2.5 % 97.5 % #>   cyl       +1    -1.50 -2.38 -0.677 #>   wt        +1    -3.21 -4.70 -1.570 #>  #> Columns: term, contrast, estimate, conf.low, conf.high  options(marginaleffects_posterior_interval = \"eti\") options(marginaleffects_posterior_center = stats::median) avg_comparisons(mod) #>  #>  Term Contrast Estimate 2.5 % 97.5 % #>   cyl       +1    -1.49 -2.36 -0.636 #>   wt        +1    -3.20 -4.79 -1.645 #>  #> Columns: term, contrast, estimate, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"random-variables-posterior-and-ggdist","dir":"Articles","previous_headings":"","what":"Random variables: posterior and ggdist","title":"Bayesian Analysis with brms","text":"Recent versions posterior, brms, ggdist packages make easy draw, summarize plot random variables. posterior_draws() can produce objects class rvar make easy use features returning data frame column type rvar:","code":"library(brms) library(ggdist) library(ggplot2) library(marginaleffects) mod <- brm(am ~ mpg + hp, data = mtcars, family = bernoulli) avg_comparisons(mod) |>   posterior_draws(shape = \"rvar\") |>   ggplot(aes(y = term, xdist = rvar)) +    stat_slabinterval()"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/brms.html","id":"non-linear-hypothesis-testing","dir":"Articles","previous_headings":"","what":"Non-linear hypothesis testing","title":"Bayesian Analysis with brms","text":"begin estimating model: Notice can compute average contrasts two different ways, using avg_comparisons() function comparison argument: Now, use hypothesis argument compare first second rows comparisons() output: hypotheses function brms package can also perform non-linear hypothesis testing, generates convenient statistics summaries. function accepts D--P matrix draws posterior distribution, D number draws N number parameters. can obtain matrix using posterior_draws(x, shape = \"DxP\"), can simply add couple calls chain operations:","code":"mod <- brm(am ~ mpg + hp, data = mtcars, family = bernoulli(),            seed = 1024, silent = 2, chains = 4, iter = 1000) avg_comparisons(mod) #>  #>  Term Contrast Estimate   2.5 %  97.5 % #>   hp        +1  0.00599 0.00288 0.00886 #>   mpg       +1  0.13547 0.07871 0.17472 #>  #> Columns: term, contrast, estimate, conf.low, conf.high  comparisons(mod, comparison = \"differenceavg\") #>  #>  Term Contrast Estimate   2.5 %  97.5 % #>   mpg mean(+1)  0.13547 0.07871 0.17472 #>   hp  mean(+1)  0.00599 0.00288 0.00886 #>  #> Columns: term, contrast, estimate, conf.low, conf.high, predicted, predicted_hi, predicted_lo, tmp_idx comparisons(     mod,     comparison = \"differenceavg\",     hypothesis = \"b2 - b1 = 0.2\") #>  #>       Term Estimate  2.5 % 97.5 % #>  b2-b1=0.2    -0.33 -0.367 -0.275 #>  #> Columns: term, estimate, conf.low, conf.high avg_comparisons(mod, comparison = \"differenceavg\") |>     posterior_draws(shape = \"DxP\") |>     brms::hypothesis(\"b2 - b1 > .2\") #> Hypothesis Tests for class : #>         Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star #> 1 (b2-b1)-(.2) > 0    -0.33      0.02    -0.36    -0.28          0         0      #> --- #> 'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses. #> '*': For one-sided hypotheses, the posterior probability exceeds 95%; #> for two-sided hypotheses, the value tested against lies outside the 95%-CI. #> Posterior probabilities of point hypotheses assume equal prior probabilities."},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/categorical.html","id":"masspolr-function","dir":"Articles","previous_headings":"","what":"MASS::polr function","title":"Categorical outcomes","text":"Consider simple ordered logit model predict number gears car based miles per gallon horsepower: Now, consider car 25 miles per gallon 110 horsepower. expected predicted probability outcome level (gear) car : Since gear categorical, make one prediction level outcome. Now consider marginal effects (aka slopes partial derivatives) car: , marginaleffects produces one estimate slope outcome level. small step size \\(\\varepsilon\\), printed quantities estimated : \\[\\frac{P(gear=3|mpg=25+\\varepsilon, hp=110)-P(gear=3|mpg=25-\\varepsilon, hp=110)}{2 \\cdot \\varepsilon}\\] \\[\\frac{P(gear=4|mpg=25+\\varepsilon, hp=110)-P(gear=4|mpg=25-\\varepsilon, hp=110)}{2 \\cdot \\varepsilon}\\] \\[\\frac{P(gear=5|mpg=25+\\varepsilon, hp=110)-P(gear=5|mpg=25-\\varepsilon, hp=110)}{2 \\cdot \\varepsilon}\\] call avg_slopes(), marginaleffects repeat computation every row original dataset, report average slope level outcome:","code":"library(MASS) mod <- polr(factor(gear) ~ mpg + hp, data = mtcars, Hess = TRUE) predictions(mod, newdata = datagrid(mpg = 25, hp = 110)) #>  #>  Group Estimate Std. Error    z Pr(>|z|)    S  2.5 % 97.5 % mpg  hp #>      3    0.203     0.0959 2.12   0.0339  4.9 0.0155  0.391  25 110 #>      4    0.578     0.1229 4.70   <0.001 18.6 0.3373  0.819  25 110 #>      5    0.218     0.1007 2.17   0.0302  5.1 0.0209  0.416  25 110 #>  #> Columns: rowid, group, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, gear, mpg, hp slopes(mod, variables = \"mpg\", newdata = datagrid(mpg = 25, hp = 110)) #>  #>  Group Term Estimate Std. Error       z Pr(>|z|)    S    2.5 %  97.5 % mpg  hp #>      3  mpg -0.06041     0.0169 -3.5809   <0.001 11.5 -0.09347 -0.0273  25 110 #>      4  mpg -0.00321     0.0335 -0.0958   0.9237  0.1 -0.06896  0.0625  25 110 #>      5  mpg  0.06362     0.0301  2.1132   0.0346  4.9  0.00461  0.1226  25 110 #>  #> Columns: rowid, group, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, gear, mpg, hp avg_slopes(mod) #>  #>  Group Term Estimate Std. Error     z Pr(>|z|)    S     2.5 %   97.5 % #>      3  mpg -0.07014   0.015480 -4.53  < 0.001 17.4 -0.100479 -0.03980 #>      3  hp  -0.00377   0.001514 -2.49  0.01283  6.3 -0.006735 -0.00080 #>      4  mpg  0.03747   0.013857  2.70  0.00685  7.2  0.010311  0.06463 #>      4  hp   0.00201   0.000957  2.10  0.03545  4.8  0.000137  0.00389 #>      5  mpg  0.03267   0.009572  3.41  < 0.001 10.6  0.013907  0.05143 #>      5  hp   0.00175   0.000833  2.11  0.03522  4.8  0.000122  0.00339 #>  #> Columns: group, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/categorical.html","id":"nnet-package","dir":"Articles","previous_headings":"","what":"nnet package","title":"Categorical outcomes","text":"multinom function nnet package allows users fit log-linear models via neural networks. data used function data frame one observation per row, response variable coded factor. marginaleffects package function work seamlessly model. example, can estimate model compute average marginal effects follows: Notice models, get one marginal effect term, level response variable. reason, use \"group\" condition argument (facet_*() function) calling one plotting functions:","code":"library(nnet)  head(mtcars) #>                    mpg cyl disp  hp drat    wt  qsec vs am gear carb #> Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4 #> Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4 #> Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1 #> Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1 #> Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2 #> Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1  mod <- multinom(factor(gear) ~ hp + mpg, data = mtcars, trace = FALSE)  avg_slopes(mod, type = \"probs\") #>  #>  Group Term  Estimate Std. Error       z Pr(>|z|)    S    2.5 %    97.5 % #>      3  hp  -3.44e-05    0.00225 -0.0153  0.98780  0.0 -0.00444  0.004372 #>      3  mpg -7.13e-02    0.02645 -2.6959  0.00702  7.2 -0.12316 -0.019466 #>      4  hp  -4.67e-03    0.00221 -2.1126  0.03464  4.9 -0.00900 -0.000337 #>      4  mpg  1.59e-02    0.02010  0.7916  0.42859  1.2 -0.02348  0.055293 #>      5  hp   4.70e-03    0.00130  3.6167  < 0.001 11.7  0.00215  0.007250 #>      5  mpg  5.54e-02    0.01642  3.3735  < 0.001 10.4  0.02322  0.087593 #>  #> Columns: group, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high library(ggplot2)  plot_predictions(mod, condition = c(\"mpg\", \"group\"), type = \"probs\") plot_predictions(mod, condition = \"mpg\", type = \"probs\") + facet_wrap(~group) plot_comparisons(     mod,     variables = list(mpg = c(15, 30)),     condition = \"group\",     type = \"probs\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/categorical.html","id":"mlogit-package","dir":"Articles","previous_headings":"","what":"mlogit package","title":"Categorical outcomes","text":"mlogit package uses data slightly different structure, one row per observation-choice combination. example, data choice travel mode includes 4 rows per individual, one mode transportation: Note slopes function always return estimates zero regressors vertical bar formula. marginaleffects increments rows prediction dataset way compute slopes contrast. mlogit data “long” format, means alternatives incremented way, produce alternative-specific changes predictors. One strategy circumvent problem supply data frame numeric values compare, alternative specific changes. example, test happens probability selecting mode transportation increase wait time air travel: can compute yet kinds marginal effects, can construct customized data frames feed newdata argument slopes function. want compute slope response function (marginal effects) predictors fixed global mean, can : want compute marginal effects gcost wait fixed mean value, conditional choice transportation mode: can also explore complex alternatives. , example, one alternative affected cost reduction: Important: newdata argument mlogit models must “balanced” data frame, , must number rows multiple number choices.","code":"library(\"AER\") library(\"mlogit\") library(\"tidyverse\") data(\"TravelMode\", package = \"AER\")  head(TravelMode) #>   individual  mode choice wait vcost travel gcost income size #> 1          1   air     no   69    59    100    70     35    1 #> 2          1 train     no   34    31    372    71     35    1 #> 3          1   bus     no   35    25    417    70     35    1 #> 4          1   car    yes    0    10    180    30     35    1 #> 5          2   air     no   64    58     68    68     30    2 #> 6          2 train     no   44    31    354    84     30    2  mod <- mlogit(choice ~ wait + gcost | income + size, TravelMode)  avg_slopes(mod, variables = c(\"income\", \"size\")) #>  #>  Group   Term  Estimate Std. Error      z Pr(>|z|)    S     2.5 %   97.5 % #>  air   income  0.002786    0.00122  2.289  0.02208  5.5  0.000400  0.00517 #>  bus   income -0.000372    0.00110 -0.338  0.73547  0.4 -0.002531  0.00179 #>  car   income  0.003373    0.00137  2.456  0.01403  6.2  0.000682  0.00606 #>  train income -0.005787    0.00132 -4.390  < 0.001 16.4 -0.008370 -0.00320 #>  air   size   -0.126465    0.02892 -4.374  < 0.001 16.3 -0.183138 -0.06979 #>  bus   size    0.011345    0.02587  0.439  0.66096  0.6 -0.039353  0.06204 #>  car   size    0.045880    0.02476  1.853  0.06385  4.0 -0.002642  0.09440 #>  train size    0.069240    0.02478  2.794  0.00521  7.6  0.020662  0.11782 #>  #> Columns: group, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high altspec <- data.frame(   low = TravelMode$wait,   high = ifelse(TravelMode$mode == \"air\", TravelMode$wait + 15, TravelMode$wait) )  avg_comparisons(mod, variables = list(wait = altspec)) #>  #>  Group Term Contrast Estimate Std. Error      z Pr(>|z|)     S   2.5 %  97.5 % #>  air   wait   manual  -0.1321    0.01070 -12.35   <0.001 114.0 -0.1531 -0.1111 #>  bus   wait   manual   0.0251    0.00460   5.45   <0.001  24.2  0.0160  0.0341 #>  car   wait   manual   0.0701    0.00834   8.41   <0.001  54.5  0.0538  0.0865 #>  train wait   manual   0.0369    0.00528   6.99   <0.001  38.4  0.0266  0.0473 #>  #> Columns: group, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high nd <- TravelMode |>     summarize(across(c(\"wait\", \"gcost\", \"income\", \"size\"),               function(x) rep(mean(x), 4))) nd #>       wait    gcost   income     size #> 1 34.58929 110.8798 34.54762 1.742857 #> 2 34.58929 110.8798 34.54762 1.742857 #> 3 34.58929 110.8798 34.54762 1.742857 #> 4 34.58929 110.8798 34.54762 1.742857  avg_slopes(mod, newdata = nd, variables = c(\"income\", \"size\")) #>  #>  Group   Term  Estimate Std. Error     z Pr(>|z|)   S     2.5 %    97.5 % #>  air   income  6.66e-03   2.42e-03  2.75  0.00603 7.4  1.91e-03  1.14e-02 #>  bus   income -1.14e-03   9.43e-04 -1.21  0.22639 2.1 -2.99e-03  7.08e-04 #>  car   income  6.48e-06   2.02e-05  0.32  0.74893 0.4 -3.32e-05  4.62e-05 #>  train income -5.52e-03   1.91e-03 -2.89  0.00383 8.0 -9.26e-03 -1.78e-03 #>  air   size   -1.69e-01   5.88e-02 -2.88  0.00394 8.0 -2.85e-01 -5.43e-02 #>  bus   size    4.67e-02   2.72e-02  1.72  0.08623 3.5 -6.65e-03  1.00e-01 #>  car   size    1.36e-03   8.81e-04  1.54  0.12305 3.0 -3.68e-04  3.08e-03 #>  train size    1.21e-01   4.45e-02  2.73  0.00634 7.3  3.42e-02  2.08e-01 #>  #> Columns: group, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high nd <- TravelMode |>     group_by(mode) |>     summarize(across(c(\"wait\", \"gcost\", \"income\", \"size\"), mean)) nd #> # A tibble: 4 × 5 #>   mode   wait gcost income  size #>   <fct> <dbl> <dbl>  <dbl> <dbl> #> 1 air    61.0 103.    34.5  1.74 #> 2 train  35.7 130.    34.5  1.74 #> 3 bus    41.7 115.    34.5  1.74 #> 4 car     0    95.4   34.5  1.74  avg_slopes(mod, newdata = nd, variables = c(\"income\", \"size\")) #>  #>  Group   Term  Estimate Std. Error      z Pr(>|z|)    S     2.5 %   97.5 % #>  air   income  0.006015    0.00233  2.585  0.00975  6.7  0.001454  0.01058 #>  bus   income -0.000713    0.00146 -0.489  0.62481  0.7 -0.003570  0.00214 #>  car   income  0.005445    0.00229  2.382  0.01721  5.9  0.000965  0.00993 #>  train income -0.010747    0.00256 -4.202  < 0.001 15.2 -0.015760 -0.00573 #>  air   size   -0.232927    0.05659 -4.116  < 0.001 14.7 -0.343848 -0.12201 #>  bus   size    0.020440    0.03436  0.595  0.55195  0.9 -0.046908  0.08779 #>  car   size    0.067820    0.04123  1.645  0.09996  3.3 -0.012984  0.14862 #>  train size    0.144668    0.04774  3.030  0.00244  8.7  0.051102  0.23823 #>  #> Columns: group, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high nd <- datagrid(mode = TravelMode$mode, newdata = TravelMode) nd <- lapply(1:4, function(i) mutate(nd, gcost = ifelse(1:4 == i, 30, gcost))) nd <- bind_rows(nd) nd #>    individual choice wait vcost travel gcost income size  mode #> 1           1     no   35    48    486    30     35    2   air #> 2           1     no   35    48    486   111     35    2 train #> 3           1     no   35    48    486   111     35    2   bus #> 4           1     no   35    48    486   111     35    2   car #> 5           1     no   35    48    486   111     35    2   air #> 6           1     no   35    48    486    30     35    2 train #> 7           1     no   35    48    486   111     35    2   bus #> 8           1     no   35    48    486   111     35    2   car #> 9           1     no   35    48    486   111     35    2   air #> 10          1     no   35    48    486   111     35    2 train #> 11          1     no   35    48    486    30     35    2   bus #> 12          1     no   35    48    486   111     35    2   car #> 13          1     no   35    48    486   111     35    2   air #> 14          1     no   35    48    486   111     35    2 train #> 15          1     no   35    48    486   111     35    2   bus #> 16          1     no   35    48    486    30     35    2   car  avg_slopes(mod, newdata = nd, variables = c(\"income\", \"size\")) #>  #>  Group   Term  Estimate Std. Error      z Pr(>|z|)    S     2.5 %    97.5 % #>  air   income  8.24e-03   2.46e-03  3.352   <0.001 10.3  3.42e-03  0.013058 #>  bus   income -1.33e-03   1.30e-03 -1.020    0.308  1.7 -3.88e-03  0.001222 #>  car   income  2.66e-05   4.31e-05  0.617    0.537  0.9 -5.79e-05  0.000111 #>  train income -6.94e-03   1.86e-03 -3.735   <0.001 12.4 -1.06e-02 -0.003298 #>  air   size   -2.12e-01   6.02e-02 -3.526   <0.001 11.2 -3.31e-01 -0.094366 #>  bus   size    6.06e-02   3.79e-02  1.600    0.110  3.2 -1.37e-02  0.134911 #>  car   size    2.38e-03   1.57e-03  1.512    0.131  2.9 -7.04e-04  0.005459 #>  train size    1.49e-01   4.28e-02  3.489   <0.001 11.0  6.55e-02  0.233392 #>  #> Columns: group, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/comparisons.html","id":"simple-example-titanic","dir":"Articles","previous_headings":"","what":"Simple example: Titanic","title":"Comparisons","text":"Consider logistic regression model estimated using Titanic mortality data:","code":"library(marginaleffects)  dat <- \"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Titanic.csv\" dat <- read.csv(dat) dat$PClass[dat$PClass == \"*\"] <- NA mod <- glm(Survived ~ PClass * SexCode * Age, data = dat, family = binomial)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/comparisons.html","id":"step-1-quantity","dir":"Articles","previous_headings":"Simple example: Titanic","what":"Step 1: Quantity","title":"Comparisons","text":"question interests us : probability survival (outcome) change passenger travels 1st class vs. 3rd class? Since comparing two predicted outcomes, use comparisons(). indicate focal variable PClass interested comparison 1st 3rd class, use variables argument:","code":"comparisons(mod,   variables = list(PClass = c(\"1st\", \"3rd\"))) # Step 1: Quantity"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/comparisons.html","id":"step-2-grid","dir":"Articles","previous_headings":"Simple example: Titanic","what":"Step 2: Grid","title":"Comparisons","text":"GLM models, quantities interest conditional, sense typically depend values predictors model. Therefore, need decide predictor space want evaluate quantity interest described . default, comparisons() compute estimates every row original dataset used fit model. estimation made 756 observations titanic dataset. Therefore, just execute code previous section, obtain 756 estimates difference probability survival 3rd 1st class: Notice contrast 3rd 1st different row row. reflects fact , model, moving 1st 3rd different effect predicted probability survival different individuals. can specific query. Instead using empirical distribution “grid”, can specify exactly want evaluate comparison predictor space, using newdata argument datagrid() function. example, say interested : effect moving 1st 3rd class probability survival 50 year old man 50 year old woman. can type: now know moving 1st 3rd changes -0.184 probability survival 50 year old men (SexCode=0), -0.511 probability survival 50 year old women (SexCode=1).","code":"comparisons(mod,   variables = list(PClass = c(\"1st\", \"3rd\"))) # Step 1: Quantity #>  #>    Term  Contrast Estimate Std. Error     z Pr(>|z|)    S  2.5 % 97.5 % #>  PClass 3rd - 1st   -0.496     0.0610 -8.13  < 0.001 51.0 -0.616 -0.376 #>  PClass 3rd - 1st   -0.472     0.1247 -3.79  < 0.001 12.7 -0.716 -0.228 #>  PClass 3rd - 1st   -0.353     0.0641 -5.51  < 0.001 24.7 -0.478 -0.227 #>  PClass 3rd - 1st   -0.493     0.0583 -8.45  < 0.001 54.9 -0.607 -0.379 #>  PClass 3rd - 1st   -0.445     0.1452 -3.07  0.00216  8.9 -0.730 -0.161 #> --- 746 rows omitted. See ?avg_comparisons and ?print.marginaleffects ---  #>  PClass 3rd - 1st   -0.377     0.0703 -5.36  < 0.001 23.5 -0.515 -0.239 #>  PClass 3rd - 1st   -0.384     0.0726 -5.30  < 0.001 23.0 -0.527 -0.242 #>  PClass 3rd - 1st   -0.412     0.0821 -5.02  < 0.001 20.9 -0.573 -0.251 #>  PClass 3rd - 1st   -0.399     0.0773 -5.16  < 0.001 22.0 -0.550 -0.247 #>  PClass 3rd - 1st   -0.361     0.0661 -5.47  < 0.001 24.4 -0.490 -0.232 #> Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, Survived, PClass, SexCode, Age cmp <- comparisons(mod,   variables = list(PClass = c(\"1st\", \"3rd\")),  # Step 1: Quantity   newdata = datagrid(Age = 50, SexCode = 0:1)) # Step 2: Grid cmp #>  #>    Term  Contrast Estimate Std. Error     z Pr(>|z|)    S  2.5 %  97.5 % Age SexCode #>  PClass 3rd - 1st   -0.184     0.0535 -3.45   <0.001 10.8 -0.289 -0.0796  50       0 #>  PClass 3rd - 1st   -0.511     0.1242 -4.12   <0.001 14.7 -0.755 -0.2679  50       1 #>  #> Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, Survived, PClass, Age, SexCode"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/comparisons.html","id":"step-3-averaging","dir":"Articles","previous_headings":"Simple example: Titanic","what":"Step 3: Averaging","title":"Comparisons","text":", default comparisons() estimates quantities actually observed units dataset. Sometimes, convenient marginalize conditional estimates, order obtain “average contrast”: Alternatively, also take average, just two estimates computed 50 year old man 50 year old woman. Notice exactly average estimates previous section, stored cmp:","code":"avg_comparisons(mod,                          # Step 3: Average   variables = list(PClass = c(\"1st\", \"3rd\"))) # Step 1: Quantity #>  #>    Term  Contrast Estimate Std. Error    z Pr(>|z|)    S  2.5 % 97.5 % #>  PClass 3rd - 1st   -0.396     0.0425 -9.3   <0.001 66.0 -0.479 -0.312 #>  #> Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high avg_comparisons(mod,                           # Step 3: Average   variables = list(PClass = c(\"1st\", \"3rd\")),  # Step 1: Quantity   newdata = datagrid(Age = 50, SexCode = 0:1)) # Step 2: Grid #>  #>    Term  Contrast Estimate Std. Error     z Pr(>|z|)    S 2.5 % 97.5 % #>  PClass 3rd - 1st   -0.348     0.0676 -5.15   <0.001 21.8 -0.48 -0.215 #>  #> Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high cmp$estimate #> [1] -0.1844289 -0.5113098  mean(cmp$estimate) #> [1] -0.3478694"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/comparisons.html","id":"hypothesis","dir":"Articles","previous_headings":"Simple example: Titanic","what":"Hypothesis","title":"Comparisons","text":"Finally, imagine interested question: moving 1st 3rd class bigger effect probability survival 50 year old men, 50 year old women? answer , use hypothesis argument: result maps directly onto estimates . difference contrast 50-men 50-women: result can interpreted “difference--differences”: Moving 1st 3rd much larger negative effect probability survival 50 year old woman 50 year old man. difference statistically significant. can similar comparison, instead fixing conditional grid, can average subgroups empirical distribution, using argument:","code":"comparisons(mod,   variables = list(PClass = c(\"1st\", \"3rd\")),  # Step 1: Quantity   newdata = datagrid(Age = 50, SexCode = 0:1), # Step 2: Grid   hypothesis = \"b1 = b2\")                      # Step 4: Hypothesis #>  #>   Term Estimate Std. Error    z Pr(>|z|)   S  2.5 % 97.5 % #>  b1=b2    0.327      0.135 2.42   0.0156 6.0 0.0618  0.592 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high diff(cmp$estimate) #> [1] -0.3268809 avg_comparisons(mod,   variables = list(PClass = c(\"1st\", \"3rd\")),  # Step 1: Quantity   by = \"SexCode\",                              # Step 3: Average   hypothesis = \"b1 = b2\")                      # Step 4: Hypothesis #>  #>   Term Estimate Std. Error     z Pr(>|z|)   S  2.5 %  97.5 % #>  b1=b2   -0.162     0.0845 -1.91   0.0558 4.2 -0.327 0.00402 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/comparisons.html","id":"manual-computation","dir":"Articles","previous_headings":"Simple example: Titanic","what":"Manual computation","title":"Comparisons","text":"Now show use base R predict() function compute quantities . exercise may clarifying users.","code":"grid_50_1_3 <- data.frame(Age = 50, SexCode = 1, PClass = \"3rd\") grid_50_1_1 <- data.frame(Age = 50, SexCode = 1, PClass = \"1st\") grid_50_0_3 <- data.frame(Age = 50, SexCode = 0, PClass = \"3rd\") grid_50_0_1 <- data.frame(Age = 50, SexCode = 0, PClass = \"1st\")   yhat_50_1_3 <- predict(mod, newdata = grid_50_1_3, type = \"response\") yhat_50_1_1 <- predict(mod, newdata = grid_50_1_1, type = \"response\") yhat_50_0_3 <- predict(mod, newdata = grid_50_0_3, type = \"response\") yhat_50_0_1 <- predict(mod, newdata = grid_50_0_1, type = \"response\")  # prediction on a grid predictions(mod, newdata = datagrid(Age = 50, SexCode = 1, PClass = \"3rd\")) #>  #>  Estimate Pr(>|z|)   S 2.5 % 97.5 % Age SexCode PClass #>     0.446    0.661 0.6 0.235  0.679  50       1    3rd #>  #> Columns: rowid, estimate, p.value, s.value, conf.low, conf.high, Survived, Age, SexCode, PClass yhat_50_1_3 #>         1  #> 0.4463379  # contrast on a grid comparisons(mod,   variables = list(PClass = c(\"1st\", \"3rd\")),   newdata = datagrid(Age = 50, SexCode = 0:1)) #>  #>    Term  Contrast Estimate Std. Error     z Pr(>|z|)    S  2.5 %  97.5 % Age SexCode #>  PClass 3rd - 1st   -0.184     0.0535 -3.45   <0.001 10.8 -0.289 -0.0796  50       0 #>  PClass 3rd - 1st   -0.511     0.1242 -4.12   <0.001 14.7 -0.755 -0.2679  50       1 #>  #> Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, Survived, PClass, Age, SexCode  yhat_50_0_3 - yhat_50_0_1 #>          1  #> -0.1844289 yhat_50_1_3 - yhat_50_1_1 #>          1  #> -0.5113098  # difference-in-differences  comparisons(mod,   variables = list(PClass = c(\"1st\", \"3rd\")),   newdata = datagrid(Age = 50, SexCode = 0:1),   hypothesis = \"b1 = b2\") #>  #>   Term Estimate Std. Error    z Pr(>|z|)   S  2.5 % 97.5 % #>  b1=b2    0.327      0.135 2.42   0.0156 6.0 0.0618  0.592 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  (yhat_50_0_3 - yhat_50_0_1) - (yhat_50_1_3 - yhat_50_1_1) #>         1  #> 0.3268809  # average of the empirical distribution of contrasts avg_comparisons(mod, variables = list(PClass = c(\"1st\", \"3rd\")), by = \"SexCode\") #>  #>    Term              Contrast SexCode Estimate Std. Error     z Pr(>|z|)    S  2.5 % 97.5 % #>  PClass mean(3rd) - mean(1st)       1   -0.496     0.0623 -7.95   <0.001 49.0 -0.618 -0.374 #>  PClass mean(3rd) - mean(1st)       0   -0.334     0.0570 -5.86   <0.001 27.7 -0.446 -0.222 #>  #> Columns: term, contrast, SexCode, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo  grid_empirical_1_3 <- dat |> subset(SexCode == 1) |> transform(PClass = \"3rd\") grid_empirical_1_1 <- dat |> subset(SexCode == 1) |> transform(PClass = \"1st\") grid_empirical_0_3 <- dat |> subset(SexCode == 0) |> transform(PClass = \"3rd\") grid_empirical_0_1 <- dat |> subset(SexCode == 0) |> transform(PClass = \"1st\") yhat_empirical_0_1 <- predict(mod, newdata = grid_empirical_0_1, type = \"response\") yhat_empirical_0_3 <- predict(mod, newdata = grid_empirical_0_3, type = \"response\") yhat_empirical_1_1 <- predict(mod, newdata = grid_empirical_1_1, type = \"response\") yhat_empirical_1_3 <- predict(mod, newdata = grid_empirical_1_3, type = \"response\") mean(yhat_empirical_0_3, na.rm = TRUE) - mean(yhat_empirical_0_1, na.rm = TRUE) #> [1] -0.3341426 mean(yhat_empirical_1_3, na.rm = TRUE) - mean(yhat_empirical_1_1, na.rm = TRUE) #> [1] -0.4956673"},{"path":[]},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/comparisons.html","id":"logical-and-factor-predictors","dir":"Articles","previous_headings":"Predictor types","what":"Logical and factor predictors","title":"Comparisons","text":"Consider simple model logical factor variable: comparisons function automatically computes contrasts level categorical variables, relative baseline category (FALSE logicals, reference level factors), holding values observed values. avg_comparisons() , marginalizes taking average unit-level estimates: summary printed says moving reference category 4 level 6 cyl factor variable associated change -6.156 adjusted prediction. Similarly, contrast FALSE TRUE variable equal 2.560. can obtain different contrasts using comparisons() function. example: comparison, code produces results using emmeans package: Note commands also work types models, GLMs, different scales:","code":"library(marginaleffects)  tmp <- mtcars tmp$am <- as.logical(tmp$am) mod <- lm(mpg ~ am + factor(cyl), tmp) cmp <- avg_comparisons(mod) cmp #>  #>  Term     Contrast Estimate Std. Error     z Pr(>|z|)    S    2.5 % 97.5 % #>   am  TRUE - FALSE     2.56       1.30  1.97   0.0485  4.4   0.0167   5.10 #>   cyl 6 - 4           -6.16       1.54 -4.01   <0.001 14.0  -9.1661  -3.15 #>   cyl 8 - 4          -10.07       1.45 -6.93   <0.001 37.8 -12.9136  -7.22 #>  #> Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high avg_comparisons(mod, variables = list(cyl = \"sequential\")) #>  #>  Term Contrast Estimate Std. Error     z Pr(>|z|)    S 2.5 % 97.5 % #>   cyl    6 - 4    -6.16       1.54 -4.01  < 0.001 14.0 -9.17  -3.15 #>   cyl    8 - 6    -3.91       1.47 -2.66  0.00781  7.0 -6.79  -1.03 #>  #> Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  avg_comparisons(mod, variables = list(cyl = \"pairwise\")) #>  #>  Term Contrast Estimate Std. Error     z Pr(>|z|)    S  2.5 % 97.5 % #>   cyl    6 - 4    -6.16       1.54 -4.01  < 0.001 14.0  -9.17  -3.15 #>   cyl    8 - 4   -10.07       1.45 -6.93  < 0.001 37.8 -12.91  -7.22 #>   cyl    8 - 6    -3.91       1.47 -2.66  0.00781  7.0  -6.79  -1.03 #>  #> Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  avg_comparisons(mod, variables = list(cyl = \"reference\")) #>  #>  Term Contrast Estimate Std. Error     z Pr(>|z|)    S  2.5 % 97.5 % #>   cyl    6 - 4    -6.16       1.54 -4.01   <0.001 14.0  -9.17  -3.15 #>   cyl    8 - 4   -10.07       1.45 -6.93   <0.001 37.8 -12.91  -7.22 #>  #> Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high library(emmeans) emm <- emmeans(mod, specs = \"cyl\") contrast(emm, method = \"revpairwise\") #>  contrast    estimate   SE df t.ratio p.value #>  cyl6 - cyl4    -6.16 1.54 28  -4.009  0.0012 #>  cyl8 - cyl4   -10.07 1.45 28  -6.933  <.0001 #>  cyl8 - cyl6    -3.91 1.47 28  -2.660  0.0331 #>  #> Results are averaged over the levels of: am  #> P value adjustment: tukey method for comparing a family of 3 estimates  emm <- emmeans(mod, specs = \"am\") contrast(emm, method = \"revpairwise\") #>  contrast     estimate  SE df t.ratio p.value #>  TRUE - FALSE     2.56 1.3 28   1.973  0.0585 #>  #> Results are averaged over the levels of: cyl mod_logit <- glm(am ~ factor(gear), data = mtcars, family = binomial)  avg_comparisons(mod_logit) #>  #>  Term Contrast Estimate Std. Error       z Pr(>|z|)    S 2.5 % 97.5 % #>  gear    4 - 3    0.667   1.36e-01     4.9   <0.001 20.0   0.4  0.933 #>  gear    5 - 3    1.000   1.07e-05 93380.2   <0.001  Inf   1.0  1.000 #>  #> Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  avg_comparisons(mod_logit, type = \"link\") #>  #>  Term Contrast Estimate Std. Error       z Pr(>|z|)   S  2.5 % 97.5 % #>  gear    4 - 3     21.3       4578 0.00464    0.996 0.0  -8951   8994 #>  gear    5 - 3     41.1       9156 0.00449    0.996 0.0 -17904  17986 #>  #> Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/comparisons.html","id":"character-predictors","dir":"Articles","previous_headings":"Predictor types","what":"Character predictors","title":"Comparisons","text":"functions marginaleffects package attempt treat character predictors factor predictors. However, using factors instead characters modeling strongly encouraged, much safer faster. factors hold useful information full list levels, makes easier track handle internally marginaleffects. Users strongly encouraged convert character variables factor fitting models using slopes functions.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/comparisons.html","id":"numeric-predictors","dir":"Articles","previous_headings":"Predictor types","what":"Numeric predictors","title":"Comparisons","text":"can also compute contrasts differences numeric variables. example, can compare adjusted predictions across change regressor two arbitrary values: can also easily compare adjusted predictions regressor changes across interquartile range, across one two standard deviations mean, across full range: provided two values hp variable previous numeric predictor examples, can also specify single value. passing two values produces comparison adjusted predictions assuming unit-level rows take one two values, function’s default behavior passed single value compare adjusted predictions regressor changes specified, constant number units. example, can compare adjusted predictions increment hp variable 1 unit (default) 5 units: comparisons() function computes “centered” difference default, actually computes effect incrementation hp - 0.5 hp + 0.5 hp - 2.5 hp + 2.5 rather hp hp + 1 hp hp + 5. discussion default alternative centering, see section vignette “Forward, Backward, Centered, Custom Differences.”","code":"mod <- lm(mpg ~ hp, data = mtcars)  avg_comparisons(mod, variables = list(hp = c(90, 110))) #>  #>  Term Contrast Estimate Std. Error     z Pr(>|z|)    S 2.5 % 97.5 % #>    hp 110 - 90    -1.36      0.202 -6.74   <0.001 35.9 -1.76 -0.968 #>  #> Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high avg_comparisons(mod, variables = list(hp = \"iqr\")) #>  #>  Term Contrast Estimate Std. Error     z Pr(>|z|)    S 2.5 % 97.5 % #>    hp  Q3 - Q1     -5.7      0.845 -6.74   <0.001 35.9 -7.35  -4.04 #>  #> Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  avg_comparisons(mod, variables = list(hp = \"sd\")) #>  #>  Term                Contrast Estimate Std. Error     z Pr(>|z|)    S 2.5 % 97.5 % #>    hp (x + sd/2) - (x - sd/2)    -4.68      0.694 -6.74   <0.001 35.9 -6.04  -3.32 #>  #> Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  avg_comparisons(mod, variables = list(hp = \"2sd\")) #>  #>  Term            Contrast Estimate Std. Error     z Pr(>|z|)    S 2.5 % 97.5 % #>    hp (x + sd) - (x - sd)    -9.36       1.39 -6.74   <0.001 35.9 -12.1  -6.64 #>  #> Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  avg_comparisons(mod, variables = list(hp = \"minmax\")) #>  #>  Term  Contrast Estimate Std. Error     z Pr(>|z|)    S 2.5 % 97.5 % #>    hp Max - Min    -19.3       2.86 -6.74   <0.001 35.9 -24.9  -13.7 #>  #> Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high avg_comparisons(mod) #>  #>  Term Contrast Estimate Std. Error     z Pr(>|z|)    S   2.5 %  97.5 % #>    hp       +1  -0.0682     0.0101 -6.74   <0.001 35.9 -0.0881 -0.0484 #>  #> Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  avg_comparisons(mod, variables = list(hp = 5)) #>  #>  Term Contrast Estimate Std. Error     z Pr(>|z|)    S 2.5 % 97.5 % #>    hp       +5   -0.341     0.0506 -6.74   <0.001 35.9 -0.44 -0.242 #>  #> Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/comparisons.html","id":"interactions-and-cross-contrasts","dir":"Articles","previous_headings":"","what":"Interactions and Cross-Contrasts","title":"Comparisons","text":"contexts interested whether “effect” variable changes, function another variable. simple strategy tackle question estimate model multiplicative interaction like one: Calling avg_comparisons() argument shows estimated comparisons differ based cyl: However, using hypothesis argument pairwise contrasts comparisons reveals heterogeneity statistically significant: contexts, interested “cross-contrast” “cross-comparisons”; like know happens two () predictors change time. assess , can specify regressors interest variables argument, set cross=TRUE:","code":"mod <- lm(mpg ~ am * factor(cyl), data = mtcars) avg_comparisons(mod, variables = \"am\", by = \"cyl\") #>  #>  Term          Contrast cyl Estimate Std. Error     z Pr(>|z|)   S 2.5 % 97.5 % #>    am mean(1) - mean(0)   6     1.44       2.32 0.623   0.5336 0.9 -3.10   5.98 #>    am mean(1) - mean(0)   4     5.18       2.05 2.521   0.0117 6.4  1.15   9.20 #>    am mean(1) - mean(0)   8     0.35       2.32 0.151   0.8799 0.2 -4.19   4.89 #>  #> Columns: term, contrast, cyl, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo avg_comparisons(mod, variables = \"am\", by = \"cyl\", hypothesis = \"pairwise\") #>  #>   Term Estimate Std. Error      z Pr(>|z|)   S 2.5 % 97.5 % #>  6 - 4    -3.73       3.09 -1.206    0.228 2.1 -9.80   2.33 #>  6 - 8     1.09       3.28  0.333    0.739 0.4 -5.33   7.51 #>  4 - 8     4.82       3.09  1.559    0.119 3.1 -1.24  10.89 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high avg_comparisons(mod, variables = c(\"cyl\", \"am\"), cross = TRUE) #>  #>  C: cyl C: am Estimate Std. Error      z Pr(>|z|)   S  2.5 % 97.5 % #>   6 - 4 1 - 0    -2.33       2.48 -0.942  0.34596 1.5  -7.19   2.52 #>   8 - 4 1 - 0    -7.50       2.77 -2.709  0.00674 7.2 -12.93  -2.07 #>  #> Columns: term, contrast_cyl, contrast_am, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/comparisons.html","id":"quantities-of-interest","dir":"Articles","previous_headings":"","what":"Quantities of interest","title":"Comparisons","text":"section compares 4 quantities: Unit-Level Contrasts Average Contrast Contrast Mean Contrast Marginal Means ideas discussed section focus contrasts, carry directly analogous types marginal effects.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/comparisons.html","id":"unit-level-contrasts","dir":"Articles","previous_headings":"Quantities of interest","what":"Unit-level contrasts","title":"Comparisons","text":"models interactions non-linear components (e.g., link function), value contrast marginal effect can depend value predictors model. result, contrasts marginal effects fundamentally unit-level quantities. effect 1 unit increase \\(X\\) can different Mary John. Every row dataset different contrast marginal effect. mtcars dataset 32 rows, comparisons() function produces 32 contrast estimates:","code":"library(marginaleffects) mod <- glm(vs ~ factor(gear) + mpg, family = binomial, data = mtcars) cmp <- comparisons(mod, variables = \"mpg\") nrow(cmp) #> [1] 32"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/comparisons.html","id":"average-contrasts","dir":"Articles","previous_headings":"Quantities of interest","what":"Average contrasts","title":"Comparisons","text":"default, slopes() comparisons() functions compute marginal effects contrasts every row original dataset. unit-level estimates can great interest, discussed another vignette. Nevertheless, one may want focus one-number summaries: avg_*() functions argument compute “Average Marginal Effect” “Average Contrast,” taking mean unit-level estimates. equivalent : also show full distribution contrasts across dataset histogram:  graph display effect change 1 unit mpg variable, individual observed data.","code":"avg_comparisons(mod, variables = \"mpg\") #>  #>  Term Contrast Estimate Std. Error    z Pr(>|z|)    S  2.5 % 97.5 % #>   mpg       +1   0.0608     0.0128 4.74   <0.001 18.8 0.0356  0.086 #>  #> Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  comparisons(mod, variables = \"mpg\", by = TRUE) #>  #>  Term Contrast Estimate Std. Error    z Pr(>|z|)    S  2.5 % 97.5 % #>   mpg       +1   0.0608     0.0128 4.74   <0.001 18.8 0.0356  0.086 #>  #> Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high mean(cmp$estimate) #> [1] 0.06080995 library(ggplot2)  cmp <- comparisons(mod, variables = \"gear\")  ggplot(cmp, aes(estimate)) +     geom_histogram(bins = 30) +     facet_wrap(~contrast, scale = \"free_x\") +     labs(x = \"Distribution of unit-level contrasts\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/comparisons.html","id":"contrasts-at-the-mean","dir":"Articles","previous_headings":"Quantities of interest","what":"Contrasts at the mean","title":"Comparisons","text":"alternative used common now fallen bit disfavor compute “Contrasts mean.” idea create “synthetic” “hypothetical” individual (row dataset) whose characteristics completely average. , compute report contrast specific hypothetical individual. can achieved setting newdata=\"mean\" newdata=datagrid(), fix variables means modes: Contrasts mean can differ substantially average contrasts. advantage approach cheap fast computationally. disadvantage interpretation somewhat ambiguous. Often times, simply exist individual perfectly average across dimensions dataset. also clear analyst particularly interested contrast one, synthetic, perfectly average individual.","code":"comparisons(mod, variables = \"mpg\", newdata = \"mean\") #>  #>  Term Contrast Estimate Std. Error    z Pr(>|z|)   S  2.5 % 97.5 % #>   mpg       +1    0.166     0.0627 2.65  0.00794 7.0 0.0436  0.289 #>  #> Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, vs, gear, mpg"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/comparisons.html","id":"contrasts-between-marginal-means","dir":"Articles","previous_headings":"Quantities of interest","what":"Contrasts between marginal means","title":"Comparisons","text":"Yet another type contrast “Contrast marginal means.” type contrast closely related “Contrast mean”, wrinkles. default approach used emmeans package R. Roughly speaking, procedure follows: Create prediction grid one cell combination categorical predictors model, numeric variables held means. Make adjusted predictions cell prediction grid. Take average predictions (marginal means) combination btype (focal variable) resp (group variable). Compute pairwise differences (contrasts) marginal means across different levels focal variable btype. contrast obtained approach two critical characteristics: contrast synthetic individual perfectly average qualities every (numeric) predictor. weighted average unit-level contrasts, weights assume perfectly balanced dataset across every categorical predictor. respect (), analyst ask : quantity interest contrast perfectly average hypothetical individual? respect (b), analyst ask : quantity interest contrast model estimated using (potentially) unbalanced data, interpreted data perfectly balanced? example, imagine one control variables model variable measuring educational attainment 4 categories: high school, High school, college, Completed college. contrast marginal means weighted average contrasts estimated 4 cells, contrasts weighted equally overall estimate. population interest highly unbalanced educational categories, estimate computed way useful. contrasts marginal means really quantity interest, easy use comparisons() estimate contrasts marginal means. newdata determines values predictors want compute contrasts. can set newdata=\"marginalmeans\" emulate emmeans behavior. example, compute contrasts model interaction: equivalent emmeans: emmeans section Alternative Software vignette shows examples. excellent vignette emmeans package discuss issues slightly different (positive) way: point marginal means cell.means give equal weight cell. many situations (especially experimental data), much fairer way compute marginal means, biased imbalances data. , sense, estimating marginal means , experiment balanced. Estimated marginal means (EMMs) serve need. said, certainly situations equal weighting appropriate. Suppose, example, data sales product given different packaging features. data unbalanced customers attracted combinations others. goal understand scientifically packaging features inherently profitable, equally weighted EMMs may appropriate; goal predict maximize profit, ordinary marginal means provide better estimates can expect marketplace.","code":"dat <- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\") mod <- lm(bill_length_mm ~ species * sex + island + body_mass_g, data = dat)  avg_comparisons(     mod,     newdata = \"marginalmeans\",     variables = c(\"species\", \"island\")) #>  #>     Term           Contrast Estimate Std. Error      z Pr(>|z|)     S  2.5 % 97.5 % #>  species Chinstrap - Adelie  10.2693      0.407 25.252   <0.001 465.0  9.472 11.066 #>  species Gentoo - Adelie      5.8957      0.677  8.705   <0.001  58.1  4.568  7.223 #>  island  Dream - Biscoe      -0.4557      0.453 -1.005    0.315   1.7 -1.344  0.433 #>  island  Torgersen - Biscoe   0.0851      0.470  0.181    0.856   0.2 -0.836  1.006 #>  #> Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high emm <- emmeans(     mod,     specs = c(\"species\", \"island\")) contrast(emm, method = \"trt.vs.ctrl1\") #>  contrast                            estimate    SE  df t.ratio p.value #>  Chinstrap Biscoe - Adelie Biscoe     10.2693 0.407 324  25.252  <.0001 #>  Gentoo Biscoe - Adelie Biscoe         5.8957 0.677 324   8.705  <.0001 #>  Adelie Dream - Adelie Biscoe         -0.4557 0.453 324  -1.005  0.8274 #>  Chinstrap Dream - Adelie Biscoe       9.8136 0.434 324  22.630  <.0001 #>  Gentoo Dream - Adelie Biscoe          5.4400 0.941 324   5.779  <.0001 #>  Adelie Torgersen - Adelie Biscoe      0.0851 0.470 324   0.181  0.9994 #>  Chinstrap Torgersen - Adelie Biscoe  10.3544 0.622 324  16.656  <.0001 #>  Gentoo Torgersen - Adelie Biscoe      5.9808 0.954 324   6.268  <.0001 #>  #> Results are averaged over the levels of: sex  #> P value adjustment: dunnettx method for 8 tests"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/comparisons.html","id":"conditional-contrasts","dir":"Articles","previous_headings":"","what":"Conditional contrasts","title":"Comparisons","text":"Consider model interaction term. happens dependent variable hp variable increases 10 units?","code":"library(marginaleffects)  mod <- lm(mpg ~ hp * wt, data = mtcars)  plot_comparisons(     mod,     variables = list(hp = 10),     condition = \"wt\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/comparisons.html","id":"transformations","dir":"Articles","previous_headings":"","what":"Transformations","title":"Comparisons","text":"far focused simple differences adjusted predictions. Now, show use ratios, back transformations, arbitrary functions estimate slew quantities interest. Powerful transformations custom contrasts made possible using three arguments act different stages computation process: comparison transform Consider case model single predictor \\(x\\). compute average contrasts, proceed follows: Compute adjusted predictions row dataset observed values \\(x\\): \\(\\hat{y}_x\\) Compute adjusted predictions row dataset observed values \\(x + 1\\): \\(\\hat{y}_{x+1}\\) comparison: Compute unit-level contrasts taking difference (function ) adjusted predictions: \\(\\hat{y}_{x+1} - \\hat{y}_x\\) Compute average contrast taking mean unit-level contrasts: \\(1/N \\sum_{=1}^N \\hat{y}_{x+1} - \\hat{y}_x\\) transform: Transform average contrast return -. comparison argument comparisons() function determines adjusted predictions combined create contrast. default, take simple difference predictions hi value \\(x\\), predictions lo value \\(x\\): function(hi, lo) hi-lo. transform argument comparisons() function applies custom transformation unit-level contrasts. transform argument applies custom transformation final quantity, returned evaluated call without transform.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/comparisons.html","id":"differences","dir":"Articles","previous_headings":"","what":"Differences","title":"Comparisons","text":"default contrast calculated comparisons() function (untransformed) difference two adjusted predictions. instance, estimate effect change 1 unit, : can use avg_comparisons() function , argument obtain results:","code":"library(marginaleffects)  mod <- glm(vs ~ mpg, data = mtcars, family = binomial)  # construct data  mtcars_minus <- mtcars_plus <- mtcars mtcars_minus$mpg <- mtcars_minus$mpg - 0.5 mtcars_plus$mpg <- mtcars_plus$mpg + 0.5  # adjusted predictions yhat_minus <- predict(mod, newdata = mtcars_minus, type = \"response\") yhat_plus <- predict(mod, newdata = mtcars_plus, type = \"response\")  # unit-level contrasts con <- yhat_plus - yhat_minus  # average contrasts mean(con) #> [1] 0.05540227 avg_comparisons(mod) #>  #>  Term Contrast Estimate Std. Error    z Pr(>|z|)    S  2.5 % 97.5 % #>   mpg       +1   0.0554    0.00834 6.64   <0.001 34.9 0.0391 0.0717 #>  #> Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  comparisons(mod, by = TRUE) #>  #>  Term Contrast Estimate Std. Error    z Pr(>|z|)    S  2.5 % 97.5 % #>   mpg       +1   0.0554    0.00834 6.64   <0.001 34.9 0.0391 0.0717 #>  #> Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/comparisons.html","id":"difference-in-differences-in-differences","dir":"Articles","previous_headings":"","what":"Difference-in-Differences(-in-Differences)","title":"Comparisons","text":"Going back Titanic example: case, contrast difference predicted probabilities. can compute contrast different types individuals: One can notice , gap predicted probabilities survival men women larger 1st class 3rd class. woman matters chances survival travel first class. difference contrasts (diff--diff) statistically significant? answer question, can compute difference--difference using hypothesis argument (see Hypothesis vignette details). example, using b1 b2 refer contrasts first second rows output , can test difference two quantities different 0: Now, let’s say consider types individuals: results, compute triple difference:","code":"dat <- \"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Titanic.csv\" dat <- read.csv(dat) titanic <- glm(Survived ~ PClass * SexCode * Age, data = dat, family = binomial) comparisons(   titanic,   variables = \"SexCode\",   newdata = datagrid(PClass = c(\"1st\", \"3rd\"))) #>  #>     Term Contrast Estimate Std. Error    z Pr(>|z|)    S 2.5 % 97.5 %  Age PClass #>  SexCode    1 - 0    0.483     0.0631 7.65   <0.001 45.5 0.359  0.606 30.4    1st #>  SexCode    1 - 0    0.335     0.0634 5.29   <0.001 22.9 0.211  0.459 30.4    3rd #>  #> Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, Survived, SexCode, Age, PClass comparisons(   titanic,   hypothesis = \"b1 - b2 = 0\",   variables = \"SexCode\",   newdata = datagrid(PClass = c(\"1st\", \"3rd\"))) #>  #>     Term Estimate Std. Error    z Pr(>|z|)   S   2.5 % 97.5 % #>  b1-b2=0    0.148     0.0894 1.65   0.0987 3.3 -0.0276  0.323 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high comparisons(   titanic,   variables = \"SexCode\",   newdata = datagrid(PClass = c(\"1st\", \"3rd\"), Age = range)) #>  #>     Term Contrast Estimate Std. Error      z Pr(>|z|)     S   2.5 % 97.5 % PClass   Age #>  SexCode    1 - 0   0.1081      0.122  0.883   0.3774   1.4 -0.1319  0.348    1st  0.17 #>  SexCode    1 - 0   0.8795      0.057 15.437   <0.001 176.2  0.7679  0.991    1st 71.00 #>  SexCode    1 - 0   0.0805      0.157  0.513   0.6081   0.7 -0.2272  0.388    3rd  0.17 #>  SexCode    1 - 0   0.4265      0.203  2.101   0.0356   4.8  0.0287  0.824    3rd 71.00 #>  #> Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, Survived, SexCode, PClass, Age comparisons(   titanic,   hypothesis = \"(b1 - b3) - (b2 - b4) = 0\",   variables = \"SexCode\",   newdata = datagrid(PClass = c(\"1st\", \"3rd\"), Age = range)) #>  #>               Term Estimate Std. Error     z Pr(>|z|)   S 2.5 % 97.5 % #>  (b1-b3)-(b2-b4)=0   -0.425      0.359 -1.19    0.236 2.1 -1.13  0.278 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/comparisons.html","id":"ratios","dir":"Articles","previous_headings":"","what":"Ratios","title":"Comparisons","text":"Instead taking simple differences adjusted predictions, can sometimes useful compute ratios functions predictions. example, adjrr function Stata software package can compute “adjusted risk ratios”, ratios adjusted predictions. R, use comparison argument: result average adjusted risk ratio, , adjusted predictions mpg incremented 1, divided adjusted predictions mpg original value. comparison accepts different values common types contrasts: ‘difference’, ‘ratio’, ‘lnratio’, ‘ratioavg’, ‘lnratioavg’, ‘lnoravg’, ‘differenceavg’. strings shortcuts functions accept two vectors adjusted predictions returns single vector contrasts. example, two commands yield identical results: mechanism powerful, lets users create fully customized contrasts. non-sensical example: arguments work plotting function plot_comparisons() well, allows us plot various custom contrasts. comparison Adjusted Risk Ratio Adjusted Risk Difference model probability survival aboard Titanic:  default, standard errors around contrasts computed using delta method scale determined type argument (e.g., “link” “response”). analysts may prefer proceed differently. example, Stata, adjrr computes adjusted risk ratios (ARR) two steps: Compute natural log ratio mean adjusted predictions \\(x+1\\) mean adjusted predictions \\(x\\). Exponentiate estimate confidence interval bounds. Step 1 easy achieve comparison argument described . Step 2 can achieved transform argument: Note equivalent results can obtained using shortcut strings comparison argument: “ratio”, “lnratio”, “lnratioavg”. arguments apply plotting functions marginaleffects package well. example can plot Adjusted Risk Ratio model quadratic term:","code":"avg_comparisons(mod, comparison = \"ratio\") #>  #>  Term Contrast Estimate Std. Error   z Pr(>|z|)    S 2.5 % 97.5 % #>   mpg       +1     1.29      0.133 9.7   <0.001 71.4  1.03   1.55 #>  #> Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high avg_comparisons(mod, comparison = \"ratio\") #>  #>  Term Contrast Estimate Std. Error   z Pr(>|z|)    S 2.5 % 97.5 % #>   mpg       +1     1.29      0.133 9.7   <0.001 71.4  1.03   1.55 #>  #> Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  avg_comparisons(mod, comparison = function(hi, lo) hi / lo) #>  #>  Term Contrast Estimate Std. Error   z Pr(>|z|)    S 2.5 % 97.5 % #>   mpg       +1     1.29      0.133 9.7   <0.001 71.4  1.03   1.55 #>  #> Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high avg_comparisons(mod, comparison = function(hi, lo) sqrt(hi) / log(lo + 10)) #>  #>  Term Contrast Estimate Std. Error    z Pr(>|z|)    S 2.5 % 97.5 % #>   mpg       +1    0.264     0.0261 10.1   <0.001 77.3 0.213  0.315 #>  #> Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high library(ggplot2) library(patchwork) titanic <- \"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Titanic.csv\" titanic <- read.csv(titanic) mod_titanic <- glm(     Survived ~ Sex * PClass + Age + I(Age^2),     family = binomial,     data = titanic)  avg_comparisons(mod_titanic) #>  #>    Term      Contrast Estimate Std. Error      z Pr(>|z|)     S    2.5 %   97.5 % #>  Sex    male - female  -0.4847    0.03004 -16.14   <0.001 192.2 -0.54355 -0.42580 #>  PClass 2nd - 1st      -0.2058    0.03954  -5.20   <0.001  22.3 -0.28328 -0.12828 #>  PClass 3rd - 1st      -0.4043    0.03958 -10.21   <0.001  78.9 -0.48187 -0.32670 #>  Age    +1             -0.0065    0.00108  -6.03   <0.001  29.2 -0.00862 -0.00439 #>  #> Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  p1 <- plot_comparisons(     mod_titanic,     variables = \"Age\",     condition = \"Age\",     comparison = \"ratio\") +     ylab(\"Adjusted Risk Ratio\\nP(Survival | Age + 1) / P(Survival | Age)\")  p2 <- plot_comparisons(     mod_titanic,     variables = \"Age\",     condition = \"Age\") +     ylab(\"Adjusted Risk Difference\\nP(Survival | Age + 1) - P(Survival | Age)\")  p1 + p2 avg_comparisons(     mod,     comparison = function(hi, lo) log(hi / lo),     transform = exp) #>  #>  Term Contrast Estimate Pr(>|z|)   S 2.5 % 97.5 % #>   mpg       +1     1.27  0.00936 6.7  1.06   1.53 #>  #> Columns: term, contrast, estimate, p.value, s.value, conf.low, conf.high comparisons(     mod,     comparison = \"lnratioavg\",     transform = exp) #>  #>  Term Contrast Estimate Pr(>|z|)    S 2.5 % 97.5 % #>   mpg mean(+1)     1.14   <0.001 31.9  1.09   1.18 #>  #> Columns: term, contrast, estimate, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo library(ggplot2) dat_titanic <- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Titanic.csv\") mod2 <- glm(Survived  ~ Age, data = dat_titanic, family = binomial) plot_comparisons(     mod2,     variables = list(\"Age\" = 10),     condition = \"Age\",     comparison = \"ratio\") +     ylab(\"Adjusted Risk Ratio\\nP(Survived = 1 | Age + 10) / P(Survived = 1 | Age)\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/comparisons.html","id":"forward-backward-centered-and-custom-differences","dir":"Articles","previous_headings":"","what":"Forward, Backward, Centered, and Custom Differences","title":"Comparisons","text":"default, comparisons() function computes “centered” difference. example, ask comparisons() estimate effect 10-unit change predictor x outcome y, comparisons() compare predicted values x-5 x+5. Since version 0.7.2 marginaleffects, can supply arbitrary functions create custom differences. functions must accept vector values predictor interest, return data frame number rows length, two columns values compare. example, can : Notice last “centered” difference gives results default comparisons() call.","code":"dat <- mtcars dat$new_hp <- 49 * (mtcars$hp - min(mtcars$hp)) / (max(mtcars$hp) - min(mtcars$hp)) + 1 mod <- lm(mpg ~ log(new_hp), data = dat)  avg_comparisons(   mod,   variables = list(new_hp = 10)) #>  #>    Term Contrast Estimate Std. Error     z Pr(>|z|)    S 2.5 % 97.5 % #>  new_hp      +10    -4.06      0.464 -8.74   <0.001 58.6 -4.97  -3.15 #>  #> Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high forward_diff <- \\(x) data.frame(x, x + 10) backward_diff <- \\(x) data.frame(x - 10, x) center_diff <- \\(x) data.frame(x - 5, x + 5)  avg_comparisons(   mod,   variables = list(new_hp = forward_diff)) #>  #>    Term Contrast Estimate Std. Error     z Pr(>|z|)    S 2.5 % 97.5 % #>  new_hp   custom     -3.8      0.435 -8.74   <0.001 58.6 -4.65  -2.95 #>  #> Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  avg_comparisons(   mod,   variables = list(new_hp = backward_diff)) #>  #>    Term Contrast Estimate Std. Error     z Pr(>|z|)    S 2.5 % 97.5 % #>  new_hp   custom    -6.51      0.744 -8.74   <0.001 58.6 -7.97  -5.05 #>  #> Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  avg_comparisons(   mod,   variables = list(new_hp = center_diff)) #>  #>    Term Contrast Estimate Std. Error     z Pr(>|z|)    S 2.5 % 97.5 % #>  new_hp   custom    -4.06      0.464 -8.74   <0.001 58.6 -4.97  -3.15 #>  #> Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/comparisons.html","id":"lognormal-hurdle-model","dir":"Articles","previous_headings":"","what":"Lognormal hurdle model","title":"Comparisons","text":"hurdle models, can fit two separate models simultaneously: model predicts outcome zero zero outcome zero, model predicts value outcome can calculate predictions marginal effects hurdle model processes, requires variable transformation since stages models use different link functions. hurdle_lognormal() family brms uses logistic regression (logit link) hurdle part model lognormal regression (outcome logged getting used model) non-hurdled part. Let’s look example predicting GDP per capita (distributed exponentially) using life expectancy. ’ll add artificial zeros can work hurdle stage model. two different sets coefficients two different processes. hurdle part (hu) uses logit link, non-hurdle part (mu) uses identity link. However, ’s slight misnomer—true identity link show coefficients non-logged dollar value scale. ’re using lognormal family, GDP per capita pre-logged, “original” identity scale actually logged dollars. can get predictions hu part model link (logit) scale: …response (percentage point) scale: can also get slopes hu part model link (logit) response (percentage point) scales: Working mu part model trickier. Switching type = \"link\" type = \"response\" doesn’t change anything, since outcome pre-logged: predictions, need exponentiate results scale back dollar amounts. can post-processing results (e.g. dplyr::mutate(predicted = exp(predicted))), can use transform argument predictions() pass results exp() getting calculated: can pass transform = exp plot_predictions() :  marginal effects, need transform predictions calculating instantaneous slopes. also can’t use slopes() function directly—need use comparisons() compute numerical derivative (.e. predict gdpPercap lifeExp 40 40.001 calculate slope predictions). can use comparison argument pass pair predicted values exp() calculating slopes: can visually confirm instantaneous slopes levels life expectancy:","code":"library(dplyr) library(ggplot2) library(patchwork) library(brms) library(marginaleffects) library(gapminder)  # Build some 0s into the GDP column set.seed(1234) gapminder <- gapminder::gapminder |>    filter(continent != \"Oceania\") |>    # Make a bunch of GDP values 0   mutate(prob_zero = ifelse(lifeExp < 50, 0.3, 0.02),          will_be_zero = rbinom(n(), 1, prob = prob_zero),          gdpPercap0 = ifelse(will_be_zero, 0, gdpPercap)) |>    select(-prob_zero, -will_be_zero)  mod <- brm(   bf(gdpPercap0 ~ lifeExp,      hu ~ lifeExp),   data = gapminder,   family = hurdle_lognormal(),   chains = 4, cores = 4, seed = 1234) summary(mod) #>  Family: hurdle_lognormal  #>   Links: mu = identity; sigma = identity; hu = logit  #> Formula: gdpPercap0 ~ lifeExp  #>          hu ~ lifeExp #>    Data: gapminder (Number of observations: 1680)  #>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #>          total post-warmup draws = 4000 #>  #> Population-Level Effects:  #>              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS #> Intercept        3.47      0.09     3.29     3.65 1.00     4757     3378 #> hu_Intercept     3.16      0.40     2.37     3.96 1.00     2773     2679 #> lifeExp          0.08      0.00     0.08     0.08 1.00     5112     3202 #> hu_lifeExp      -0.10      0.01    -0.12    -0.08 1.00     2385     2652 #> ... predictions(mod, dpar = \"hu\", type = \"link\",             newdata = datagrid(lifeExp = seq(40, 80, 20))) #>  #>  Estimate 2.5 % 97.5 % lifeExp #>    -0.817 -1.03 -0.604      40 #>    -2.805 -3.06 -2.555      60 #>    -4.790 -5.34 -4.275      80 #>  #> Columns: rowid, estimate, conf.low, conf.high, gdpPercap0, lifeExp predictions(mod, dpar = \"hu\", type = \"response\",             newdata = datagrid(lifeExp = seq(40, 80, 20))) #>  #>  Estimate   2.5 % 97.5 % lifeExp #>   0.30630 0.26231 0.3534      40 #>   0.05703 0.04466 0.0721      60 #>   0.00824 0.00478 0.0137      80 #>  #> Columns: rowid, estimate, conf.low, conf.high, gdpPercap0, lifeExp slopes(mod, dpar = \"hu\", type = \"link\",                 newdata = datagrid(lifeExp = seq(40, 80, 20))) #>  #>     Term Estimate  2.5 %  97.5 % lifeExp #>  lifeExp  -0.0993 -0.116 -0.0837      40 #>  lifeExp  -0.0993 -0.116 -0.0837      60 #>  lifeExp  -0.0993 -0.116 -0.0837      80 #>  #> Columns: rowid, term, estimate, conf.low, conf.high, predicted, predicted_hi, predicted_lo, tmp_idx, gdpPercap0, lifeExp  slopes(mod, dpar = \"hu\", type = \"response\",                 newdata = datagrid(lifeExp = seq(40, 80, 20))) #>  #>     Term  Estimate    2.5 %    97.5 % lifeExp #>  lifeExp -0.021078 -0.02591 -0.016588      40 #>  lifeExp -0.005321 -0.00615 -0.004561      60 #>  lifeExp -0.000812 -0.00115 -0.000543      80 #>  #> Columns: rowid, term, estimate, conf.low, conf.high, predicted, predicted_hi, predicted_lo, tmp_idx, gdpPercap0, lifeExp predictions(mod, dpar = \"mu\", type = \"link\",             newdata = datagrid(lifeExp = seq(40, 80, 20))) #>  #>  Estimate 2.5 % 97.5 % lifeExp #>      6.61  6.54   6.69      40 #>      8.18  8.15   8.22      60 #>      9.75  9.69   9.82      80 #>  #> Columns: rowid, estimate, conf.low, conf.high, gdpPercap0, lifeExp predictions(mod, dpar = \"mu\", type = \"response\",             newdata = datagrid(lifeExp = seq(40, 80, 20))) #>  #>  Estimate 2.5 % 97.5 % lifeExp #>      6.61  6.54   6.69      40 #>      8.18  8.15   8.22      60 #>      9.75  9.69   9.82      80 #>  #> Columns: rowid, estimate, conf.low, conf.high, gdpPercap0, lifeExp predictions(mod, dpar = \"mu\",              newdata = datagrid(lifeExp = seq(40, 80, 20)),             transform = exp) #>  #>  Estimate 2.5 % 97.5 % lifeExp #>       744   694    801      40 #>      3581  3449   3718      60 #>     17215 16110  18410      80 #>  #> Columns: rowid, estimate, conf.low, conf.high, gdpPercap0, lifeExp plot_predictions(   mod,   dpar = \"hu\",   type = \"link\",   condition = \"lifeExp\") +   labs(y = \"hu\",        title = \"Hurdle part (hu)\",        subtitle = \"Logit-scale predictions\") + plot_predictions(   mod,   dpar = \"hu\",   type = \"response\",   condition = \"lifeExp\") +   labs(y = \"hu\",        subtitle = \"Percentage point-scale predictions\") + plot_predictions(   mod,   dpar = \"mu\",   condition = \"lifeExp\") +   labs(y = \"mu\",        title = \"Non-hurdle part (mu)\",        subtitle = \"Log-scale predictions\") + plot_predictions(   mod,   dpar = \"mu\",   transform = exp,   condition = \"lifeExp\") +   labs(y = \"mu\",        subtitle = \"Dollar-scale predictions\") # step size of the numerical derivative eps <- 0.001  comparisons(   mod,   dpar = \"mu\",   variables = list(lifeExp = eps),   newdata = datagrid(lifeExp = seq(40, 80, 20)),   # rescale the elements of the slope   # (exp(40.001) - exp(40)) / exp(0.001)   comparison = function(hi, lo) ((exp(hi) - exp(lo)) / exp(eps)) / eps ) #>  #>     Term Contrast Estimate  2.5 % 97.5 % #>  lifeExp   +0.001     58.4   55.8     61 #>  lifeExp   +0.001    280.9  266.6    296 #>  lifeExp   +0.001   1349.4 1222.6   1490 #>  #> Columns: rowid, term, contrast, estimate, conf.low, conf.high, predicted, predicted_hi, predicted_lo, tmp_idx, gdpPercap0, lifeExp predictions_data <- predictions(   mod,   newdata = datagrid(lifeExp = seq(30, 80, 1)),   dpar = \"mu\",   transform = exp) |>   select(lifeExp, prediction = estimate)  slopes_data <- comparisons(   mod,   dpar = \"mu\",   variables = list(lifeExp = eps),   newdata = datagrid(lifeExp = seq(40, 80, 20)),   comparison = function(hi, lo) ((exp(hi) - exp(lo)) / exp(eps)) / eps) |>   select(lifeExp, estimate) |>   left_join(predictions_data, by = \"lifeExp\") |>   # Point-slope formula: (y - y1) = m(x - x1)   mutate(intercept = estimate * (-lifeExp) + prediction)  ggplot(predictions_data, aes(x = lifeExp, y = prediction)) +   geom_line(size = 1) +    geom_abline(data = slopes_data, aes(slope = estimate, intercept = intercept),                size = 0.5, color = \"red\") +   geom_point(data = slopes_data) +   geom_label(data = slopes_data, aes(label = paste0(\"Slope: \", round(estimate, 1))),              nudge_x = -1, hjust = 1) +   theme_minimal()"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/experiments.html","id":"analyzing-2x2-experiments-with-marginaleffects","dir":"Articles","previous_headings":"","what":"Analyzing 2x2 Experiments with marginaleffects","title":"Experiments: 2x2 designs and regression adjustment","text":"2×2 factorial design type experimental design allows researchers understand effects two independent variables (two levels) single dependent variable. design popular among academic researchers well industry running /B tests. illustrate analyze designs marginaleffects, use mtcars dataset. ’ll analyze fuel efficiency, mpg (miles per gallon), function (transmission type) vs (engine shape). vs indicator variable car straight engine (1 = straight engine, 0 = V-shaped). indicator variable car manual transmission (1 = manual transmission, 0=automatic transmission). four types cars (1 type four combinations binary indicators).","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/experiments.html","id":"fitting-a-model","dir":"Articles","previous_headings":"Analyzing 2x2 Experiments with marginaleffects","what":"Fitting a Model","title":"Experiments: 2x2 designs and regression adjustment","text":"Let’s start creating model fuel efficiency. simplicity, ’ll use linear regression model interaction vs . can plot predictions model using plot_predictions function. plot , can see things: Straight engines (vs=1) estimated better expected fuel efficiency V-shaped engines (vs=0). Manual transmissions (=1) estimated better fuel efficiency V-shaped straight engines. straight engines, effect manual transmissions fuel efficiency seems increase.","code":"library(tidyverse) library(marginaleffects)  # See ?mtcars for variable definitions fit <- lm(mpg ~ vs + am + vs:am, data=mtcars) # equivalent to ~ vs*am plot_predictions(fit, by = c(\"vs\", \"am\"))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/experiments.html","id":"evaluating-effects-from-the-model-summary","dir":"Articles","previous_headings":"Analyzing 2x2 Experiments with marginaleffects","what":"Evaluating Effects From The Model Summary","title":"Experiments: 2x2 designs and regression adjustment","text":"Since model fairly simple estimated differences four possible combinations vs can read summary(fit) little arithmetic. estimated model \\[ \\mbox{mpg} = 20.743 + 5.693 \\cdot \\mbox{vs} + 4.700 \\cdot \\mbox{} + 2.929 \\cdot \\mbox{vs} \\cdot \\mbox{} \\>. \\] estimated differences fuel efficiency : 5.693 mpg straight engines V-shaped engines car automatic transmission. 4.700 mpg manual transmissions automatic transmissions car V-shaped engine. 7.629 mpg manual transmissions automatic transmissions car straight engine. 13.322 mpg manual transmissions straight engines automatic transmissions V-shaped engines. Reading differences model summary becomes difficult variables added (mention obtaining estimated standard errors becomes nightmarish). make process easier , can leverage avg_comparisons function get estimates uncertainty.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/experiments.html","id":"using-avg_comparisons-to-estimate-all-differences","dir":"Articles","previous_headings":"Analyzing 2x2 Experiments with marginaleffects","what":"Using avg_comparisons To Estimate All Differences","title":"Experiments: 2x2 designs and regression adjustment","text":"Note dot grey rectangle estimated fuel efficiency vs=0 =0 (, automatic transmission car V-shaped engine).  Let’s use avg_comparisons get difference straight engines V-shaped engines car automatic transmission. call avg_comparisons shown results estimate made directly model. contrast corresponding estimate shown plot .  next difference manual transmissions automatic transmissions car V-shaped engine. , call avg_comparisons shown , corresponding contrast indicated plot using arrow.  third difference estimated manual transmissions automatic transmissions car straight engine. model call contrast  last difference contrast manual transmissions straight engines automatic transmissions V-shaped engines ","code":"avg_comparisons(fit,   newdata = datagrid(am = 0),   variables = \"vs\") #>  #>  Term Contrast Estimate Std. Error    z Pr(>|z|)    S 2.5 % 97.5 % #>    vs    1 - 0     5.69       1.65 3.45   <0.001 10.8  2.46   8.93 #>  #> Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo avg_comparisons(fit,   newdata = datagrid(vs = 0),   variables = \"am\") #>  #>  Term Contrast Estimate Std. Error    z Pr(>|z|)   S 2.5 % 97.5 % #>    am    1 - 0      4.7       1.74 2.71  0.00678 7.2   1.3    8.1 #>  #> Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo avg_comparisons(fit,   newdata = datagrid(vs = 1),   variables = \"am\") #>  #>  Term Contrast Estimate Std. Error    z Pr(>|z|)    S 2.5 % 97.5 % #>    am    1 - 0     7.63       1.86 4.11   <0.001 14.6  3.99   11.3 #>  #> Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo avg_comparisons(fit,   newdata = datagrid(\"vs\", \"am\"),   variables = c(\"am\", \"vs\"),   cross = TRUE) #>  #>  C: am C: vs Estimate Std. Error    z Pr(>|z|)    S 2.5 % 97.5 % #>  1 - 0 1 - 0     13.3       1.65 8.07   <0.001 50.3  10.1   16.6 #>  #> Columns: rowid, term, contrast_am, contrast_vs, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/experiments.html","id":"conclusion","dir":"Articles","previous_headings":"Analyzing 2x2 Experiments with marginaleffects","what":"Conclusion","title":"Experiments: 2x2 designs and regression adjustment","text":"2x2 design popular design, using linear model, estimated differences groups can directly read model summary, little arithmetic. However, using models non-identity link function, seeking obtain standard errors estimated differences, things become considerably difficult. vignette showed use avg_comparisons specify contrasts interests obtain standard errors differences. approach used applies generalized linear models effects can stratified using argument (although shown vignette.)","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/experiments.html","id":"regression-adjustment-in-experiments","dir":"Articles","previous_headings":"","what":"Regression adjustment in experiments","title":"Experiments: 2x2 designs and regression adjustment","text":"Many analysts conduct analyze experiments wish use regression adjustment linear regression model improve precision estimate treatment effect. Unfortunately, regression adjustment can introduce small-sample bias undesirable properties (Freedman 2008). Lin (2013) proposes simple strategy fix problems sufficiently large samples: Center predictors subtracting means. Estimate linear model treatment interacted covariates. estimatr package includes convenient function implement strategy: can obtain results fitting model standard lm function using comparisons() function: Notice treat coefficient associate standard error lm_lin regression exactly estimates produced comparisons() function.","code":"library(estimatr) library(marginaleffects) lalonde <- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/MatchIt/lalonde.csv\")  mod <- lm_lin(     re78 ~ treat,     covariates = ~ age + educ + race,     data = lalonde,     se_type = \"HC3\") summary(mod) #>  #> Call: #> lm_lin(formula = re78 ~ treat, covariates = ~age + educ + race,  #>     data = lalonde, se_type = \"HC3\") #>  #> Standard error type:  HC3  #>  #> Coefficients: #>                    Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper  DF #> (Intercept)         6488.05     356.71 18.1885 2.809e-59  5787.50   7188.6 604 #> treat                489.73     878.52  0.5574 5.774e-01 -1235.59   2215.0 604 #> age_c                 85.88      35.42  2.4248 1.561e-02    16.32    155.4 604 #> educ_c               464.04     131.51  3.5286 4.495e-04   205.77    722.3 604 #> racehispan_c        2775.47    1155.40  2.4022 1.660e-02   506.38   5044.6 604 #> racewhite_c         2291.67     793.30  2.8888 4.006e-03   733.71   3849.6 604 #> treat:age_c           17.23      76.37  0.2256 8.216e-01  -132.75    167.2 604 #> treat:educ_c         226.71     308.43  0.7350 4.626e-01  -379.02    832.4 604 #> treat:racehispan_c -1057.84    2652.42 -0.3988 6.902e-01 -6266.92   4151.2 604 #> treat:racewhite_c  -1205.68    1805.21 -0.6679 5.045e-01 -4750.92   2339.6 604 #>  #> Multiple R-squared:  0.05722 ,   Adjusted R-squared:  0.04317  #> F-statistic: 4.238 on 9 and 604 DF,  p-value: 2.424e-05 mod <- lm(re78 ~ treat * (age + educ + race), data = lalonde) avg_comparisons(     mod,     variables = \"treat\",     vcov = \"HC3\") #>  #>   Term Contrast Estimate Std. Error     z Pr(>|z|)   S 2.5 % 97.5 % #>  treat    1 - 0      490        879 0.557    0.577 0.8 -1232   2212 #>  #> Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/experiments.html","id":"references","dir":"Articles","previous_headings":"Regression adjustment in experiments","what":"References","title":"Experiments: 2x2 designs and regression adjustment","text":"Freedman, David . “Regression Adjustments Experimental Data.” Advances Applied Mathematics 40, . 2 (February 2008): 180–93. Lin, Winston. “Agnostic Notes Regression Adjustments Experimental Data: Reexamining Freedman’s Critique.” Annals Applied Statistics 7, . 1 (March 2013): 295–318. https://doi.org/10.1214/12-AOAS583.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/extensions.html","id":"support-a-new-model-type","dir":"Articles","previous_headings":"","what":"Support a new model type","title":"Extending or Modifying marginaleffects","text":"easy add support new models marginaleffects. need set global option define 4 simple functions. add support class models produced CRAN package, please consider submitting code inclusion package: https://github.com/vincentarelbundock/marginaleffects add support class models produced package hosted elsewhere CRAN, can submit inclusion unsupported user-submitted library extensions: Currently countreg package. Thanks Olivier Beaumais. censreg package. Thanks Oleg Komashko. rest section illustrates add support simple lm_manual model.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/extensions.html","id":"fit-function","dir":"Articles","previous_headings":"Support a new model type","what":"Fit function","title":"Extending or Modifying marginaleffects","text":"begin, define function fits model. Normally, function supplied modeling package published CRAN. , create function called lm_manual(), estimates linear regression model using simple linear algebra operates: Important: custom fit function must assign new class name object returns. example , model assigned class lm_manual (see penultimate line code function). new function replicates results lm():","code":"lm_manual <- function(f, data, ...) {     # design matrix     X <- model.matrix(f, data = data)     # response matrix     Y <- data[[as.character(f[2])]]     # coefficients     b <- solve(crossprod(X)) %*% crossprod(X, Y)     Yhat <- X %*% b     # variance-covariance matrix     e <- Y - Yhat     df <- nrow(X) - ncol(X)     s2 <- sum(e^2) / df     V <- s2 * solve(crossprod(X))     # model object     out <- list(         d = data,         f = f,         X = X,         Y = Y,         V = V,         b = b)     # class name: lm_manual     class(out) <- c(\"lm_manual\", \"list\")     return(out) } model <- lm_manual(mpg ~ hp + drat, data = mtcars) model$b #>                    [,1] #> (Intercept) 10.78986122 #> hp          -0.05178665 #> drat         4.69815776  model_lm <- lm(mpg ~ hp + drat, data = mtcars) coef(model_lm) #> (Intercept)          hp        drat  #> 10.78986122 -0.05178665  4.69815776"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/extensions.html","id":"marginaleffects-extension","dir":"Articles","previous_headings":"Support a new model type","what":"marginaleffects extension","title":"Extending or Modifying marginaleffects","text":"extend support marginaleffects, first step tell package new class supported. defining global option: , define 4 methods: Mandatory arguments: model, ... Returns: named vector parameters (coefficients). Mandatory arguments: model, coefs (named vector coefficients), ... Returns: new model object original coefficients replaced new vector. Example Mandatory arguments: model, .... Optional arguments: vcov Returns: named square variance-covariance matrix. Mandatory arguments: model, newdata (data frame), ... Option arguments: type model-specific arguments. Returns: data frame two columns: unique rowid column estimate values. Note methods named suffix .lm_manual indicate used whenever marginaleffects needs process object class lm_manual. methods just defined work expected: Now can use avg_slopes function: Note , custom model, typically supply values newdata variables arguments explicitly.","code":"library(marginaleffects)  options(\"marginaleffects_model_classes\" = \"lm_manual\") get_coef.lm_manual <- function(model, ...) {     b <- model$b     b <- setNames(as.vector(b), row.names(b))     return(b) }  set_coef.lm_manual <- function(model, coefs, ...) {     out <- model     out$b <- coefs     return(out) }  get_vcov.lm_manual <- function(model, ...) {     return(model$V) }  get_predict.lm_manual <- function(model, newdata, ...) {     newX <- model.matrix(model$f, data = newdata)     Yhat <- newX %*% model$b     out <- data.frame(         rowid = seq_len(nrow(Yhat)),         estimate = as.vector(Yhat))     return(out) } get_coef(model) #> (Intercept)          hp        drat  #> 10.78986122 -0.05178665  4.69815776  get_vcov(model) #>             (Intercept)            hp         drat #> (Intercept) 25.78356135 -3.054007e-02 -5.836030687 #> hp          -0.03054007  8.635615e-05  0.004969385 #> drat        -5.83603069  4.969385e-03  1.419990359  get_predict(model, newdata = head(mtcars)) #>   rowid estimate #> 1     1 23.41614 #> 2     2 23.41614 #> 3     3 24.06161 #> 4     4 19.56366 #> 5     5 16.52639 #> 6     6 18.31918 avg_slopes(model, newdata = mtcars, variables = c(\"hp\", \"drat\")) #>  #>  Term Estimate Std. Error     z Pr(>|z|)    S 2.5 %  97.5 % #>  hp    -0.0518    0.00929 -5.57   <0.001 25.2 -0.07 -0.0336 #>  drat   4.6982    1.19163  3.94   <0.001 13.6  2.36  7.0337 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  predictions(model, newdata = mtcars) |> head() #>  #>  Estimate Std. Error    z Pr(>|z|)     S 2.5 % 97.5 %  mpg cyl disp  hp drat   wt qsec vs am gear carb #>      23.4      0.671 34.9   <0.001 883.6  22.1   24.7 21.0   6  160 110 3.90 2.62 16.5  0  1    4    4 #>      23.4      0.671 34.9   <0.001 883.6  22.1   24.7 21.0   6  160 110 3.90 2.88 17.0  0  1    4    4 #>      24.1      0.720 33.4   <0.001 810.2  22.6   25.5 22.8   4  108  93 3.85 2.32 18.6  1  1    4    1 #>      19.6      0.999 19.6   <0.001 281.4  17.6   21.5 21.4   6  258 110 3.08 3.21 19.4  1  0    3    1 #>      16.5      0.735 22.5   <0.001 369.1  15.1   18.0 18.7   8  360 175 3.15 3.44 17.0  0  0    3    2 #>      18.3      1.343 13.6   <0.001 138.3  15.7   21.0 18.1   6  225 105 2.76 3.46 20.2  1  0    3    1 #>  #> Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/extensions.html","id":"modify-or-extend-supported-models","dir":"Articles","previous_headings":"","what":"Modify or extend supported models","title":"Extending or Modifying marginaleffects","text":"Let’s say want estimate model using mclogit::mblogit function. package already supported marginaleffects, want use type (scale) predictions currently supported: “centered link scale.” achieve , need override get_predict.mblogit() method. However, can unsafe reassign methods supplied package loaded library. safe, assign new model class object (“customclass”) inherit mblogit. , define get_predict.customclass method make new kinds predictions. Load libraries, estimate model: Tell marginaleffects adding support new class model models, assign new inherited class name duplicate model object: Define new get_predict.customclass method. use default predict() function obtain predictions. Since multinomial model, predict() returns matrix predictions one column per level response variable. new get_predict.customclass method takes matrix predictions, modifies , reshapes return data frame three columns: rowid, group, estimate: Finally, can call slopes function obtain results. Notice object class customclass now produces different results default mblogit object:","code":"library(mclogit) library(data.table)  model <- mblogit(     factor(gear) ~ am + mpg,     data = mtcars,     trace = FALSE) options(\"marginaleffects_model_classes\" = \"customclass\")  model_custom <- model  class(model_custom) <- c(\"customclass\", class(model)) get_predict.customclass <- function(model, newdata, ...) {     out <- predict(model, newdata = newdata, type = \"link\")     out <- cbind(0, out)     colnames(out)[1] <- dimnames(model$D)[[1]][[1]]     out <- out - rowMeans(out)     out <- as.data.frame(out)     out$rowid <- seq_len(nrow(out))     out <- data.table(out)     out <- melt(         out,         id.vars = \"rowid\",         value.name = \"estimate\",         variable.name = \"group\") } avg_predictions(model) #>  #>  Group Estimate Std. Error     z Pr(>|z|)    S  2.5 % 97.5 % #>      3    0.469     0.0444 10.56  < 0.001 84.2 0.3817  0.556 #>      4    0.375     0.0671  5.59  < 0.001 25.4 0.2436  0.506 #>      5    0.156     0.0503  3.11  0.00188  9.1 0.0577  0.255 #>  #> Columns: group, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  avg_predictions(model_custom) #>  #>  Group Estimate Std. Error         z Pr(>|z|)   S 2.5 % 97.5 % #>      3    -1.42       2525 -0.000561    1.000 0.0 -4950   4947 #>      4     6.36       1779  0.003578    0.997 0.0 -3480   3493 #>      5    -4.95       3074 -0.001609    0.999 0.0 -6030   6020 #>  #> Columns: group, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/faq.html","id":"stack-overflow-questions","dir":"Articles","previous_headings":"","what":"Stack Overflow questions","title":"FAQ","text":"plot_predictions() range unobserved values Plot marginal effects plm package model Models demeaned, polynomials, transformed variables","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/faq.html","id":"calling-marginaleffects-in-functions-loops-environments-or-after-re-assigning-variables","dir":"Articles","previous_headings":"","what":"Calling marginaleffects in functions, loops, environments, or after re-assigning variables","title":"FAQ","text":"Functions marginaleffects package can sometimes fail called inside function, loop, environments. see , important know marginaleffects often needs operate original data used fit model. extract original data, use get_data() function insight package. cases, get_data() can extract data stored inside model object created modeling package. However, modeling packages save original data model object (order save memory). cases, get_data() parse call find name data object, search data object global environment. users fit models different environment (e.g., function calls), get_data() may able retrieve original data. related problem can arise users fit model, assign new value variable used store dataset. Recommendations: Supply dataset explicitly newdata argument slopes functions. Avoid assigning new value variable use store dataset model fitting.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/gam.html","id":"estimate-a-gam-model","dir":"Articles","previous_headings":"","what":"Estimate a GAM model","title":"Generalized Additive Models","text":"estimate GAM model using mgcv package simdat dataset distributed itsadug package: Fit model random effect group-time smooths:","code":"library(marginaleffects) library(itsadug) library(mgcv)  simdat$Subject <- as.factor(simdat$Subject)  dim(simdat) #> [1] 75600     6 head(simdat) #>    Group      Time Trial Condition Subject         Y #> 1 Adults   0.00000   -10        -1     a01 0.7554469 #> 2 Adults  20.20202   -10        -1     a01 2.7834759 #> 3 Adults  40.40404   -10        -1     a01 1.9696963 #> 4 Adults  60.60606   -10        -1     a01 0.6814298 #> 5 Adults  80.80808   -10        -1     a01 1.6939195 #> 6 Adults 101.01010   -10        -1     a01 2.3651969 model <- bam(Y ~ Group + s(Time, by = Group) + s(Subject, bs = \"re\"),              data = simdat)  summary(model) #>  #> Family: gaussian  #> Link function: identity  #>  #> Formula: #> Y ~ Group + s(Time, by = Group) + s(Subject, bs = \"re\") #>  #> Parametric coefficients: #>             Estimate Std. Error t value Pr(>|t|)    #> (Intercept)   2.0574     0.6903   2.980  0.00288 ** #> GroupAdults   3.1265     0.9763   3.202  0.00136 ** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Approximate significance of smooth terms: #>                         edf Ref.df    F p-value     #> s(Time):GroupChildren  8.26  8.850 3649  <2e-16 *** #> s(Time):GroupAdults    8.66  8.966 6730  <2e-16 *** #> s(Subject)            33.94 34.000  569  <2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> R-sq.(adj) =  0.609   Deviance explained =   61% #> fREML = 2.3795e+05  Scale est. = 31.601    n = 75600"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/gam.html","id":"adjusted-predictions-predictions-and-plot_predictions","dir":"Articles","previous_headings":"","what":"Adjusted Predictions: predictions() and plot_predictions()","title":"Generalized Additive Models","text":"Compute adjusted predictions observed combination regressor dataset used fit model. gives us dataset number rows original data, new columns predicted values uncertainty estimates: can easily plot adjusted predictions different values regressor using plot_predictions() function:","code":"pred <- predictions(model) dim(pred) #> [1] 75600    12 head(pred) #>  #>  Estimate Std. Error     z Pr(>|z|)    S   2.5 %  97.5 % #>    -1.874      0.199 -9.41   <0.001 67.4 -2.2643 -1.4834 #>    -1.346      0.182 -7.41   <0.001 42.8 -1.7025 -0.9901 #>    -0.819      0.167 -4.90   <0.001 20.0 -1.1467 -0.4916 #>    -0.293      0.156 -1.88   0.0605  4.0 -0.5988  0.0129 #>     0.231      0.149  1.55   0.1204  3.1 -0.0606  0.5232 #>     0.753      0.146  5.17   <0.001 22.0  0.4675  1.0379 #>  #> Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, Y, Group, Time, Subject plot_predictions(model, condition = \"Time\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/gam.html","id":"marginal-effects-slopes-and-plot_slopes","dir":"Articles","previous_headings":"","what":"Marginal Effects: slopes() and plot_slopes()","title":"Generalized Additive Models","text":"Marginal effects slopes prediction equation. observation-level quantity. slopes() function produces dataset number rows original data, new columns slop uncertainty estimates: can plot marginal effects different values regressor using plot_slopes() function. next plot shows slope prediction equation, , slope previous plot, every value Time variable.  marginal effects plot can interpreted measuring change Y associated small increase Time, different baseline values Time.","code":"mfx <- slopes(model, variables = \"Time\") head(mfx) #>  #>  Term Estimate Std. Error    z Pr(>|z|)     S  2.5 % 97.5 % #>  Time   0.0261    0.00137 19.1   <0.001 267.8 0.0234 0.0288 #>  Time   0.0261    0.00136 19.2   <0.001 270.3 0.0234 0.0288 #>  Time   0.0261    0.00133 19.5   <0.001 280.0 0.0235 0.0287 #>  Time   0.0260    0.00128 20.3   <0.001 301.3 0.0235 0.0285 #>  Time   0.0259    0.00120 21.6   <0.001 339.9 0.0235 0.0282 #>  Time   0.0257    0.00109 23.5   <0.001 404.8 0.0236 0.0279 #>  #> Columns: rowid, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, Y, Group, Time, Subject plot_slopes(model, variables = \"Time\", condition = \"Time\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/gam.html","id":"excluding-terms","dir":"Articles","previous_headings":"","what":"Excluding terms","title":"Generalized Additive Models","text":"predict() method mgcv package allows users “exclude” smoothing terms, using exclude argument. can pass argument function marginaleffects package: See documentation ?mgcv:::predict.bam details.","code":"predictions(model, newdata = \"mean\", exclude = \"s(Subject)\") #>  #>  Estimate Std. Error    z Pr(>|z|)     S 2.5 % 97.5 %  Group Time Subject #>      11.7      0.695 16.9   <0.001 210.8  10.4   13.1 Adults 1000     a01 #>  #> Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, Y, Group, Time, Subject"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/gformula.html","id":"what-is-the-parametric-g-formula","dir":"Articles","previous_headings":"","what":"What is the parametric g-formula?","title":"Causal Inference with the Parametric g-Formula","text":"parametric g-formula method standardization can used address confounding problems causal inference observational data. relies identification assumptions Inverse Probability Weighting (IPW), uses different modeling assumptions. Whereas IPW models treatment equation, standardization models mean outcome equation. Hernán Robins note: “IP weighting standardization estimators g-formula, general method causal inference first described 1986. … say standardization ”plug-g-formula estimator” simply replaces conditional mean outcome g-formula estimates. , like Chapter 13, estimates come parametric models, refer method parametric g-formula.”","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/gformula.html","id":"how-does-it-work","dir":"Articles","previous_headings":"","what":"How does it work?","title":"Causal Inference with the Parametric g-Formula","text":"Imagine causal model like :  want estimate effect binary treatment \\(X\\) outcome \\(Y\\), confounding variable \\(W\\). can use standardization parametric g-formula handle . Roughly speaking, procedure follows: Use observed data fit regression model \\(Y\\) outcome, \\(X\\) treatment, \\(W\\) control variable (perhaps polynomials /interactions multiple control variables). Create new dataset exactly identical original data, \\(X=1\\) every row. Create new dataset exactly identical original data, \\(X=0\\) every row. Use model Step 1 compute adjusted predictions two counterfactual datasets Steps 2 3. quantity interest difference means adjusted predictions two counterfactual datasets. equivalent computing “Average Contrast”, value \\(X\\) moves 0 1. Thanks equivalence, can apply parametric g-formula method using single line code marginaleffects, obtain delta method standard errors automatically.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/gformula.html","id":"example-with-real-world-data","dir":"Articles","previous_headings":"","what":"Example with real-world data","title":"Causal Inference with the Parametric g-Formula","text":"Let’s illustrate method replicating example Chapter 13 Hernán Robins. data come National Health Nutrition Examination Survey Data Epidemiologic Follow-Study (NHEFS). outcome wt82_71, measure weight gain. treatment qsmk, binary measure smoking cessation. many confounders. Step 1 fit regression model outcome treatment control variables: Steps 2 3 require us replicate full dataset setting qsmk treatment counterfactual values. can automatically calling comparisons().","code":"library(boot) library(marginaleffects)  f <- wt82_71 ~ qsmk + sex + race + age + I(age * age) + factor(education) +      smokeintensity + I(smokeintensity * smokeintensity) + smokeyrs +      I(smokeyrs * smokeyrs) + factor(exercise) + factor(active) + wt71 +      I(wt71 * wt71) + I(qsmk * smokeintensity)  url <- \"https://raw.githubusercontent.com/vincentarelbundock/modelarchive/main/data-raw/nhefs.csv\" nhefs <- read.csv(url) nhefs <- na.omit(nhefs[, all.vars(f)])  fit <- glm(f, data = nhefs)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/gformula.html","id":"tldr","dir":"Articles","previous_headings":"Example with real-world data","what":"TLDR","title":"Causal Inference with the Parametric g-Formula","text":"simple commands everything need apply parametric g-formula: rest vignette walks process bit detail compares replication code Hernán Robins.","code":"avg_comparisons(fit, variables = list(qsmk = 0:1)) ##  ##  Term Contrast Estimate Std. Error    z Pr(>|z|)    S 2.5 % 97.5 % ##  qsmk    1 - 0     3.52       0.44 7.99   <0.001 49.4  2.65   4.38 ##  ## Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/gformula.html","id":"adjusted-predictions","dir":"Articles","previous_headings":"Example with real-world data","what":"Adjusted Predictions","title":"Causal Inference with the Parametric g-Formula","text":"can compute average predictions original data, average predictions two counterfactual datasets like : R code accompanies book, Hernán Robins compute quantities manually, follows: may useful note datagrid() function provided marginaleffects can create counterfactual datasets automatically. equivalent onesample dataset:","code":"# average predicted outcome in the original data p <- predictions(fit) mean(p$estimate) ## [1] 2.6383 # average predicted outcome in the two counterfactual datasets p <- predictions(fit, newdata = datagrid(qsmk = 0:1, grid_type = \"counterfactual\")) aggregate(estimate ~ qsmk, data = p, FUN = mean) ##   qsmk estimate ## 1    0 1.756213 ## 2    1 5.273587 # create a dataset with 3 copies of each subject nhefs$interv <- -1 # 1st copy: equal to original one  interv0 <- nhefs # 2nd copy: treatment set to 0, outcome to missing interv0$interv <- 0 interv0$qsmk <- 0 interv0$wt82_71 <- NA  interv1 <- nhefs # 3rd copy: treatment set to 1, outcome to missing interv1$interv <- 1 interv1$qsmk <- 1 interv1$wt82_71 <- NA  onesample <- rbind(nhefs, interv0, interv1) # combining datasets  # linear model to estimate mean outcome conditional on treatment and confounders # parameters are estimated using original observations only (nhefs) # parameter estimates are used to predict mean outcome for observations with  # treatment set to 0 (interv=0) and to 1 (interv=1)  std <- glm(f, data = onesample) onesample$predicted_meanY <- predict(std, onesample)  # estimate mean outcome in each of the groups interv=0, and interv=1 # this mean outcome is a weighted average of the mean outcomes in each combination  # of values of treatment and confounders, that is, the standardized outcome mean(onesample[which(onesample$interv == -1), ]$predicted_meanY) ## [1] 2.6383 mean(onesample[which(onesample$interv == 0), ]$predicted_meanY) ## [1] 1.756213 mean(onesample[which(onesample$interv == 1), ]$predicted_meanY) ## [1] 5.273587 nd <- datagrid(     model = fit,     qsmk = c(0, 1),     grid_type = \"counterfactual\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/gformula.html","id":"contrast","dir":"Articles","previous_headings":"Example with real-world data","what":"Contrast","title":"Causal Inference with the Parametric g-Formula","text":"Now want compute treatment effect parametric g-formula, difference average predicted outcomes two counterfactual datasets. equivalent taking average contrast comparisons() function. three important things note command follows: variables argument used indicate want estimate “contrast” adjusted predictions qsmk equal 1 0. comparisons() automatically produces estimates uncertainty. hood, comparisons() exactly described g-formula steps : can obtain result manually computing quantities, using replication code Hernán Robins: Although manual computation simple, provide uncertainty estimates. contrast, comparisons() already computed standard error confidence interval using delta method. Instead delta method, analysts rely bootstrapping. example, replication code Hernán Robins : results close obtained comparisons(), confidence interval differs slightly difference bootstrapping delta method.","code":"avg_comparisons(std, variables = list(qsmk = 0:1)) ##  ##  Term Contrast Estimate Std. Error    z Pr(>|z|)    S 2.5 % 97.5 % ##  qsmk    1 - 0     3.52       0.44 7.99   <0.001 49.4  2.65   4.38 ##  ## Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high mean(onesample[which(onesample$interv == 1), ]$predicted_meanY) - mean(onesample[which(onesample$interv == 0), ]$predicted_meanY) ## [1] 3.517374 # function to calculate difference in means standardization <- function(data, indices) {     # create a dataset with 3 copies of each subject     d <- data[indices, ] # 1st copy: equal to original one`     d$interv <- -1     d0 <- d # 2nd copy: treatment set to 0, outcome to missing     d0$interv <- 0     d0$qsmk <- 0     d0$wt82_71 <- NA     d1 <- d # 3rd copy: treatment set to 1, outcome to missing     d1$interv <- 1     d1$qsmk <- 1     d1$wt82_71 <- NA     d.onesample <- rbind(d, d0, d1) # combining datasets      # linear model to estimate mean outcome conditional on treatment and confounders     # parameters are estimated using original observations only (interv= -1)     # parameter estimates are used to predict mean outcome for observations with set     # treatment (interv=0 and interv=1)     fit <- glm(f, data = d.onesample)      d.onesample$predicted_meanY <- predict(fit, d.onesample)      # estimate mean outcome in each of the groups interv=-1, interv=0, and interv=1     return(mean(d.onesample$predicted_meanY[d.onesample$interv == 1]) -            mean(d.onesample$predicted_meanY[d.onesample$interv == 0])) }  # bootstrap results <- boot(data = nhefs, statistic = standardization, R = 1000)  # generating confidence intervals se <- sd(results$t[, 1]) meant0 <- results$t0 ll <- meant0 - qnorm(0.975) * se ul <- meant0 + qnorm(0.975) * se  bootstrap <- data.frame(     \" \" = \"Treatment - No Treatment\",     estimate = meant0,     std.error = se,     conf.low = ll,     conf.high = ul,     check.names = FALSE) bootstrap ##                            estimate std.error conf.low conf.high ## 1 Treatment - No Treatment 3.517374 0.4756176 2.585181  4.449568 avg_comparisons(fit, variables = list(qsmk = 0:1)) ##  ##  Term Contrast Estimate Std. Error    z Pr(>|z|)    S 2.5 % 97.5 % ##  qsmk    1 - 0     3.52       0.44 7.99   <0.001 49.4  2.65   4.38 ##  ## Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/hypothesis.html","id":"null-hypothesis","dir":"Articles","previous_headings":"","what":"Null hypothesis","title":"Hypothesis Tests, Equivalence Tests, and Custom Contrasts","text":"simplest way modify hypothesis test change null hypothesis. default, functions marginaleffects package assume null 0. can changed changing hypothesis argument. example, consider logistic regression model: can compute predicted outcome hypothetical unit regressors fixed sample means: Z statistic p value reported assume null hypothesis equals zero. can change null hypothesis argument: can obviously useful contexts. instance, compute risk ratios (mean) associated increase 1 unit hp, makes sense test null hypothesis ratio predictions 1 rather 0: Warning: Z statistics p values computed applying functions transform.","code":"library(marginaleffects) mod <- glm(am ~ hp + drat, data = mtcars, family = binomial) predictions(mod, newdata = \"mean\") #>  #>  Estimate Pr(>|z|)   S  2.5 % 97.5 %  hp drat #>     0.231    0.135 2.9 0.0584  0.592 147  3.6 #>  #> Columns: rowid, estimate, p.value, s.value, conf.low, conf.high, am, hp, drat predictions(mod, newdata = \"mean\", hypothesis = .5) #>  #>  Estimate Pr(>|z|)   S  2.5 % 97.5 %  hp drat #>     0.231   0.0343 4.9 0.0584  0.592 147  3.6 #>  #> Columns: rowid, estimate, p.value, s.value, conf.low, conf.high, am, hp, drat comparisons(     mod,     newdata = \"mean\",     variables = \"hp\",     comparison = \"ratio\",     hypothesis = 1) |>     print(digits = 3) #>  #>  Term Contrast Estimate Std. Error    z Pr(>|z|)   S 2.5 % 97.5 % #>    hp       +1     1.01    0.00793 1.05    0.293 1.8 0.993   1.02 #>  #> Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, am, hp, drat"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/hypothesis.html","id":"hypothesis-tests-with-the-delta-method","dir":"Articles","previous_headings":"","what":"Hypothesis tests with the delta method","title":"Hypothesis Tests, Equivalence Tests, and Custom Contrasts","text":"Version 0.6.0 marginaleffects includes powerful function called hypotheses(). function emulates behavior well-established car::deltaMethod car::linearHypothesis functions, supports models, requires fewer dependencies, offers convenience features like shortcuts robust standard errors. hypotheses() can used compute estimates standard errors arbitrary functions model parameters. example, can used conduct tests equality coefficients, test value linear non-linear combination quantities interest. hypotheses() can also used conduct hypothesis tests functions model’s parameter, adjusted predictions marginal effects. Let’s start estimating simple model: FUN hypothesis arguments hypotheses() equal NULL (default), function returns data.frame raw estimates: Test equality coefficients: Non-linear function coefficients vcov argument behaves slopes() function. allows us easily compute robust standard errors: can use shortcuts like b1, b2, ... identify position parameter output FUN. example, b2=b3 equivalent hp=wt term names appear 2nd 3rd row call hypotheses(mod). Term names special characters must enclosed backticks: FUN argument can used compute standard errors arbitrary functions model parameters. user-supplied function must accept single model object, return numeric vector data.frame two columns named term estimate. Test equality two predictions (row 2 vs row 3): Note specified newdata argument f function. predict() method associated lm objects automatically original fitted values newdata NULL, instead returning slightly altered fitted values need compute numerical derivatives delta method. can also use numeric vectors specify linear combinations parameters. example, 3 coefficients last model estimated. test null hypothesis sum 2nd 3rd coefficients equal 0, can : See example use string formulas, numeric vectors, matrices calculate custom contrasts, linear combinations, linear non-linear hypothesis tests.","code":"library(marginaleffects) mod <- lm(mpg ~ hp + wt + factor(cyl), data = mtcars) hypotheses(mod) #>  #>  Term Estimate Std. Error     z Pr(>|z|)   2.5 %    97.5 %     S #>    b1  35.8460      2.041 17.56   <0.001 31.8457 39.846319 227.0 #>    b2  -0.0231      0.012 -1.93   0.0531 -0.0465  0.000306   4.2 #>    b3  -3.1814      0.720 -4.42   <0.001 -4.5918 -1.771012  16.6 #>    b4  -3.3590      1.402 -2.40   0.0166 -6.1062 -0.611803   5.9 #>    b5  -3.1859      2.170 -1.47   0.1422 -7.4399  1.068169   2.8 #>  #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high, s.value hypotheses(mod, \"hp = wt\") #>  #>     Term Estimate Std. Error    z Pr(>|z|) 2.5 % 97.5 %    S #>  hp = wt     3.16       0.72 4.39   <0.001  1.75   4.57 16.4 #>  #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high, s.value hypotheses(mod, \"exp(hp + wt) = 0.1\") #>  #>                Term Estimate Std. Error     z Pr(>|z|)  2.5 %  97.5 %   S #>  exp(hp + wt) = 0.1  -0.0594     0.0292 -2.04   0.0418 -0.117 -0.0022 4.6 #>  #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high, s.value hypotheses(mod, \"hp = wt\", vcov = \"HC3\") #>  #>     Term Estimate Std. Error    z Pr(>|z|) 2.5 % 97.5 %    S #>  hp = wt     3.16      0.805 3.92   <0.001  1.58   4.74 13.5 #>  #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high, s.value hypotheses(mod, \"b2 = b3\") #>  #>     Term Estimate Std. Error    z Pr(>|z|) 2.5 % 97.5 %    S #>  b2 = b3     3.16       0.72 4.39   <0.001  1.75   4.57 16.4 #>  #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high, s.value hypotheses(mod, \"`factor(cyl)6` = `factor(cyl)8`\") #>  #>                             Term Estimate Std. Error      z Pr(>|z|) 2.5 % 97.5 %   S #>  `factor(cyl)6` = `factor(cyl)8`   -0.173       1.65 -0.105    0.917 -3.41   3.07 0.1 #>  #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high, s.value mod <- glm(am ~ hp + mpg, data = mtcars, family = binomial)  f <- function(x) predict(x, type = \"link\", newdata = mtcars) p <- hypotheses(mod, FUN = f) head(p) #>  #>  Term Estimate Std. Error      z Pr(>|z|) 2.5 % 97.5 %   S #>    b1   -1.098      0.716 -1.534    0.125 -2.50  0.305 3.0 #>    b2   -1.098      0.716 -1.534    0.125 -2.50  0.305 3.0 #>    b3    0.233      0.781  0.299    0.765 -1.30  1.764 0.4 #>    b4   -0.595      0.647 -0.919    0.358 -1.86  0.674 1.5 #>    b5   -0.418      0.647 -0.645    0.519 -1.69  0.851 0.9 #>    b6   -5.026      2.195 -2.290    0.022 -9.33 -0.725 5.5 #>  #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high, s.value f <- function(x) predict(x, newdata = mtcars) hypotheses(mod, FUN = f, hypothesis = \"b2 = b3\") #>  #>     Term Estimate Std. Error     z Pr(>|z|) 2.5 % 97.5 %   S #>  b2 = b3    -1.33      0.616 -2.16   0.0305 -2.54 -0.125 5.0 #>  #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high, s.value hypotheses(mod, hypothesis = c(0, 1, 1)) #>  #>    Term Estimate Std. Error    z Pr(>|z|) 2.5 % 97.5 %   S #>  custom     1.31      0.593 2.22   0.0266 0.153   2.48 5.2 #>  #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high, s.value"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/hypothesis.html","id":"hypotheses-formulas","dir":"Articles","previous_headings":"","what":"hypotheses Formulas","title":"Hypothesis Tests, Equivalence Tests, and Custom Contrasts","text":"4 core functions package support hypothesis argument behaves similarly hypotheses() function. argument allows users specify custom hypothesis tests contrasts, order test null hypotheses : coefficients \\(\\beta_1\\) \\(\\beta_2\\) equal. marginal effects \\(X_1\\) \\(X_2\\) equal. marginal effect \\(X\\) \\(W=0\\) equal marginal effect \\(X\\) \\(W=1\\). non-linear function adjusted predictions equal 100. marginal mean control group equal average marginal means 3 treatment arms. Cross-level contrasts: multinomial model, effect \\(X\\) 1st outcome level equal effect \\(X\\) 2nd outcome level.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/hypothesis.html","id":"marginal-effects","dir":"Articles","previous_headings":"hypotheses Formulas","what":"Marginal effects","title":"Hypothesis Tests, Equivalence Tests, and Custom Contrasts","text":"example, let’s fit model compute marginal effects mean: marginal effect different marginal effect vs? answer question can run linear hypothesis test using hypotheses function: Alternatively, can specify hypothesis directly original call: hypotheses string can include valid R expression, can run silly non-linear tests:","code":"library(marginaleffects)  mod <- lm(mpg ~ am + vs, data = mtcars)  mfx <- slopes(mod, newdata = \"mean\") mfx #>  #>  Term Contrast Estimate Std. Error    z Pr(>|z|)    S 2.5 % 97.5 % #>    am    1 - 0     6.07       1.27 4.76   <0.001 19.0  3.57   8.57 #>    vs    1 - 0     6.93       1.26 5.49   <0.001 24.6  4.46   9.40 #>  #> Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, mpg, am, vs hypotheses(mfx, hypothesis = \"am = vs\") #>  #>   Term Estimate Std. Error      z Pr(>|z|)   S 2.5 % 97.5 % #>  am=vs   -0.863       1.94 -0.445    0.656 0.6 -4.66   2.94 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high library(marginaleffects)  mod <- lm(mpg ~ am + vs, data = mtcars)  slopes(     mod,     newdata = \"mean\",     hypothesis = \"am = vs\") #>  #>   Term Estimate Std. Error      z Pr(>|z|)   S 2.5 % 97.5 % #>  am=vs   -0.863       1.94 -0.445    0.656 0.6 -4.66   2.94 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high slopes(     mod,     newdata = \"mean\",     hypothesis = \"exp(am) - 2 * vs = -400\") #>  #>               Term Estimate Std. Error    z Pr(>|z|)   S 2.5 % 97.5 % #>  exp(am)-2*vs=-400      817        550 1.49    0.137 2.9  -261   1896 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/hypothesis.html","id":"adjusted-predictions","dir":"Articles","previous_headings":"hypotheses Formulas","what":"Adjusted Predictions","title":"Hypothesis Tests, Equivalence Tests, and Custom Contrasts","text":"Now consider case adjusted predictions: Since term column output predictions function, must use parameter identifiers like b1, b2, etc. determine estimates want compare: directly: next section, see can get equivalent results using vector contrast weights, used compute linear combination estimates: many possibilities:","code":"p <- predictions(     mod,     newdata = datagrid(am = 0:1, vs = 0:1)) p #>  #>  Estimate Std. Error    z Pr(>|z|)     S 2.5 % 97.5 % am vs #>      14.6      0.926 15.8   <0.001 183.4  12.8   16.4  0  0 #>      21.5      1.130 19.0   <0.001 266.3  19.3   23.7  0  1 #>      20.7      1.183 17.5   <0.001 224.5  18.3   23.0  1  0 #>      27.6      1.130 24.4   <0.001 435.0  25.4   29.8  1  1 #>  #> Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, mpg, am, vs hypotheses(p, hypothesis = \"b1 = b2\") #>  #>   Term Estimate Std. Error     z Pr(>|z|)    S 2.5 % 97.5 % #>  b1=b2    -6.93       1.26 -5.49   <0.001 24.6  -9.4  -4.46 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high predictions(     mod,     hypothesis = \"b1 = b2\",     newdata = datagrid(am = 0:1, vs = 0:1)) #>  #>   Term Estimate Std. Error     z Pr(>|z|)    S 2.5 % 97.5 % #>  b1=b2    -6.93       1.26 -5.49   <0.001 24.6  -9.4  -4.46 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  p$estimate[1] - p$estimate[2] #> [1] -6.929365 predictions(     mod,     hypothesis = c(1, -1, 0, 0),     newdata = datagrid(am = 0:1, vs = 0:1)) #>  #>    Term Estimate Std. Error     z Pr(>|z|)    S 2.5 % 97.5 % #>  custom    -6.93       1.26 -5.49   <0.001 24.6  -9.4  -4.46 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high predictions(     mod,     hypothesis = \"b1 + b2 = 30\",     newdata = datagrid(am = 0:1, vs = 0:1)) #>  #>      Term Estimate Std. Error    z Pr(>|z|)    S 2.5 % 97.5 % #>  b1+b2=30     6.12       1.64 3.74   <0.001 12.4  2.91   9.32 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  p$estimate[1] + p$estimate[2] - 30 #> [1] 6.118254  predictions(     mod,     hypothesis = \"(b2 - b1) / (b3 - b2) = 0\",     newdata = datagrid(am = 0:1, vs = 0:1)) #>  #>               Term Estimate Std. Error      z Pr(>|z|)   S 2.5 % 97.5 % #>  (b2-b1)/(b3-b2)=0    -8.03         17 -0.473    0.636 0.7 -41.3   25.2 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/hypothesis.html","id":"average-contrasts-or-marginal-effects","dir":"Articles","previous_headings":"hypotheses Formulas","what":"Average contrasts or marginal effects","title":"Hypothesis Tests, Equivalence Tests, and Custom Contrasts","text":"standard workflow marginaleffects package call function like predictions(), slopes() comparisons() compute unit-level quantities; one cousins avg_predictions(), avg_comparisons(), avg_slopes() aggregate unit-level quantities “Average Marginal Effects” “Average Contrasts.” can also use comparison argument emulate behavior avg_*() functions. First, note three commands produce results: See transformations section Contrasts vignette details. results hand, can now conduct linear hypothesis test average marginal effects: Computing contrasts average marginal effects requires little care obtain right scale. particular, need specify variables comparison:","code":"comparisons(mod, variables = \"vs\")$estimate |> mean() #> [1] 6.929365  avg_comparisons(mod, variables = \"vs\") #>  #>  Term Contrast Estimate Std. Error    z Pr(>|z|)    S 2.5 % 97.5 % #>    vs    1 - 0     6.93       1.26 5.49   <0.001 24.6  4.46    9.4 #>  #> Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  comparisons(     mod,     variables = \"vs\",     comparison = \"differenceavg\") #>  #>  Term          Contrast Estimate Std. Error    z Pr(>|z|)    S 2.5 % 97.5 % #>    vs mean(1) - mean(0)     6.93       1.26 5.49   <0.001 24.6  4.46    9.4 #>  #> Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo comparisons(     mod,     hypothesis = \"am = vs\",     comparison = \"differenceavg\") #>  #>   Term Estimate Std. Error      z Pr(>|z|)   S 2.5 % 97.5 % #>  am=vs   -0.863       1.94 -0.445    0.656 0.6 -4.66   2.94 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high comparisons(     mod,     hypothesis = \"am = vs\",     variables = c(\"am\", \"vs\"),     comparison = \"dydxavg\") #>  #>   Term Estimate Std. Error      z Pr(>|z|)   S 2.5 % 97.5 % #>  am=vs   -0.863       1.94 -0.445    0.656 0.6 -4.66   2.94 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/hypothesis.html","id":"hypotheses-vectors-and-matrices","dir":"Articles","previous_headings":"","what":"hypotheses Vectors and Matrices","title":"Hypothesis Tests, Equivalence Tests, and Custom Contrasts","text":"marginal_means() function computes estimated marginal means. hypothesis argument function offers powerful mechanism estimate custom contrasts marginal means, way linear combination. Consider simple example: contrast marginal means carb==1 carb==2 : last two commands express contrast interest linear combination marginal means.","code":"library(marginaleffects) library(emmeans) library(nnet)  dat <- mtcars dat$carb <- factor(dat$carb) dat$cyl <- factor(dat$cyl) dat$am <- as.logical(dat$am)  mod <- lm(mpg ~ carb + cyl, dat) mm <- marginal_means(mod, variables = \"carb\") mm #>  #>  Term Value Mean Std. Error     z Pr(>|z|)     S 2.5 % 97.5 % #>  carb     4 18.9       1.21 15.59   <0.001 179.7  16.5   21.3 #>  carb     1 21.7       1.44 15.06   <0.001 167.8  18.8   24.5 #>  carb     2 21.3       1.23 17.29   <0.001 220.0  18.9   23.8 #>  carb     3 21.4       2.19  9.77   <0.001  72.5  17.1   25.7 #>  carb     6 19.8       3.55  5.56   <0.001  25.2  12.8   26.7 #>  carb     8 20.1       3.51  5.73   <0.001  26.6  13.2   27.0 #>  #> Results averaged over levels of: cyl, carb  #> Columns: term, value, carb, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high 21.66232 - 21.34058  #> [1] 0.32174 21.66232 + -(21.34058) #> [1] 0.32174 sum(c(21.66232, 21.34058) * c(1, -1)) #> [1] 0.32174 c(21.66232, 21.34058) %*% c(1, -1) #>         [,1] #> [1,] 0.32174"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/hypothesis.html","id":"simple-contrast","dir":"Articles","previous_headings":"hypotheses Vectors and Matrices","what":"Simple contrast","title":"Hypothesis Tests, Equivalence Tests, and Custom Contrasts","text":"marginal_means() function, can supply hypothesis argument compute linear combinations marginal means. argument must numeric vector length number rows output marginal_means(). example, previous six rows, two marginal means want compare first two positions:","code":"lc <- c(1, -1, 0, 0, 0, 0) marginal_means(mod, variables = \"carb\", hypothesis = lc) #>  #>    Term  Mean Std. Error     z Pr(>|z|)   S 2.5 % 97.5 % #>  custom -2.78       2.08 -1.34    0.181 2.5 -6.85    1.3 #>  #> Results averaged over levels of: cyl, carb  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/hypothesis.html","id":"complex-contrast","dir":"Articles","previous_headings":"hypotheses Vectors and Matrices","what":"Complex contrast","title":"Hypothesis Tests, Equivalence Tests, and Custom Contrasts","text":"course, can also estimate complex contrasts: emmeans produces similar results:","code":"lc <- c(-2, 1, 1, 0, -1, 1) marginal_means(mod, variables = \"carb\", hypothesis = lc) #>  #>    Term Mean Std. Error     z Pr(>|z|)   S 2.5 % 97.5 % #>  custom 5.59        6.2 0.901    0.367 1.4 -6.57   17.7 #>  #> Results averaged over levels of: cyl, carb  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high library(emmeans) em <- emmeans(mod, \"carb\") lc <- data.frame(custom_contrast = c(-2, 1, 1, 0, -1, 1)) contrast(em, method = lc) #>  contrast        estimate   SE df t.ratio p.value #>  custom_contrast   -0.211 6.93 24  -0.030  0.9760 #>  #> Results are averaged over the levels of: cyl"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/hypothesis.html","id":"multiple-contrasts","dir":"Articles","previous_headings":"hypotheses Vectors and Matrices","what":"Multiple contrasts","title":"Hypothesis Tests, Equivalence Tests, and Custom Contrasts","text":"Users can also compute multiple linear combinations simultaneously supplying numeric matrix hypotheses. matrix must number rows output slopes(), column represents distinct set weights different linear combinations. column names matrix become labels output. example:","code":"lc <- matrix(c(     -2, 1, 1, 0, -1, 1,     1, -1, 0, 0, 0, 0     ), ncol = 2) colnames(lc) <- c(\"Contrast A\", \"Contrast B\") lc #>      Contrast A Contrast B #> [1,]         -2          1 #> [2,]          1         -1 #> [3,]          1          0 #> [4,]          0          0 #> [5,]         -1          0 #> [6,]          1          0  marginal_means(mod, variables = \"carb\", hypothesis = lc) #>  #>        Term  Mean Std. Error      z Pr(>|z|)   S 2.5 % 97.5 % #>  Contrast A  5.59       6.20  0.901    0.367 1.4 -6.57   17.7 #>  Contrast B -2.78       2.08 -1.337    0.181 2.5 -6.85    1.3 #>  #> Results averaged over levels of: cyl, carb  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/hypothesis.html","id":"contrasts-across-response-levels","dir":"Articles","previous_headings":"hypotheses Vectors and Matrices","what":"Contrasts across response levels","title":"Hypothesis Tests, Equivalence Tests, and Custom Contrasts","text":"models multinomial outcomes, one may interested comparing outcomes contrasts across response levels. example, model 18 estimated marginal means, across 6 outcome levels (group column): Let’s contrast marginal means first outcome level cyl equals 4 6. marginal means located rows 1 7 respectively: indeed equal results obtained manually: Now let’s say want calculate “contrast contrasts”, , outcome 3-step process: Contrast cyl=6 cyl=4 1st outcome level Contrast cyl=6 cyl=4 2nd outcome level Contrast contrasts defined steps 1 2. create linear combination weights follows: make sure weights correct, can display side side original marginal_means() output: Compute results:","code":"library(nnet) mod <- multinom(carb ~ mpg + cyl, data = dat, trace = FALSE) mm <- marginal_means(mod, type = \"probs\") mm #>  #>  Group Term Value     Mean Std. Error       z Pr(>|z|)   S     2.5 %   97.5 % #>      1  cyl     6 2.83e-01   1.96e-01 1.44491   0.1485 2.8 -1.01e-01 6.67e-01 #>      1  cyl     4 3.68e-01   2.60e-01 1.41643   0.1566 2.7 -1.41e-01 8.77e-01 #>      1  cyl     8 4.63e-04   9.59e-03 0.04824   0.9615 0.1 -1.83e-02 1.93e-02 #>      2  cyl     6 1.85e-06   2.40e-06 0.77087   0.4408 1.2 -2.85e-06 6.55e-06 #>      2  cyl     4 6.31e-01   2.60e-01 2.42765   0.0152 6.0  1.22e-01 1.14e+00 #>      2  cyl     8 6.65e-01   3.74e-01 1.77961   0.0751 3.7 -6.74e-02 1.40e+00 #>      3  cyl     6 1.12e-05   1.32e-03 0.00848   0.9932 0.0 -2.58e-03 2.60e-03 #>      3  cyl     4 6.85e-04   1.19e-02 0.05748   0.9542 0.1 -2.27e-02 2.40e-02 #>      3  cyl     8 3.10e-01   3.71e-01 0.83676   0.4027 1.3 -4.17e-01 1.04e+00 #>      4  cyl     6 5.56e-01   2.18e-01 2.55000   0.0108 6.5  1.29e-01 9.84e-01 #>      4  cyl     4 2.12e-04   1.75e-02 0.01211   0.9903 0.0 -3.41e-02 3.45e-02 #>      4  cyl     8 9.58e-03   2.28e-02 0.41999   0.6745 0.6 -3.51e-02 5.43e-02 #>      6  cyl     6 1.61e-01   1.54e-01 1.04685   0.2952 1.8 -1.40e-01 4.62e-01 #>      6  cyl     4 8.82e-06   8.39e-05 0.10505   0.9163 0.1 -1.56e-04 1.73e-04 #>      6  cyl     8 4.35e-09   9.89e-08 0.04393   0.9650 0.1 -1.90e-07 1.98e-07 #>      8  cyl     6 9.29e-06   7.98e-04 0.01164   0.9907 0.0 -1.56e-03 1.57e-03 #>      8  cyl     4 1.50e-04   7.97e-03 0.01878   0.9850 0.0 -1.55e-02 1.58e-02 #>      8  cyl     8 1.41e-02   4.66e-02 0.30317   0.7618 0.4 -7.72e-02 1.05e-01 #>  #> Results averaged over levels of: mpg, cyl  #> Columns: group, term, value, cyl, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high lc <- rep(0, nrow(mm)) lc[1] <- -1 lc[7] <- 1 marginal_means(     mod,     type = \"probs\",     hypothesis = lc) #>  #>    Term   Mean Std. Error     z Pr(>|z|)   S  2.5 % 97.5 % #>  custom -0.283      0.196 -1.44    0.149 2.8 -0.667  0.101 #>  #> Results averaged over levels of: mpg, cyl  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high 2.828726e-01 - 3.678521e-01 #> [1] -0.0849795 lc <- rep(0, nrow(mm)) lc[c(1, 8)] <- -1 lc[c(7, 2)] <- 1 transform(mm[, 1:3], lc = lc) #>    group term value lc #> 1      1  cyl     6 -1 #> 2      1  cyl     4  1 #> 3      1  cyl     8  0 #> 4      2  cyl     6  0 #> 5      2  cyl     4  0 #> 6      2  cyl     8  0 #> 7      3  cyl     6  1 #> 8      3  cyl     4 -1 #> 9      3  cyl     8  0 #> 10     4  cyl     6  0 #> 11     4  cyl     4  0 #> 12     4  cyl     8  0 #> 13     6  cyl     6  0 #> 14     6  cyl     4  0 #> 15     6  cyl     8  0 #> 16     8  cyl     6  0 #> 17     8  cyl     4  0 #> 18     8  cyl     8  0 marginal_means(mod, type = \"probs\", hypothesis = lc) #>  #>    Term   Mean Std. Error     z Pr(>|z|)   S  2.5 % 97.5 % #>  custom 0.0843      0.321 0.263    0.793 0.3 -0.545  0.714 #>  #> Results averaged over levels of: mpg, cyl  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/hypothesis.html","id":"pairwise-contrasts-difference-in-differences","dir":"Articles","previous_headings":"","what":"Pairwise contrasts: Difference-in-Differences","title":"Hypothesis Tests, Equivalence Tests, and Custom Contrasts","text":"Now illustrate use machinery described pairwise comparisons contrasts, type analysis often associated “Difference--Differences” research design. First, simulate data two treatment groups pre/post periods: , estimate linear model multiple interaction time treatment indicators. also compute contrasts mean treatment level: Finally, compute pairwise differences contrasts. Diff--Diff estimate:","code":"library(data.table)  N <- 1000 did <- data.table(     id = 1:N,     pre = rnorm(N),     trt = sample(0:1, N, replace = TRUE)) did$post <- did$pre + did$trt * 0.3 + rnorm(N) did <- melt(     did,     value.name = \"y\",     variable.name = \"time\",     id.vars = c(\"id\", \"trt\")) head(did) #>    id trt time          y #> 1:  1   1  pre -1.0980291 #> 2:  2   1  pre -0.4147377 #> 3:  3   1  pre -1.6208783 #> 4:  4   1  pre  2.4596721 #> 5:  5   1  pre -0.6089537 #> 6:  6   0  pre -1.3583396 did_model <- lm(y ~ time * trt, data = did)  comparisons(     did_model,     newdata = datagrid(trt = 0:1),     variables = \"time\") #>  #>  Term   Contrast Estimate Std. Error       z Pr(>|z|)    S  2.5 % 97.5 % trt #>  time post - pre -0.00561     0.0780 -0.0718    0.943  0.1 -0.159  0.147   0 #>  time post - pre  0.28161     0.0775  3.6314   <0.001 11.8  0.130  0.434   1 #>  #> Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, y, time, trt comparisons(     did_model,     variables = \"time\",     newdata = datagrid(trt = 0:1),     hypothesis = \"pairwise\") #>  #>           Term Estimate Std. Error     z Pr(>|z|)   S  2.5 %  97.5 % #>  Row 1 - Row 2   -0.287       0.11 -2.61  0.00903 6.8 -0.503 -0.0716 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/hypothesis.html","id":"joint-hypotheses-tests","dir":"Articles","previous_headings":"","what":"Joint hypotheses tests","title":"Hypothesis Tests, Equivalence Tests, and Custom Contrasts","text":"hypotheses() function can also test multiple hypotheses jointly. example, consider model: may want test null hypothesis two coefficients jointly () equal zero. joint argument allows users flexibly specify parameters tested, using character vectors, integer indices, Perl-compatible regular expressions. can also specificy null hypothesis parameter individually using hypothesis argument. Naturally, hypotheses function also works marginaleffects objects. can also combine multiple calls hypotheses execute joint test linear combinations coefficients:","code":"model <- lm(mpg ~ as.factor(cyl) * hp, data = mtcars) coef(model) #>        (Intercept)    as.factor(cyl)6    as.factor(cyl)8                 hp as.factor(cyl)6:hp as.factor(cyl)8:hp  #>        35.98302564       -15.30917451       -17.90295193        -0.11277589         0.10516262         0.09853177 hypotheses(model, joint = c(\"as.factor(cyl)6:hp\", \"as.factor(cyl)8:hp\")) #>  #>  #> Joint hypothesis test: #> as.factor(cyl)6:hp = 0 #> as.factor(cyl)8:hp = 0 #>   #>     F Pr(>|F|) Df 1 Df 2 #>  2.11    0.142    2   26 #>  #> Columns: statistic, p.value, df1, df2 # joint hypotheses: regular expression hypotheses(model, joint = \"cyl\") #>  #>  #> Joint hypothesis test: #>  as.factor(cyl)6 = 0 #>  as.factor(cyl)8 = 0 #>  as.factor(cyl)6:hp = 0 #>  as.factor(cyl)8:hp = 0 #>   #>    F Pr(>|F|) Df 1 Df 2 #>  5.7  0.00197    4   26 #>  #> Columns: statistic, p.value, df1, df2  # joint hypotheses: integer indices hypotheses(model, joint = 2:3) #>  #>  #> Joint hypothesis test: #>  as.factor(cyl)6 = 0 #>  as.factor(cyl)8 = 0 #>   #>     F Pr(>|F|) Df 1 Df 2 #>  6.12  0.00665    2   26 #>  #> Columns: statistic, p.value, df1, df2  # joint hypotheses: different null hypotheses hypotheses(model, joint = 2:3, hypothesis = 1) #>  #>  #> Joint hypothesis test: #>  as.factor(cyl)6 = 1 #>  as.factor(cyl)8 = 1 #>   #>     F Pr(>|F|) Df 1 Df 2 #>  6.84  0.00411    2   26 #>  #> Columns: statistic, p.value, df1, df2 hypotheses(model, joint = 2:3, hypothesis = 1:2) #>  #>  #> Joint hypothesis test: #>  as.factor(cyl)6 = 1 #>  as.factor(cyl)8 = 2 #>   #>     F Pr(>|F|) Df 1 Df 2 #>  7.47  0.00273    2   26 #>  #> Columns: statistic, p.value, df1, df2  # joint hypotheses: marginaleffects object cmp <- avg_comparisons(model) hypotheses(cmp, joint = \"cyl\") #>  #>  #> Joint hypothesis test: #>  cyl 6 - 4 = 0 #>  cyl 8 - 4 = 0 #>   #>    F Pr(>|F|) Df 1 Df 2 #>  1.6    0.219    2   29 #>  #> Columns: statistic, p.value, df1, df2 # fit model mod <- lm(mpg ~ factor(carb), mtcars)  # hypothesis matrix for linear combinations H <- matrix(0, nrow = length(coef(mod)), ncol = 2) H[2:3, 1] <- H[4:6, 2] <- 1  # test individual linear combinations hyp <- hypotheses(mod, hypothesis = H) hyp #>  #>    Term Estimate Std. Error     z Pr(>|z|) 2.5 % 97.5 %   S #>  custom    -12.0       4.92 -2.44  0.01477 -21.6  -2.35 6.1 #>  custom    -25.5       9.03 -2.83  0.00466 -43.2  -7.85 7.7 #>  #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high, s.value  # test joint hypotheses hypotheses(hyp, joint = TRUE, hypothesis = c(-10, -20)) #>  #>  #> Joint hypothesis test: #>  b1 = -10 #>  b2 = -20 #>   #>      F Pr(>|F|) Df 1 Df 2 #>  0.197    0.822    2   30 #>  #> Columns: statistic, p.value, df1, df2"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/hypothesis.html","id":"equivalence-non-inferiority-and-non-superiority-tests","dir":"Articles","previous_headings":"","what":"Equivalence, non-inferiority, and non-superiority tests","title":"Hypothesis Tests, Equivalence Tests, and Custom Contrasts","text":"many contexts, analysts less interested rejecting null hypothesis, interested testing whether estimate “inferior”, “superior”, “equivalent” given threshold interval. example, medical researchers may wish determine estimated effect new treatment larger effect prior treatments, larger threshold “clinical significance.” Alternatively, researchers may wish support claim estimated parameter “equivalent ” “meaningfully different ” null hypothesis. answer questions, can use non-inferiority, non-superiority, equivalence tests like two-one-sided test (TOST). article gives primer tutorial TOST: Lakens D, Scheel , Isager PM. Equivalence Testing Psychological Research: Tutorial. Advances Methods Practices Psychological Science. 2018;1(2):259-269. doi:10.1177/2515245918770963 hypotheses() function marginaleffects package includes equivalence argument allows users apply tests quantities generated package, well arbitrary functions model’s parameters. illustrate, begin estimating simple linear regression model: rest section considers several quantities estimated marginaleffects.","code":"mod <- lm(mpg ~ hp + factor(gear), data = mtcars)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/hypothesis.html","id":"example-1-predictions","dir":"Articles","previous_headings":"Equivalence, non-inferiority, and non-superiority tests","what":"Example 1: Predictions","title":"Hypothesis Tests, Equivalence Tests, and Custom Contrasts","text":"Consider single prediction, predictors held median mode: Now specify equivalence interval (“region”) predictions 17 18: results allow us draw three conclusions: p value non-inferiority test 0.0040. suggests can reject null hypothesis parameter 17. p value non-superiority test 0.9508. suggests reject null hypothesis parameter (19.6589) 18. p value equivalence test 0.9508. suggests reject hypothesis parameter falls outside equivalence interval.","code":"p <- predictions(mod, newdata = \"median\") p #>  #>  Estimate Std. Error    z Pr(>|z|)     S 2.5 % 97.5 %  hp gear #>      19.7          1 19.6   <0.001 281.3  17.7   21.6 123    3 #>  #> Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, mpg, hp, gear hypotheses(p, equivalence = c(17, 18)) #>  #>  Estimate Std. Error    z Pr(>|z|)     S 2.5 % 97.5 %  hp gear p (NonInf) p (NonSup) p (Equiv) #>      19.7          1 19.6   <0.001 281.3  17.7   21.6 123    3    0.00404      0.951     0.951 #>  #> Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, mpg, hp, gear, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/hypothesis.html","id":"example-2-model-coefficients","dir":"Articles","previous_headings":"Equivalence, non-inferiority, and non-superiority tests","what":"Example 2: Model coefficients","title":"Hypothesis Tests, Equivalence Tests, and Custom Contrasts","text":"hypotheses function also allows users conduct equivalence, non-inferiority, non-superiority tests model coefficients, arbitrary functions model coefficients. estimate 4th coefficient model : can test parameter likely fall [5,7] interval : p value 0.3979, reject hypothesis factor(gear)5 parameter falls outside [5,7] interval.","code":"coef(mod)[4] #> factor(gear)5  #>      6.574763 hypotheses(mod, equivalence = c(5, 7))[4, ] #>  #>  Term Estimate Std. Error z Pr(>|z|) 2.5 % 97.5 %    S p (NonInf) p (NonSup) p (Equiv) #>    b4     6.57       1.64 4   <0.001  3.36   9.79 14.0      0.169      0.398     0.398 #>  #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high, s.value, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/hypothesis.html","id":"example-3-slopes","dir":"Articles","previous_headings":"Equivalence, non-inferiority, and non-superiority tests","what":"Example 3: Slopes","title":"Hypothesis Tests, Equivalence Tests, and Custom Contrasts","text":"syntax can used conduct tests quantities produced marginaleffects package. example, imagine , substantive theoretical reasons, average slope -0.1 0.1 uninteresting. can conduct equivalence test check case: p value 0.0013, suggests can reject hypothesis parameter falls outside region “substantive equivalence” defined interval.","code":"avg_slopes(mod, variables = \"hp\", equivalence = c(-.1, .1)) #>  #>  Term Estimate Std. Error     z Pr(>|z|)    S   2.5 %  97.5 % p (NonInf) p (NonSup) p (Equiv) #>    hp  -0.0669      0.011 -6.05   <0.001 29.4 -0.0885 -0.0452    0.00135     <0.001   0.00135 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/hypothesis.html","id":"example-4-difference-between-comparisons-contrasts","dir":"Articles","previous_headings":"Equivalence, non-inferiority, and non-superiority tests","what":"Example 4: Difference between comparisons (contrasts)","title":"Hypothesis Tests, Equivalence Tests, and Custom Contrasts","text":"Consider model multiplicative interaction: average contrast change 1 unit hp differs based value gear: contrasts different one another? Let’s look pairwise differences : consider pairwise comparisons “equivalent zero” fall [-.1, .1] interval: p (Equiv) column shows difference average contrasts gear 3 gear 5 can said equivalent specified interval. However, good reasons think two pairwise comparisons may fall outside interval.","code":"int <- lm(mpg ~ hp * factor(gear), data = mtcars) avg_comparisons(int, variables = \"hp\", by = \"gear\") #>  #>  Term Contrast gear Estimate Std. Error     z Pr(>|z|)    S   2.5 %  97.5 % #>    hp mean(+1)    4  -0.1792     0.0303 -5.92   <0.001 28.2 -0.2385 -0.1199 #>    hp mean(+1)    3  -0.0522     0.0146 -3.59   <0.001 11.6 -0.0808 -0.0237 #>    hp mean(+1)    5  -0.0583     0.0126 -4.61   <0.001 17.9 -0.0830 -0.0335 #>  #> Columns: term, contrast, gear, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo avg_comparisons(int, variables = \"hp\", by = \"gear\",     hypothesis = \"pairwise\") #>  #>   Term Estimate Std. Error      z Pr(>|z|)    S   2.5 %  97.5 % #>  4 - 3 -0.12695     0.0336 -3.781   <0.001 12.6 -0.1928 -0.0611 #>  4 - 5 -0.12092     0.0328 -3.688   <0.001 12.1 -0.1852 -0.0567 #>  3 - 5  0.00603     0.0193  0.313    0.754  0.4 -0.0318  0.0438 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high avg_comparisons(int, variables = \"hp\", by = \"gear\",     hypothesis = \"pairwise\",     equivalence = c(-.1, .1)) #>  #>   Term Estimate Std. Error      z Pr(>|z|)    S   2.5 %  97.5 % p (NonInf) p (NonSup) p (Equiv) #>  4 - 3 -0.12695     0.0336 -3.781   <0.001 12.6 -0.1928 -0.0611      0.789     <0.001     0.789 #>  4 - 5 -0.12092     0.0328 -3.688   <0.001 12.1 -0.1852 -0.0567      0.738     <0.001     0.738 #>  3 - 5  0.00603     0.0193  0.313    0.754  0.4 -0.0318  0.0438     <0.001     <0.001    <0.001 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/hypothesis.html","id":"example-5-marginal-means-and-emmeans","dir":"Articles","previous_headings":"Equivalence, non-inferiority, and non-superiority tests","what":"Example 5: Marginal means and emmeans","title":"Hypothesis Tests, Equivalence Tests, and Custom Contrasts","text":"example shows equivalence results produced emmeans package marginal_means() function:","code":"library(emmeans)  mod <- lm(log(conc) ~ source + factor(percent), data = pigs)  # {emmeans} emmeans(mod, specs = \"source\") |>     pairs() |>     test(df = Inf,          null = 0,          delta = log(1.25),          side = \"equivalence\",          adjust = \"none\") #>  contrast    estimate     SE  df z.ratio p.value #>  fish - soy    -0.273 0.0529 Inf   0.937  0.8257 #>  fish - skim   -0.402 0.0542 Inf   3.308  0.9995 #>  soy - skim    -0.130 0.0530 Inf  -1.765  0.0388 #>  #> Results are averaged over the levels of: percent  #> Degrees-of-freedom method: user-specified  #> Results are given on the log (not the response) scale.  #> Statistics are tests of equivalence with a threshold of 0.22314  #> P values are left-tailed  # {marginaleffects} marginal_means(     mod,     variables = \"source\",     hypothesis = \"pairwise\",     equivalence = c(-log(1.25), log(1.25))) #>  #>         Term   Mean Std. Error     z Pr(>|z|)    S  2.5 %  97.5 % p (Equiv) p (NonInf) p (NonSup) #>  fish - soy  -0.273     0.0529 -5.15   <0.001 21.9 -0.377 -0.1690    0.8257     0.8257     <0.001 #>  fish - skim -0.402     0.0542 -7.43   <0.001 43.0 -0.508 -0.2961    0.9995     0.9995     <0.001 #>  soy - skim  -0.130     0.0530 -2.44   0.0146  6.1 -0.233 -0.0255    0.0388     0.0388     <0.001 #>  #> Results averaged over levels of: percent, source  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, p.value.equiv, p.value.noninf, p.value.nonsup, statistic.noninf, statistic.nonsup"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/hypothesis.html","id":"example-6-t-test","dir":"Articles","previous_headings":"Equivalence, non-inferiority, and non-superiority tests","what":"Example 6: t-test","title":"Hypothesis Tests, Equivalence Tests, and Custom Contrasts","text":"Now show results produced hypotheses() identical results produced equivalence package case simple t-test:","code":"library(equivalence)  set.seed(1024)  # simulate data data N <- 20 dat <- data.frame(     y = rnorm(N),     x = sample(c(rep(0, N / 2), rep(1, N / 2)), N))  # fit model mod <- lm(y ~ x, data = dat)  # test with the {equivalence} package e <- tost(     x = dat$y[dat$x == 0],     y = dat$y[dat$x == 1],     epsilon = 10) e #>  #>  Welch Two Sample TOST #>  #> data:  dat$y[dat$x == 0] and dat$y[dat$x == 1] #> df = 17.607 #> sample estimates: #>  mean of x  mean of y  #> -0.3788551 -0.2724594  #>  #> Epsilon: 10  #> 95 percent two one-sided confidence interval (TOST interval): #>  -1.058539  0.845747 #> Null hypothesis of statistical difference is: rejected  #> TOST p-value: 4.248528e-13  # test with {marginaleffects} package hypotheses(mod, equivalence = c(-10, 10), df = e$parameter)[2, ] #>  #>  Term Estimate Std. Error     t Pr(>|t|) 2.5 % 97.5 %   Df   S p (NonInf) p (NonSup) p (Equiv) #>    b2    0.106      0.548 0.194    0.848 -1.05   1.26 17.6 0.2     <0.001     <0.001    <0.001 #>  #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high, df, s.value, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/lme4.html","id":"unit-level-predictions","dir":"Articles","previous_headings":"","what":"Unit-level predictions","title":"Mixed Effects Models with lme4","text":"Predict weight chick time:  Predictions chick, 4 counterfactual worlds different values Diet variable:","code":"pred1 <- predictions(fit1,                      newdata = datagrid(Chick = ChickWeight$Chick,                                         Time = 0:21))  p1 <- ggplot(pred1, aes(Time, estimate, level = Chick)) +       geom_line() +       labs(y = \"Predicted weight\", x = \"Time\", title = \"Linear growth model\")  pred2 <- predictions(fit2,                      newdata = datagrid(Chick = ChickWeight$Chick,                                         Time = 0:21))  p2 <- ggplot(pred2, aes(Time, estimate, level = Chick)) +       geom_line() +       labs(y = \"Predicted weight\", x = \"Time\", title = \"Quadratic growth model\")  p1 + p2 pred <- predictions(fit2)  ggplot(pred, aes(Time, estimate, level = Chick)) +     geom_line() +     ylab(\"Predicted Weight\") +     facet_wrap(~ Diet, labeller = label_both)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/lme4.html","id":"population-level-predictions","dir":"Articles","previous_headings":"","what":"Population-level predictions","title":"Mixed Effects Models with lme4","text":"make population-level predictions, set Chick variable NA, set re.form=NA. last argument offered lme4::predict function used behind scenes compute predictions:","code":"pred <- predictions(     fit2,     newdata = datagrid(Chick = NA,                        Diet = 1:4,                        Time = 0:21),     re.form = NA)  ggplot(pred, aes(x = Time, y = estimate, ymin = conf.low, ymax = conf.high)) +     geom_ribbon(alpha = .1, fill = \"red\") +     geom_line() +     facet_wrap(~ Diet, labeller = label_both) +     labs(title = \"Population-level trajectories\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/logit.html","id":"data","dir":"Articles","previous_headings":"","what":"Data","title":"Logistic Regression","text":"focus subset data GUSTO-study, patients randomly assigned accelerated tissue plasminogen activator (tPA) streptokinase (SK). Load libraries, data fit covariate-adjusted logistic regression model.","code":"library(marginaleffects) library(modelsummary) library(ggplot2) library(rms)  load(url( \"https://github.com/vincentarelbundock/modelarchive/raw/main/data-raw/gusto.rda\" ))  gusto <- subset(gusto, tx %in% c(\"tPA\", \"SK\")) gusto$tx <- factor(gusto$tx, levels = c(\"tPA\", \"SK\"))  mod <- glm(     day30 ~ tx + rcs(age, 4) + Killip + pmin(sysbp, 120) + lsp(pulse, 50) +     pmi + miloc + sex, family = \"binomial\",     data = gusto)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/logit.html","id":"one-number-summaries","dir":"Articles","previous_headings":"Data","what":"One-Number Summaries","title":"Logistic Regression","text":"usual, can produce one-number summary relationship interest exponentiating coefficients, yields Odds Ratio (): Unlike ORs, adjusted risk differences vary individual individual based values control variables. comparisons() function can compute adjusted risk differences every individual. , display first 6 : Population-averaged (aka “marginal”) adjusted risk difference (see vignette) can obtained using avg_*() functions using argument: comparisons() function computed predicted probability mortality (day30==1) observed row data two counterfactual cases: tx “SK”, tx “tPA”. , computed differences two sets predictions. Finally, computed population-average risk differences. Instead risk differences, compute population-averaged (marginal) adjusted risk ratios: Population-averaged (marginal) odds ratios:","code":"modelsummary(mod, exponentiate = TRUE, coef_omit = \"^(?!txSK)\") comparisons(     mod,     variables = \"tx\") #>  #>  Term Contrast Estimate Std. Error    z Pr(>|z|)   S    2.5 %  97.5 % #>    tx SK - tPA 0.001074   0.000497 2.16  0.03060 5.0 0.000101 0.00205 #>    tx SK - tPA 0.000857   0.000380 2.26  0.02410 5.4 0.000112 0.00160 #>    tx SK - tPA 0.001780   0.000779 2.29  0.02229 5.5 0.000253 0.00331 #>    tx SK - tPA 0.001137   0.000500 2.27  0.02302 5.4 0.000157 0.00212 #>    tx SK - tPA 0.001366   0.000594 2.30  0.02143 5.5 0.000202 0.00253 #> --- 30500 rows omitted. See ?avg_comparisons and ?print.marginaleffects ---  #>    tx SK - tPA 0.002429   0.000808 3.00  0.00266  8.6 0.000844 0.00401 #>    tx SK - tPA 0.012130   0.003900 3.11  0.00187  9.1 0.004486 0.01977 #>    tx SK - tPA 0.036812   0.010361 3.55  < 0.001 11.4 0.016505 0.05712 #>    tx SK - tPA 0.022969   0.006976 3.29  < 0.001 10.0 0.009297 0.03664 #>    tx SK - tPA 0.049707   0.012843 3.87  < 0.001 13.2 0.024535 0.07488 #> Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, day30, tx, age, Killip, sysbp, pulse, pmi, miloc, sex avg_comparisons(mod, variables = \"tx\") #>  #>  Term Contrast Estimate Std. Error    z Pr(>|z|)    S   2.5 % 97.5 % #>    tx SK - tPA   0.0111    0.00277 4.01   <0.001 14.0 0.00566 0.0165 #>  #> Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high avg_comparisons(     mod,     variables = \"tx\",     comparison = \"lnratioavg\",     transform = exp) #>  #>  Term                 Contrast Estimate Pr(>|z|)    S 2.5 % 97.5 % #>    tx ln(mean(SK) / mean(tPA))     1.18   <0.001 13.3  1.08   1.28 #>  #> Columns: term, contrast, estimate, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo avg_comparisons(     mod,     variables = \"tx\",     comparison = \"lnoravg\",     transform = \"exp\") #>  #>  Term                 Contrast Estimate Pr(>|z|)    S 2.5 % 97.5 % #>    tx ln(odds(SK) / odds(tPA))     1.19   <0.001 13.4  1.09    1.3 #>  #> Columns: term, contrast, estimate, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/logit.html","id":"unit-level-summaries","dir":"Articles","previous_headings":"Data","what":"Unit-level Summaries","title":"Logistic Regression","text":"Instead estimating one-number summaries, can focus unit-level proportion differences using comparisons(). function applies fitted logistic regression model predict outcome probabilities patient, .e., unit-level. Show predicted probability individual patients treatment alternatives.  can present entire distribution unit-level proportion differences cumulative distribution function:  information histogram mean median.","code":"cmp <- comparisons(mod, variables = \"tx\") cmp #>  #>  Term Contrast Estimate Std. Error    z Pr(>|z|)   S    2.5 %  97.5 % #>    tx SK - tPA 0.001074   0.000497 2.16  0.03060 5.0 0.000101 0.00205 #>    tx SK - tPA 0.000857   0.000380 2.26  0.02410 5.4 0.000112 0.00160 #>    tx SK - tPA 0.001780   0.000779 2.29  0.02229 5.5 0.000253 0.00331 #>    tx SK - tPA 0.001137   0.000500 2.27  0.02302 5.4 0.000157 0.00212 #>    tx SK - tPA 0.001366   0.000594 2.30  0.02143 5.5 0.000202 0.00253 #> --- 30500 rows omitted. See ?avg_comparisons and ?print.marginaleffects ---  #>    tx SK - tPA 0.002429   0.000808 3.00  0.00266  8.6 0.000844 0.00401 #>    tx SK - tPA 0.012130   0.003900 3.11  0.00187  9.1 0.004486 0.01977 #>    tx SK - tPA 0.036812   0.010361 3.55  < 0.001 11.4 0.016505 0.05712 #>    tx SK - tPA 0.022969   0.006976 3.29  < 0.001 10.0 0.009297 0.03664 #>    tx SK - tPA 0.049707   0.012843 3.87  < 0.001 13.2 0.024535 0.07488 #> Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, day30, tx, age, Killip, sysbp, pulse, pmi, miloc, sex ggplot(cmp, aes(predicted_hi, predicted_lo)) +   geom_point() +   geom_abline(slope = 1, intercept = 0, linetype = 3) +   coord_fixed() +   labs(x = \"SK\", y = \"tPA\") ggplot(cmp, aes(estimate)) + stat_ecdf() ggplot(cmp, aes(estimate)) +   geom_histogram(bins = 100) +   geom_vline(xintercept = mean(cmp$estimate), color = \"orange\") +   geom_vline(xintercept = median(cmp$estimate), color = \"darkgreen\") +   labs(x = \"SK - TPA\", title = \"Distribution of unit-level contrasts\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/logit.html","id":"appendix","dir":"Articles","previous_headings":"Data","what":"Appendix","title":"Logistic Regression","text":"comparisons() performed following calculations hood: original dataset contains 30510 patients, thus comparisons() generates output amount rows.","code":"d  <- gusto  d$tx = \"SK\" predicted_hi <- predict(mod, newdata = d, type = \"response\")  d$tx = \"tPA\" predicted_lo <- predict(mod, newdata = d, type = \"response\")  comparison <- predicted_hi - predicted_lo nrow(gusto) #> [1] 30510 nrow(cmp) #> [1] 30510"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/marginaleffects.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"Get Started","text":"Install latest CRAN release: Install development version: Restart R completely moving .","code":"install.packages(\"marginaleffects\") install.packages(     c(\"marginaleffects\", \"insight\"),     repos = c(\"https://vincentarelbundock.r-universe.dev\", \"https://easystats.r-universe.dev\"))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/marginaleffects.html","id":"estimands-predictions-comparisons-and-slopes","dir":"Articles","previous_headings":"","what":"Estimands: Predictions, Comparisons, and Slopes","title":"Get Started","text":"marginaleffects package allows R users compute plot three principal quantities interest: (1) predictions, (2) comparisons, (3) slopes. addition, package includes convenience function compute fourth estimand, “marginal means”, special case averaged predictions. marginaleffects can also average (“marginalize”) unit-level (“conditional”) estimates quantities, conduct hypothesis tests . Predictions: outcome predicted fitted model specified scale given combination values predictor variables, observed values, means, factor levels. .k.. Fitted values, adjusted predictions. predictions(), avg_predictions(), plot_predictions(). Comparisons: Compare predictions made model different regressor values (e.g., college graduates vs. others): contrasts, differences, risk ratios, odds, etc. comparisons(), avg_comparisons(), plot_comparisons(). Slopes: Partial derivative regression equation respect regressor interest. .k.. Marginal effects, trends. slopes(), avg_slopes(), plot_slopes(). Marginal Means: Predictions model, averaged across “reference grid” categorical predictors. marginalmeans(). Predictions, comparisons, slopes fundamentally unit-level (“conditional”) quantities. Except simplest linear case, estimates typically vary based values regressors model. observations dataset thus associated prediction, comparison, slope estimates. , see can useful marginalize (“average ”) unit-level estimates report “average prediction”, “average comparison”, “average slope”. One ambiguous aspect definitions word “marginal” comes two different opposite ways: “marginal effects,” refer effect tiny (marginal) change regressor outcome. slope, derivative. “marginal means,” refer process marginalizing across rows prediction grid. average, integral. website package, reserve expression “marginal effect” mean “slope” “partial derivative”. marginaleffects package includes functions estimate, average, plot, summarize estimands described . objects produced marginaleffects “tidy”: produce simple data frames “long” format. also “standards-compliant” work seamlessly standard functions like summary(), head(), tidy(), glance(), well external packages like modelsummary ggplot2. now apply marginaleffects functions compute estimands described . First, fit linear regression model multiplicative interactions: , call predictions() function. noted , predictions unit-level estimates, one specific prediction per observation. default, predictions() function makes one prediction per observation dataset used fit original model. Since mtcars 32 rows, predictions() outcome also 32 rows: Now, use comparisons() function compute difference predicted outcome predictors incremented 1 unit (one predictor time, holding others constant). , comparisons unit-level quantities. since 3 predictors model data 32 rows, obtain 96 comparisons: comparisons() function allows customized queries. example, happens predicted outcome hp variable increases 100 120? happens predicted outcome wt variable increases 1 standard deviation mean? comparisons() function also allows users specify arbitrary functions predictions, comparison argument. example, average ratio predicted Miles per Gallon increase 50 units Horsepower? See Comparisons vignette detailed explanations options. slopes() function allows us compute partial derivative outcome equation respect predictors. , obtain data frame 96 rows:","code":"library(marginaleffects)  mod <- lm(mpg ~ hp * wt * am, data = mtcars) pre <- predictions(mod)  nrow(mtcars) ## [1] 32 nrow(pre) ## [1] 32 pre ##  ##  Estimate Std. Error     z Pr(>|z|)     S 2.5 % 97.5 % ##      22.5      0.884 25.44   <0.001 471.7  20.8   24.2 ##      20.8      1.194 17.42   <0.001 223.3  18.5   23.1 ##      25.3      0.709 35.66   <0.001 922.7  23.9   26.7 ##      20.3      0.704 28.75   <0.001 601.5  18.9   21.6 ##      17.0      0.712 23.88   <0.001 416.2  15.6   18.4 ## --- 22 rows omitted. See ?avg_predictions and ?print.marginaleffects ---  ##      29.6      1.874 15.80   <0.001 184.3  25.9   33.3 ##      15.9      1.311 12.13   <0.001 110.0  13.3   18.5 ##      19.4      1.145 16.95   <0.001 211.6  17.2   21.7 ##      14.8      2.017  7.33   <0.001  42.0  10.8   18.7 ##      21.5      1.072 20.02   <0.001 293.8  19.4   23.6 ## Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, mpg, hp, wt, am cmp <- comparisons(mod)  nrow(cmp) ## [1] 96 cmp ##  ##  Term Contrast Estimate Std. Error      z Pr(>|z|)   S   2.5 %    97.5 % ##    hp    +1     -0.0369     0.0185 -1.995  0.04607 4.4 -0.0732 -0.000643 ##    hp    +1     -0.0287     0.0156 -1.836  0.06640 3.9 -0.0593  0.001942 ##    hp    +1     -0.0466     0.0226 -2.062  0.03922 4.7 -0.0908 -0.002302 ##    hp    +1     -0.0423     0.0133 -3.182  0.00146 9.4 -0.0683 -0.016238 ##    hp    +1     -0.0390     0.0134 -2.909  0.00362 8.1 -0.0653 -0.012734 ## --- 86 rows omitted. See ?avg_comparisons and ?print.marginaleffects ---  ##    am    1 - 0   4.0807     3.9351  1.037  0.29973 1.7 -3.6319 11.793387 ##    am    1 - 0   2.1064     2.2892  0.920  0.35751 1.5 -2.3804  6.593103 ##    am    1 - 0   0.8951     1.6442  0.544  0.58618 0.8 -2.3275  4.117620 ##    am    1 - 0   4.0272     3.2402  1.243  0.21391 2.2 -2.3235 10.377969 ##    am    1 - 0  -0.2369     1.5864 -0.149  0.88129 0.2 -3.3462  2.872416 ## Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, mpg, hp, wt, am comparisons(mod, variables = list(hp = c(120, 100))) ##  ##  Term  Contrast Estimate Std. Error      z Pr(>|z|)   S  2.5 %  97.5 % ##    hp 120 - 100   -0.738      0.370 -1.995  0.04607 4.4 -1.463 -0.0129 ##    hp 120 - 100   -0.574      0.313 -1.836  0.06640 3.9 -1.186  0.0388 ##    hp 120 - 100   -0.931      0.452 -2.062  0.03922 4.7 -1.817 -0.0460 ##    hp 120 - 100   -0.845      0.266 -3.182  0.00146 9.4 -1.366 -0.3248 ##    hp 120 - 100   -0.780      0.268 -2.909  0.00362 8.1 -1.306 -0.2547 ## --- 22 rows omitted. See ?avg_comparisons and ?print.marginaleffects ---  ##    hp 120 - 100   -1.451      0.705 -2.058  0.03958 4.7 -2.834 -0.0692 ##    hp 120 - 100   -0.384      0.270 -1.422  0.15498 2.7 -0.912  0.1451 ##    hp 120 - 100   -0.641      0.334 -1.918  0.05513 4.2 -1.297  0.0141 ##    hp 120 - 100   -0.126      0.272 -0.463  0.64360 0.6 -0.659  0.4075 ##    hp 120 - 100   -0.635      0.332 -1.911  0.05598 4.2 -1.286  0.0162 ## Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, mpg, hp, wt, am comparisons(mod, variables = list(hp = \"sd\")) ##  ##  Term                Contrast Estimate Std. Error      z Pr(>|z|)   S 2.5 %  97.5 % ##    hp (x + sd/2) - (x - sd/2)   -2.530      1.269 -1.995  0.04607 4.4 -5.02 -0.0441 ##    hp (x + sd/2) - (x - sd/2)   -1.967      1.072 -1.836  0.06640 3.9 -4.07  0.1332 ##    hp (x + sd/2) - (x - sd/2)   -3.193      1.549 -2.062  0.03922 4.7 -6.23 -0.1578 ##    hp (x + sd/2) - (x - sd/2)   -2.898      0.911 -3.182  0.00146 9.4 -4.68 -1.1133 ##    hp (x + sd/2) - (x - sd/2)   -2.675      0.919 -2.909  0.00362 8.1 -4.48 -0.8731 ## --- 22 rows omitted. See ?avg_comparisons and ?print.marginaleffects ---  ##    hp (x + sd/2) - (x - sd/2)   -4.976      2.418 -2.058  0.03958 4.7 -9.71 -0.2373 ##    hp (x + sd/2) - (x - sd/2)   -1.315      0.925 -1.422  0.15498 2.7 -3.13  0.4974 ##    hp (x + sd/2) - (x - sd/2)   -2.199      1.147 -1.918  0.05513 4.2 -4.45  0.0483 ##    hp (x + sd/2) - (x - sd/2)   -0.432      0.933 -0.463  0.64360 0.6 -2.26  1.3970 ##    hp (x + sd/2) - (x - sd/2)   -2.177      1.139 -1.911  0.05598 4.2 -4.41  0.0556 ## Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, mpg, hp, wt, am comparisons(   mod,   variables = list(hp = 50),   comparison = \"ratioavg\") ##  ##  Term  Contrast Estimate Std. Error    z Pr(>|z|)     S 2.5 % 97.5 % ##    hp mean(+50)     0.91     0.0291 31.3   <0.001 712.0 0.853  0.966 ##  ## Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo mfx <- slopes(mod)  nrow(mfx) ## [1] 96 mfx ##  ##  Term Contrast Estimate Std. Error      z Pr(>|z|)   S   2.5 %    97.5 % ##    hp    dY/dX  -0.0369     0.0185 -1.995  0.04607 4.4 -0.0732 -0.000643 ##    hp    dY/dX  -0.0287     0.0156 -1.836  0.06640 3.9 -0.0593  0.001942 ##    hp    dY/dX  -0.0466     0.0226 -2.062  0.03922 4.7 -0.0908 -0.002302 ##    hp    dY/dX  -0.0423     0.0133 -3.182  0.00146 9.4 -0.0683 -0.016237 ##    hp    dY/dX  -0.0390     0.0134 -2.909  0.00362 8.1 -0.0653 -0.012734 ## --- 86 rows omitted. See ?avg_slopes and ?print.marginaleffects ---  ##    am    1 - 0   4.0807     3.9351  1.037  0.29973 1.7 -3.6319 11.793387 ##    am    1 - 0   2.1064     2.2892  0.920  0.35751 1.5 -2.3804  6.593103 ##    am    1 - 0   0.8951     1.6442  0.544  0.58618 0.8 -2.3275  4.117620 ##    am    1 - 0   4.0272     3.2402  1.243  0.21391 2.2 -2.3235 10.377969 ##    am    1 - 0  -0.2369     1.5864 -0.149  0.88129 0.2 -3.3462  2.872416 ## Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, mpg, hp, wt, am"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/marginaleffects.html","id":"grid","dir":"Articles","previous_headings":"","what":"Grid","title":"Get Started","text":"Predictions, comparisons, slopes typically “conditional” quantities depend values predictors model. default, marginaleffects functions estimate quantities interest empirical distribution data (.e., row original dataset). However, users can specify exact values predictors want investigate using newdata argument. newdata accepts data frames, shortcut strings, call datagrid() function. example, compute predicted outcome hypothetical car predictors equal sample mean median, can : datagrid function gives us powerful way define grid predictors. variables mentioned explicitly datagrid() fixed mean mode: mechanism available comparisons() slopes(). estimate partial derivative mpg respect wt, equal 0 1, predictors held means: can also plot predictions, comparisons, slopes change across different values predictors using three powerful plotting functions: plot_predictions: Conditional Adjusted Predictions plot_comparisons: Conditional Comparisons plot_slopes: Conditional Marginal Effects example, plot shows outcomes predicted model different values wt variables:  plot shows derivative mpg respect varies function wt hp:  See vignette information: Plots, interactions, predictions, contrasts, slopes","code":"predictions(mod, newdata = \"mean\") ##  ##  Estimate Std. Error  z Pr(>|z|)     S 2.5 % 97.5 %  hp   wt    am ##      18.4       0.68 27   <0.001 531.7    17   19.7 147 3.22 0.406 ##  ## Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, mpg, hp, wt, am predictions(mod, newdata = \"median\") ##  ##  Estimate Std. Error    z Pr(>|z|)     S 2.5 % 97.5 %  hp   wt    am ##      18.7      0.819 22.8   <0.001 379.8  17.1   20.3 123 3.33 0.406 ##  ## Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, mpg, hp, wt, am predictions(   mod,   newdata = datagrid(     am = c(0, 1),     wt = range)) ##  ##  Estimate Std. Error    z Pr(>|z|)    S 2.5 % 97.5 %  hp am   wt ##      23.3       2.71 8.60   <0.001 56.7 17.96   28.6 147  0 1.51 ##      12.8       2.98 4.30   <0.001 15.8  6.96   18.6 147  0 5.42 ##      27.1       2.85 9.52   <0.001 69.0 21.56   32.7 147  1 1.51 ##       5.9       5.81 1.01     0.31  1.7 -5.50   17.3 147  1 5.42 ##  ## Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, mpg, hp, am, wt slopes(   mod,   variables = \"wt\",   newdata = datagrid(am = 0:1)) ##  ##  Term Estimate Std. Error     z Pr(>|z|)   S 2.5 % 97.5 %  hp   wt am ##    wt    -2.68       1.42 -1.89   0.0594 4.1 -5.46  0.106 147 3.22  0 ##    wt    -5.43       2.15 -2.52   0.0116 6.4 -9.65 -1.214 147 3.22  1 ##  ## Columns: rowid, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, mpg, hp, wt, am plot_predictions(mod, condition = list(\"hp\", \"wt\" = \"threenum\", \"am\")) plot_slopes(mod, variables = \"am\", condition = list(\"hp\", \"wt\" = \"minmax\"))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/marginaleffects.html","id":"averaging","dir":"Articles","previous_headings":"","what":"Averaging","title":"Get Started","text":"Since predictions, comparisons, slopes conditional quantities, can bit unwieldy. Often, can useful report one-number summary instead one estimate per observation. Instead presenting “conditional” estimates, methodologists recommend reporting “marginal” estimates, , average unit-level estimates. (use word “marginal” “averaging” confused term “marginal effect” , econometrics tradition, corresponds partial derivative, effect “small/marginal” change.) marginalize (average ) unit-level estimates, can use argument one convenience functions: avg_predictions(), avg_comparisons(), avg_slopes(). example, commands give us result: average predicted outcome mtcars dataset: equivalent manual computation : main marginaleffects functions include argument, allows us marginalize within sub-groups data. example, Marginal Means special case predictions, marginalized (averaged) across balanced grid categorical predictors. illustrate, estimate new model categorical predictors: can compute marginal means manually using functions already described: convenience, marginaleffects package also includes marginal_means() function: Marginal Means vignette offers detail.","code":"avg_predictions(mod) ##  ##  Estimate Std. Error    z Pr(>|z|)   S 2.5 % 97.5 % ##      20.1       0.39 51.5   <0.001 Inf  19.3   20.9 ##  ## Columns: estimate, std.error, statistic, p.value, s.value, conf.low, conf.high mean(predict(mod)) ## [1] 20.09062 avg_comparisons(mod, by = \"am\") ##  ##  Term          Contrast am Estimate Std. Error      z Pr(>|z|)   S   2.5 %   97.5 % ##    hp mean(+1)           1  -0.0436     0.0213 -2.050  0.04039 4.6 -0.0854 -0.00191 ##    hp mean(+1)           0  -0.0343     0.0159 -2.160  0.03079 5.0 -0.0654 -0.00317 ##    wt mean(+1)           1  -6.0718     1.9762 -3.072  0.00212 8.9 -9.9451 -2.19846 ##    wt mean(+1)           0  -2.4799     1.2316 -2.014  0.04406 4.5 -4.8939 -0.06595 ##    am mean(1) - mean(0)  1   1.9029     2.3086  0.824  0.40980 1.3 -2.6219  6.42773 ##    am mean(1) - mean(0)  0  -1.3830     2.5250 -0.548  0.58388 0.8 -6.3319  3.56589 ##  ## Columns: term, contrast, am, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo dat <- mtcars dat$am <- as.logical(dat$am) dat$cyl <- as.factor(dat$cyl) mod_cat <- lm(mpg ~ am + cyl + hp, data = dat) avg_predictions(   mod_cat,   newdata = datagrid(cyl = unique, am = unique),   by = \"am\") ##  ##     am Estimate Std. Error    z Pr(>|z|)     S 2.5 % 97.5 % ##   TRUE     22.5      0.834 26.9   <0.001 528.6  20.8   24.1 ##  FALSE     18.3      0.785 23.3   <0.001 397.4  16.8   19.9 ##  ## Columns: am, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high marginal_means(mod_cat, variables = \"am\") ##  ##  Term Value Mean Std. Error    z Pr(>|z|)     S 2.5 % 97.5 % ##    am  TRUE 22.5      0.834 26.9   <0.001 528.6  20.8   24.1 ##    am FALSE 18.3      0.785 23.3   <0.001 397.4  16.8   19.9 ##  ## Results averaged over levels of: cyl, am  ## Columns: term, value, am, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/marginaleffects.html","id":"hypothesis-and-equivalence-tests","dir":"Articles","previous_headings":"","what":"Hypothesis and equivalence tests","title":"Get Started","text":"hypotheses() function hypothesis argument can used conduct linear non-linear hypothesis tests model coefficients, quantities computed functions introduced . Consider model: Can reject null hypothesis drat coefficient 2 times size qsec coefficient? can ask question refer parameters position, indices b1, b2, b3, etc.: main functions marginaleffects hypothesis argument, means can complex model testing. example, consider two slope estimates: two slopes significantly different one another? test , can use hypothesis argument: Now, imagine theoretical (substantive clinical) reasons, care slopes larger 2. can use hypotheses() function conduct equivalence test: See Hypothesis Tests Custom Contrasts vignette background, details, instructions conduct hypothesis tests complex situations.","code":"mod <- lm(mpg ~ qsec * drat, data = mtcars) coef(mod) ## (Intercept)        qsec        drat   qsec:drat  ##  12.3371987  -1.0241183  -3.4371461   0.5973153 hypotheses(mod, \"drat = 2 * qsec\") ##  ##             Term Estimate Std. Error      z Pr(>|z|) 2.5 % 97.5 %   S ##  drat = 2 * qsec    -1.39       10.8 -0.129    0.897 -22.5   19.7 0.2 ##  ## Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high, s.value hypotheses(mod, \"b3 = 2 * b2\") ##  ##         Term Estimate Std. Error      z Pr(>|z|) 2.5 % 97.5 %   S ##  b3 = 2 * b2    -1.39       10.8 -0.129    0.897 -22.5   19.7 0.2 ##  ## Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high, s.value slopes(   mod,   variables = \"drat\",   newdata = datagrid(qsec = range)) ##  ##  Term Estimate Std. Error    z Pr(>|z|)   S  2.5 % 97.5 % drat qsec ##  drat     5.22       3.79 1.38   0.1682 2.6 -2.206   12.7  3.6 14.5 ##  drat    10.24       5.16 1.98   0.0472 4.4  0.125   20.4  3.6 22.9 ##  ## Columns: rowid, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, mpg, drat, qsec slopes(   mod,   hypothesis = \"b1 = b2\",   variables = \"drat\",   newdata = datagrid(qsec = range)) ##  ##   Term Estimate Std. Error      z Pr(>|z|)   S 2.5 % 97.5 % ##  b1=b2    -5.02       8.52 -0.589    0.556 0.8 -21.7   11.7 ##  ## Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high avg_slopes(mod) |> hypotheses(equivalence = c(-2, 2)) ##  ##  Term Estimate Std. Error    z Pr(>|z|)    S 2.5 % 97.5 % p (NonInf) p (NonSup) p (Equiv) ##  qsec     1.12      0.433 2.60  0.00945  6.7 0.275   1.97     <0.001     0.0216    0.0216 ##  drat     7.22      1.365 5.29  < 0.001 23.0 4.548   9.90     <0.001     0.9999    0.9999 ##  ## Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/marginaleffects.html","id":"more","dir":"Articles","previous_headings":"","what":"More!","title":"Get Started","text":"much can marginaleffects. Return Table Contents read vignettes, learn report marginal effects nice tables modelsummary package, define prediction “grid”, much . ****","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/marginalmeans.html","id":"marginal-means-vs--average-predictions","dir":"Articles","previous_headings":"","what":"Marginal Means vs. Average Predictions","title":"Marginal Means","text":"scientists report? Marginal means average predictions? Many analysts ask question, unfortunately isn’t single answer. explained , marginal means special case predictions, made perfectly balanced grid categorical predictors, numeric predictors held means, marginalized respect focal variables. Whether analyst prefers report specific type marginal means another kind average prediction depend characteristics sample population want generalize. reading vignette discussion emmeans Alternative Software vignette, may want consult statistician discuss specific real-world problem make informed choice.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/marginalmeans.html","id":"interactions","dir":"Articles","previous_headings":"","what":"Interactions","title":"Marginal Means","text":"default, marginal_means() function calculates marginal means categorical predictor one . can also compute marginal means combinations categories setting cross=TRUE: Regardless scale predictions (type argument), marginal_means() always computes standard errors using Delta Method: model linear link scale, also produces confidence intervals: easy transform link-scale marginal means arbitrary functions using transform argument: marginal_means() defaults reporting EMMs category individually, without cross-margins: can force cross:","code":"library(lme4)  dat <- \"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Titanic.csv\" dat <- read.csv(dat) titanic <- glmer(     Survived ~ Sex * PClass + Age + (1 | PClass),     family = binomial,     data = dat) marginal_means(     titanic,     type = \"response\",     variables = c(\"Sex\", \"PClass\")) #>  #>    Term  Value  Mean Std. Error     z Pr(>|z|)     S 2.5 % 97.5 % #>  Sex    female 0.738     0.0207 35.68   <0.001 923.8 0.698  0.779 #>  Sex    male   0.235     0.0203 11.62   <0.001 101.3 0.196  0.275 #>  PClass 1st    0.708     0.0273 25.95   <0.001 490.9 0.654  0.761 #>  PClass 2nd    0.511     0.0235 21.76   <0.001 346.4 0.465  0.557 #>  PClass 3rd    0.242     0.0281  8.59   <0.001  56.7 0.187  0.297 #>  #> Results averaged over levels of: Sex, PClass  #> Columns: term, value, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high marginal_means(     titanic,     type = \"link\",     variables = c(\"Sex\", \"PClass\")) #>  #>    Term  Value    Mean Std. Error       z Pr(>|z|)    S  2.5 % 97.5 % #>  Sex    female  1.6407      0.206   7.984   <0.001 49.3  1.238  2.043 #>  Sex    male   -1.3399      0.124 -10.828   <0.001 88.3 -1.582 -1.097 #>  PClass 1st     1.6307      0.271   6.028   <0.001 29.2  1.100  2.161 #>  PClass 2nd     0.0997      0.211   0.472    0.637  0.7 -0.314  0.513 #>  PClass 3rd    -1.2792      0.155  -8.255   <0.001 52.6 -1.583 -0.975 #>  #> Results averaged over levels of: Sex, PClass  #> Columns: term, value, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high marginal_means(     titanic,     type = \"link\",     transform = insight::link_inverse(titanic),     variables = c(\"Sex\", \"PClass\")) #>  #>    Term  Value  Mean Pr(>|z|)    S 2.5 % 97.5 % #>  Sex    female 0.838   <0.001 49.3 0.775  0.885 #>  Sex    male   0.208   <0.001 88.3 0.170  0.250 #>  PClass 1st    0.836   <0.001 29.2 0.750  0.897 #>  PClass 2nd    0.525    0.637  0.7 0.422  0.626 #>  PClass 3rd    0.218   <0.001 52.6 0.170  0.274 #>  #> Results averaged over levels of: Sex, PClass  #> Columns: term, value, estimate, p.value, s.value, conf.low, conf.high titanic2 <- glmer(     Survived ~ Sex + PClass + Age + (1 | PClass),     family = binomial,     data = dat)  marginal_means(     titanic2,     variables = c(\"Sex\", \"PClass\")) #>  #>    Term  Value  Mean Std. Error    z Pr(>|z|)     S 2.5 % 97.5 % #>  Sex    female 0.741     0.0240 30.8   <0.001 691.0 0.694  0.788 #>  Sex    male   0.253     0.0203 12.5   <0.001 116.0 0.213  0.293 #>  PClass 1st    0.707     0.0289 24.5   <0.001 436.5 0.650  0.763 #>  PClass 2nd    0.494     0.0287 17.2   <0.001 217.5 0.437  0.550 #>  PClass 3rd    0.291     0.0268 10.9   <0.001  88.8 0.238  0.344 #>  #> Results averaged over levels of: Sex, PClass  #> Columns: term, value, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high marginal_means(     titanic2,     cross = TRUE,     variables = c(\"Sex\", \"PClass\")) #>  #>    Mean Std. Error     z Pr(>|z|)     S  2.5 % 97.5 % #>  0.9288     0.0161 57.71   <0.001   Inf 0.8973 0.9604 #>  0.7819     0.0357 21.93   <0.001 351.8 0.7120 0.8518 #>  0.5118     0.0458 11.17   <0.001  93.8 0.4220 0.6017 #>  0.4844     0.0468 10.35   <0.001  81.0 0.3926 0.5761 #>  0.2051     0.0308  6.66   <0.001  35.1 0.1448 0.2655 #>  0.0702     0.0135  5.18   <0.001  22.1 0.0436 0.0967 #>  #> Columns: Sex, PClass, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/marginalmeans.html","id":"group-averages-with-the-by-argument","dir":"Articles","previous_headings":"","what":"Group averages with the by argument","title":"Marginal Means","text":"can collapse marginal means via averaging using argument: can use hypothesis argument compare new collapsed subgroups:","code":"dat <- mtcars dat$am <- factor(dat$am) dat$vs <- factor(dat$vs) dat$cyl <- factor(dat$cyl)  mod <- glm(gear ~ cyl + vs + am, data = dat, family = poisson)  by <- data.frame(     by = c(\"(4 & 6)\", \"(4 & 6)\", \"(8)\"),     cyl = c(4, 6, 8))  marginal_means(mod, by = by, variables = \"cyl\") #>  #>       By Mean Pr(>|z|)    S 2.5 % 97.5 % #>  (4 & 6) 3.86   <0.001 59.1  2.86   5.22 #>  (8)     3.59   <0.001 18.5  2.11   6.13 #>  #> Results averaged over levels of: vs, am, cyl  #> Columns: by, estimate, p.value, s.value, conf.low, conf.high marginal_means(mod, by = by, variables = \"cyl\", hypothesis = \"pairwise\") #>  #>           Term  Mean Std. Error     z Pr(>|z|)   S 2.5 % 97.5 % #>  (4 & 6) - (8) 0.271       1.39 0.195    0.845 0.2 -2.45      3 #>  #> Results averaged over levels of: vs, am, cyl  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/marginalmeans.html","id":"custom-contrasts-and-linear-combinations","dir":"Articles","previous_headings":"","what":"Custom Contrasts and Linear Combinations","title":"Marginal Means","text":"See vignette Custom Contrasts Combinations","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/marginalmeans.html","id":"tidy-summaries","dir":"Articles","previous_headings":"","what":"Tidy summaries","title":"Marginal Means","text":"summary, tidy, glance functions also available summarize manipulate results: Thanks tidiers, can also present results style regression table using modelsummary package. examples, see tables plots vignette.","code":"mm <- marginal_means(mod)  tidy(mm) #> # A tibble: 7 × 7 #>   term  value estimate  p.value conf.low conf.high s.value #>   <chr> <fct>    <dbl>    <dbl>    <dbl>     <dbl>   <dbl> #> 1 cyl   6         3.90 1.57e-12     2.67      5.68    39.2 #> 2 cyl   4         3.83 2.34e- 8     2.39      6.13    25.4 #> 3 cyl   8         3.59 2.66e- 6     2.11      6.13    18.5 #> 4 vs    0         3.79 1.88e-12     2.62      5.50    39.0 #> 5 vs    1         3.75 5.82e-10     2.47      5.69    30.7 #> 6 am    1         4.34 6.83e-19     3.14      6.01    60.3 #> 7 am    0         3.27 3.96e-15     2.43      4.40    47.8  glance(mm) #> # A tibble: 1 × 7 #>     aic   bic r2.nagelkerke  rmse  nobs     F logLik    #>   <dbl> <dbl>         <dbl> <dbl> <int> <dbl> <logLik>  #> 1  113.  120.         0.672 0.437    32 0.737 -51.50168  summary(mm) #>  #>  Term Value Mean Pr(>|z|)    S 2.5 % 97.5 % #>   cyl     6 3.90   <0.001 39.2  2.67   5.68 #>   cyl     4 3.83   <0.001 25.4  2.39   6.13 #>   cyl     8 3.59   <0.001 18.5  2.11   6.13 #>   vs      0 3.79   <0.001 39.0  2.62   5.50 #>   vs      1 3.75   <0.001 30.7  2.47   5.69 #>   am      1 4.34   <0.001 60.3  3.14   6.01 #>   am      0 3.27   <0.001 47.8  2.43   4.40 #>  #> Results averaged over levels of: cyl, vs, am  #> Columns: term, value, estimate, p.value, s.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/marginalmeans.html","id":"case-study-multinomial-logit","dir":"Articles","previous_headings":"","what":"Case study: Multinomial Logit","title":"Marginal Means","text":"example requires version 0.2.0 marginaleffects package. begin, generate data estimate large model: Try compute marginal means, realize grid won’t fit memory: Use variables variables_grid arguments compute marginal means reasonably sized grid:","code":"library(nnet) library(marginaleffects)  set.seed(1839) n <- 1200 x <- factor(sample(letters[1:3], n, TRUE)) y <- vector(length = n) y[x == \"a\"] <- sample(letters[4:6], sum(x == \"a\"), TRUE) y[x == \"b\"] <- sample(letters[4:6], sum(x == \"b\"), TRUE, c(1 / 4, 2 / 4, 1 / 4)) y[x == \"c\"] <- sample(letters[4:6], sum(x == \"c\"), TRUE, c(1 / 5, 3 / 5, 2 / 5))  dat <- data.frame(x = x, y = factor(y)) tmp <- as.data.frame(replicate(20, factor(sample(letters[7:9], n, TRUE)))) dat <- cbind(dat, tmp) void <- capture.output({     mod <- multinom(y ~ ., dat) }) marginal_means(mod, type = \"probs\") #> Error: You are trying to create a prediction grid with more than 1 billion rows, which is likely to exceed the memory and computational power available on your local machine. Presumably this is because you are considering many variables with many levels. All of the functions in the `marginaleffects` package include arguments to specify a restricted list of variables over which to create a prediction grid. marginal_means(mod,               type = \"probs\",               variables = c(\"x\", \"V1\"),               variables_grid = paste0(\"V\", 2:3))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/marginalmeans.html","id":"plot-conditional-marginal-means","dir":"Articles","previous_headings":"","what":"Plot conditional marginal means","title":"Marginal Means","text":"marginaleffects package offers several functions plot quantities vary function others: plot_predictions: Conditional adjusted predictions – predicted outcome change function regressors? plot_comparisons: Conditional comparisons – contrasts change function regressors? plot_slopes: Conditional marginal effects – slope change function regressors? analogous function marginal means. However, easy achieve similar effect using predictions() function, argument, standard plotting functions. example , take steps: Estimate model one continuous (hp) one categorical regressor (cyl). Create perfectly “balanced” data grid combination hp cyl. specified user datagrid() call. Compute fitted values (aka “adjusted predictions”) cell grid. Use argument take average predicted values value hp, across margins cyl. Compute standard errors around averaged predicted values (.e., marginal means). Create symmetric confidence intervals usual manner. Plot results.","code":"library(ggplot2)  mod <- lm(mpg ~ hp + factor(cyl), data = mtcars)  p <- predictions(mod,     by = \"hp\",     newdata = datagrid(         model = mod,         hp = seq(100, 120, length.out = 10),         cyl = mtcars$cyl))  ggplot(p) +     geom_ribbon(aes(hp, ymin = conf.low, ymax = conf.high), alpha = .2) +     geom_line(aes(hp, estimate))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/multiple_imputation.html","id":"mice","dir":"Articles","previous_headings":"","what":"mice","title":"Multiple Imputation and Missing Data","text":"First, insert missing observations randomly dataset impute dataset using mice package: , use standard mice syntax produce object class mira models: Finally, feed mira object marginaleffects function:","code":"library(mice) library(marginaleffects) set.seed(1024)  dat <- iris dat$Sepal.Length[sample(seq_len(nrow(iris)), 40)] <- NA dat$Sepal.Width[sample(seq_len(nrow(iris)), 40)] <- NA dat$Species[sample(seq_len(nrow(iris)), 40)] <- NA  dat_mice <- mice(dat, m = 20, printFlag = FALSE, .Random.seed = 1024) mod_mice <- with(dat_mice, lm(Petal.Width ~ Sepal.Length * Sepal.Width + Species)) mfx_mice <- avg_slopes(mod_mice, by = \"Species\") mfx_mice #>  #>          Term                        Contrast    Species Estimate Std. Error     S    Df      t Pr(>|t|)   2.5 % 97.5 % #>  Sepal.Length mean(dY/dX)                     setosa       0.0684     0.0560   2.2 120.0  1.222  0.22413 -0.0424  0.179 #>  Sepal.Length mean(dY/dX)                     versicolor   0.0540     0.0557   1.6  91.1  0.969  0.33507 -0.0567  0.165 #>  Sepal.Length mean(dY/dX)                     virginica    0.0582     0.0513   2.0 104.6  1.136  0.25869 -0.0434  0.160 #>  Sepal.Width  mean(dY/dX)                     setosa       0.1890     0.0836   5.4 400.4  2.260  0.02434  0.0246  0.353 #>  Sepal.Width  mean(dY/dX)                     versicolor   0.2093     0.0792   6.7  89.2  2.643  0.00971  0.0519  0.367 #>  Sepal.Width  mean(dY/dX)                     virginica    0.2241     0.1026   4.9  61.2  2.185  0.03272  0.0190  0.429 #>  Species      mean(versicolor) - mean(setosa) setosa       1.1399     0.0977  68.1 114.8 11.668  < 0.001  0.9464  1.333 #>  Species      mean(versicolor) - mean(setosa) versicolor   1.1399     0.0977  68.1 114.8 11.668  < 0.001  0.9464  1.333 #>  Species      mean(versicolor) - mean(setosa) virginica    1.1399     0.0977  68.1 114.8 11.668  < 0.001  0.9464  1.333 #>  Species      mean(virginica) - mean(setosa)  setosa       1.7408     0.1108 100.7 121.6 15.709  < 0.001  1.5214  1.960 #>  Species      mean(virginica) - mean(setosa)  versicolor   1.7408     0.1108 100.7 121.6 15.709  < 0.001  1.5214  1.960 #>  Species      mean(virginica) - mean(setosa)  virginica    1.7408     0.1108 100.7 121.6 15.709  < 0.001  1.5214  1.960 #>  #> Columns: term, contrast, Species, estimate, std.error, s.value, predicted, predicted_hi, predicted_lo, df, statistic, p.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/multiple_imputation.html","id":"other-imputation-packages-amelia-missranger-or-lists-of-imputed-data-frames-","dir":"Articles","previous_headings":"","what":"Other imputation packages: Amelia, missRanger, or lists of imputed data frames.","title":"Multiple Imputation and Missing Data","text":"Several R packages can impute missing data. Indeed, Missing Data CRAN View lists least dozen alternatives. Since user interface changes lot package package, marginaleffects supports single workflow can used, adaptation, imputation packages: Use external package create list imputed data frames. Apply datalist2mids() function miceadds package convert list imputed data frames mids object. Use () function fit models, illustrated mice section . Pass mids object marginaleffects function. Consider two imputation packages, can generate lists imputed datasets: Amelia missRanger.","code":"library(Amelia) library(miceadds) library(missRanger)  # impute data dat_amelia <- amelia(dat, noms = \"Species\", p2s = 0)$imputations mids_amelia <- datlist2mids(dat_amelia)  # convert lists of imputed datasets to `mids` objects dat_missRanger <- replicate(20, missRanger(dat, verbose = 0), simplify = FALSE) mids_missRanger <- datlist2mids(dat_missRanger)  # fit models mod_amelia <- with(mids_amelia, lm(Petal.Width ~ Sepal.Length * Sepal.Width + Species)) mod_missRanger <- with(mids_missRanger, lm(Petal.Width ~ Sepal.Length * Sepal.Width + Species))  # `Amelia` slopes mfx_amelia <- avg_slopes(mod_amelia, by = \"Species\") mfx_amelia #>  #>          Term                        Contrast    Species Estimate Std. Error   S   Df      t Pr(>|t|)   2.5 % 97.5 % #>  Sepal.Length mean(dY/dX)                     setosa       0.3456     0.0935 7.3 7.92  3.696  0.00618  0.1296  0.562 #>  Sepal.Length mean(dY/dX)                     virginica    0.3058     0.1020 5.5 6.52  2.998  0.02177  0.0609  0.551 #>  Sepal.Length mean(dY/dX)                     versicolor   0.3008     0.0972 5.8 6.75  3.095  0.01829  0.0692  0.532 #>  Sepal.Width  mean(dY/dX)                     setosa      -0.1690     0.1693 1.5 7.30 -0.998  0.35009 -0.5659  0.228 #>  Sepal.Width  mean(dY/dX)                     virginica   -0.0621     0.1692 0.5 6.65 -0.367  0.72495 -0.4665  0.342 #>  Sepal.Width  mean(dY/dX)                     versicolor  -0.0596     0.1510 0.5 7.77 -0.395  0.70348 -0.4097  0.290 #>  Species      mean(versicolor) - mean(setosa) setosa       0.6696     0.2063 5.8 5.88  3.246  0.01805  0.1624  1.177 #>  Species      mean(versicolor) - mean(setosa) virginica    0.6696     0.2063 5.8 5.88  3.246  0.01805  0.1624  1.177 #>  Species      mean(versicolor) - mean(setosa) versicolor   0.6696     0.2063 5.8 5.88  3.246  0.01805  0.1624  1.177 #>  Species      mean(virginica) - mean(setosa)  setosa       1.1303     0.2169 9.1 6.22  5.211  0.00178  0.6041  1.656 #>  Species      mean(virginica) - mean(setosa)  virginica    1.1303     0.2169 9.1 6.22  5.211  0.00178  0.6041  1.656 #>  Species      mean(virginica) - mean(setosa)  versicolor   1.1303     0.2169 9.1 6.22  5.211  0.00178  0.6041  1.656 #>  #> Columns: term, contrast, Species, estimate, std.error, s.value, predicted, predicted_hi, predicted_lo, df, statistic, p.value, conf.low, conf.high  # `missRanger` slopes mfx_missRanger <- avg_slopes(mod_missRanger, by = \"Species\") mfx_missRanger #>  #>          Term                        Contrast    Species Estimate Std. Error     S      Df     t Pr(>|t|)    2.5 % 97.5 % #>  Sepal.Length mean(dY/dX)                     setosa       0.0583     0.0414   2.7 3386591  1.41  0.15927 -0.02287  0.139 #>  Sepal.Length mean(dY/dX)                     versicolor   0.0670     0.0392   3.5  772141  1.71  0.08745 -0.00984  0.144 #>  Sepal.Length mean(dY/dX)                     virginica    0.0639     0.0368   3.6 1300639  1.74  0.08211 -0.00814  0.136 #>  Sepal.Width  mean(dY/dX)                     setosa       0.2314     0.0691  10.3 3034569  3.35  < 0.001  0.09600  0.367 #>  Sepal.Width  mean(dY/dX)                     versicolor   0.2188     0.0551  13.8 1270189  3.97  < 0.001  0.11091  0.327 #>  Sepal.Width  mean(dY/dX)                     virginica    0.2092     0.0687   8.8  625864  3.05  0.00232  0.07457  0.344 #>  Species      mean(versicolor) - mean(setosa) setosa       1.1588     0.0704 199.6 4239295 16.45  < 0.001  1.02078  1.297 #>  Species      mean(versicolor) - mean(setosa) versicolor   1.1588     0.0704 199.6 4239295 16.45  < 0.001  1.02078  1.297 #>  Species      mean(versicolor) - mean(setosa) virginica    1.1588     0.0704 199.6 4239295 16.45  < 0.001  1.02078  1.297 #>  Species      mean(virginica) - mean(setosa)  setosa       1.7784     0.0823 341.6 4276524 21.61  < 0.001  1.61710  1.940 #>  Species      mean(virginica) - mean(setosa)  versicolor   1.7784     0.0823 341.6 4276524 21.61  < 0.001  1.61710  1.940 #>  Species      mean(virginica) - mean(setosa)  virginica    1.7784     0.0823 341.6 4276524 21.61  < 0.001  1.61710  1.940 #>  #> Columns: term, contrast, Species, estimate, std.error, s.value, predicted, predicted_hi, predicted_lo, df, statistic, p.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/multiple_imputation.html","id":"comparing-results-with-different-imputation-software","dir":"Articles","previous_headings":"","what":"Comparing results with different imputation software","title":"Multiple Imputation and Missing Data","text":"can use modelsummary package compare results listwise deletion results using different imputations software:","code":"library(modelsummary)  # listwise deletion slopes mod_lwd <- lm(Petal.Width ~ Sepal.Length * Sepal.Width + Species, data = dat) mfx_lwd <- avg_slopes(mod_lwd, by = \"Species\")  # regression table models <- list(     \"LWD\" = mfx_lwd,     \"mice\" = mfx_mice,     \"Amelia\" = mfx_amelia,     \"missRanger\" = mfx_missRanger) modelsummary(models, shape = term : contrast + Species ~ model)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/multiple_imputation.html","id":"passing-new-data-arguments-newdata-wts-by-etc-","dir":"Articles","previous_headings":"","what":"Passing new data arguments: newdata, wts, by, etc.","title":"Multiple Imputation and Missing Data","text":"Sometimes want pass arguments changing specifying data analysis using marginaleffects. can reasons wanting specify values weights evaluate e.g. avg_slopes, due underlying models robustly preserving original data columns (fixest objects saving data fit object making potentially challenging retrieve, even retrievable include weights used fitting column wts expects given string). using multiple imputation, want just pass single dataset several fitted models multiple imputation, can pass single dataset newdata argument. However, wish supply model list resulting multiple imputation /different/ dataset calculate results, use newdata. Instead, case can useful revert manual (still easy) approach. example calculating avg_slopes using different set weights fixest models fit multiple imputation.","code":"set.seed(1024) library(mice) library(fixest) library(marginaleffects)  dat <- mtcars  # insert missing values dat$hp[sample(seq_len(nrow(mtcars)), 10)] <- NA dat$mpg[sample(seq_len(nrow(mtcars)), 10)] <- NA dat$gear[sample(seq_len(nrow(mtcars)), 10)] <- NA  # multiple imputation dat <- mice(dat, m = 5, method = \"sample\", printFlag = FALSE) dat <- complete(dat, action = \"all\")  # fit models mod <- lapply(dat, \\(x)      feglm(am ~ mpg * cyl + hp,         weight = ~gear,         family = binomial,         data = x))  # slopes without weights lapply(seq_along(mod), \\(i)      avg_slopes(mod[[i]], newdata = dat[[i]])) |>     mice::pool() #> Class: mipo    m = 5  #>   term m     estimate         ubar            b            t dfcom       df      riv    lambda       fmi #> 1  mpg 5  0.006083006 1.080596e-04 2.722367e-04 4.347437e-04    32 3.642855 3.023184 0.7514407 0.8262758 #> 2  cyl 5 -0.134279397 7.095810e-04 2.347149e-03 3.526159e-03    32 3.084411 3.969355 0.7987666 0.8649138 #> 3   hp 5  0.001649797 5.709181e-07 1.375524e-06 2.221547e-06    32 3.745533 2.891184 0.7430088 0.8192048  # slopes with weights lapply(seq_along(mod), \\(i)      avg_slopes(mod[[i]], newdata = dat[[i]], wts = \"gear\")) |>     mice::pool() #> Class: mipo    m = 5  #>   term m     estimate         ubar            b            t dfcom       df      riv    lambda       fmi #> 1  mpg 5  0.006251264 1.056051e-04 2.705362e-04 4.302485e-04    32 3.605312 3.074127 0.7545486 0.8288680 #> 2  cyl 5 -0.135839559 7.279608e-04 2.480980e-03 3.705137e-03    32 3.029311 4.089748 0.8035266 0.8686994 #> 3   hp 5  0.001671181 5.697634e-07 1.424665e-06 2.279361e-06    32 3.659903 3.000540 0.7500337 0.8250998"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/performance.html","id":"what-to-do-when-marginaleffects-is-slow","dir":"Articles","previous_headings":"","what":"What to do when marginaleffects is slow?","title":"Performance","text":"options: Compute marginal effects contrasts mean (representative value) instead observed rows original dataset: Use newdata argument datagrid() function. Compute marginal effects subset variables, paying special attention exclude factor variables can particularly costly process: Use variables argument. compute standard errors: Use vcov = FALSE argument. simulation illustrates computation time varies model 25 regressors 100,000 observations: benchmarks conducted using development version marginaleffects 2023-02-03.","code":"library(marginaleffects)  # simulate data and fit a large model N <- 1e5 dat <- data.frame(matrix(rnorm(N * 26), ncol = 26)) mod <- lm(X1 ~ ., dat)  results <- bench::mark(     # marginal effects at the mean; no standard error     slopes(mod, vcov = FALSE, newdata = \"mean\"),     # marginal effects at the mean     slopes(mod, newdata = \"mean\"),     # 1 variable; no standard error     slopes(mod, vcov = FALSE, variables = \"X3\"),     # 1 variable     slopes(mod, variables = \"X3\"),     # 26 variables; no standard error     slopes(mod, vcov = FALSE),     # 26 variables     slopes(mod),     iterations = 1, check = FALSE)  results[, c(1, 3, 5)] # <bch:expr>                                  <bch:tm> <bch:byt> # slopes(mod, vcov = FALSE, newdata = \"mean\") 230.09ms    1.24GB # slopes(mod, newdata = \"mean\")               329.14ms    1.25GB # slopes(mod, vcov = FALSE, variables = \"X3\")  198.7ms  496.24MB # slopes(mod, variables = \"X3\")                  1.27s    3.29GB # slopes(mod, vcov = FALSE)                      5.73s   11.05GB # slopes(mod)                                   21.68s   78.02GB"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/performance.html","id":"speed-comparison","dir":"Articles","previous_headings":"","what":"Speed comparison","title":"Performance","text":"slopes function relatively fast. simulation conducted using development version package 2022-04-04: marginaleffects speed margins unit-level standard errors computed: marginaleffects can 100x times faster margins unit-level standard errors computed: Models estimated larger datasets (> 1000 observations) can difficult process using margins package, memory time constraints. contrast, marginaleffects can work well much larger datasets. cases, marginaleffects considerably slower packages like emmeans modmarg. packages make extensive use hard-coded analytical derivatives, reimplement fast prediction functions.","code":"library(margins)  N <- 1e3 dat <- data.frame(     y = sample(0:1, N, replace = TRUE),     x1 = rnorm(N),     x2 = rnorm(N),     x3 = rnorm(N),     x4 = factor(sample(letters[1:5], N, replace = TRUE))) mod <- glm(y ~ x1 + x2 + x3 + x4, data = dat, family = binomial) results <- bench::mark(     slopes(mod, vcov = FALSE),     margins(mod, unit_ses = FALSE),     check = FALSE, relative = TRUE) results[, c(1, 3, 5)]  #   expression                        median mem_alloc #   <bch:expr>                          <dbl>     <dbl> # 1 slopes(mod, vcov = FALSE)   1         1 # 2 margins(mod, unit_ses = FALSE)       6.15      4.17 results <- bench::mark(     slopes(mod, vcov = TRUE),     margins(mod, unit_ses = TRUE),     check = FALSE, relative = TRUE, iterations = 1) results[, c(1, 3, 5)]  # <bch:expr>                     <dbl>     <dbl> # slopes(mod, vcov = TRUE)          1        1   # margins(mod, unit_ses = TRUE)   128.      18.6"},{"path":[]},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/plot.html","id":"conditional-predictions","dir":"Articles","previous_headings":"Predictions","what":"Conditional predictions","title":"Plots","text":"call prediction “conditional” made grid user-specified values. example, predict penguins’ body mass different values flipper length species: condition argument plot_predictions() function can used build meaningful grids predictor values somewhat easily:  Note values end x-axis correspond numerical results produced . example, predicted outcome Gentoo 231mm flippers 5597. can include 3rd conditioning variable, specify values want consider, supply R functions compute summaries, use one several string shortcuts common reference values (“threenum”, “minmax”, “quartile”, etc.):  See ?plot_predictions information.","code":"pre <- predictions(mod, newdata = datagrid(flipper_length_mm = c(172, 231), species = unique)) pre #>  #>  Estimate Std. Error    z Pr(>|z|)     S 2.5 % 97.5 % bill_length_mm island flipper_length_mm   species #>      3859        204 18.9   <0.001 263.0  3460   4259           43.9 Biscoe               172 Adelie    #>      2545        369  6.9   <0.001  37.5  1822   3268           43.9 Biscoe               172 Gentoo    #>      3146        234 13.5   <0.001 134.6  2688   3604           43.9 Biscoe               172 Chinstrap #>      4764        362 13.2   <0.001 128.9  4054   5474           43.9 Biscoe               231 Adelie    #>      5597        155 36.0   <0.001 940.9  5292   5901           43.9 Biscoe               231 Gentoo    #>      4086        469  8.7   <0.001  58.1  3166   5006           43.9 Biscoe               231 Chinstrap #>  #> Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, body_mass_g, bill_length_mm, island, flipper_length_mm, species plot_predictions(mod, condition = c(\"flipper_length_mm\", \"species\")) plot_predictions(     mod,     condition = list(         \"flipper_length_mm\" = 180:220,         \"bill_length_mm\" = \"threenum\",         \"species\" = unique))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/plot.html","id":"marginal-predictions","dir":"Articles","previous_headings":"Predictions","what":"Marginal predictions","title":"Plots","text":"call prediction “marginal” result two step process: (1) make predictions observed unit original dataset, (2) average predictions across one categorical predictors. example: can plot predictions using analogous command:  can also make predictions intersections different variables: Note certain species live certain islands. Visually:","code":"predictions(mod, by = \"species\") #>  #>    species Estimate Std. Error     z Pr(>|z|)   S 2.5 % 97.5 % #>  Adelie        3701       27.2 136.1   <0.001 Inf  3647   3754 #>  Gentoo        5076       30.1 168.5   <0.001 Inf  5017   5135 #>  Chinstrap     3733       40.5  92.2   <0.001 Inf  3654   3812 #>  #> Columns: species, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high plot_predictions(mod, by = \"species\") predictions(mod, by = c(\"species\", \"island\")) #>  #>    species    island Estimate Std. Error     z Pr(>|z|)   S 2.5 % 97.5 % #>  Adelie    Torgersen     3706       46.8  79.2   <0.001 Inf  3615   3798 #>  Adelie    Biscoe        3710       50.4  73.7   <0.001 Inf  3611   3808 #>  Adelie    Dream         3688       44.6  82.6   <0.001 Inf  3601   3776 #>  Gentoo    Biscoe        5076       30.1 168.5   <0.001 Inf  5017   5135 #>  Chinstrap Dream         3733       40.5  92.2   <0.001 Inf  3654   3812 #>  #> Columns: species, island, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high plot_predictions(mod, by = c(\"species\", \"island\"))"},{"path":[]},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/plot.html","id":"conditional-comparisons","dir":"Articles","previous_headings":"Comparisons","what":"Conditional comparisons","title":"Plots","text":"syntax conditional comparisons syntax conditional predictions, except now need specify variable(s) interest using additional argument:  can specify custom comparisons, using variables argument comparisons() function. example, see happens predicted outcome flipper_length_mm increases 1 standard deviation 10mm:  Notice vertical scale different plots , reflecting fact plotting effect change 1 standard deviation left vs 10 units right. Like comparisons() function, plot_comparisons() powerful tool allows us compute display custom comparisons differences, ratios, odds, arbitrary functions predicted outcomes. example, want plot ratio predicted body mass different species penguins, :  left panel shows ratio Chinstrap body mass Adelie body mass approximately constant, slightly 0.8. right panel shows ratio Gentoo Adelie body mass depends bill length. birds short bills, Gentoos seem smaller body mass Adelies. birds long bills, Gentoos seem heavier Adelies, although null ratio (1) outside confidence interval.","code":"comparisons(mod,   variables = \"flipper_length_mm\",   newdata = datagrid(flipper_length_mm = c(172, 231), species = unique)) #>  #>               Term Contrast Estimate Std. Error    z Pr(>|z|)    S 2.5 % 97.5 % bill_length_mm island   species #>  flipper_length_mm       +1     15.3       9.25 1.66   0.0976  3.4 -2.81   33.5           43.9 Biscoe Adelie    #>  flipper_length_mm       +1     51.7       8.70 5.95   <0.001 28.5 34.68   68.8           43.9 Biscoe Gentoo    #>  flipper_length_mm       +1     15.9      11.37 1.40   0.1610  2.6 -6.34   38.2           43.9 Biscoe Chinstrap #>  flipper_length_mm       +1     15.3       9.25 1.66   0.0976  3.4 -2.81   33.5           43.9 Biscoe Adelie    #>  flipper_length_mm       +1     51.7       8.70 5.95   <0.001 28.5 34.68   68.8           43.9 Biscoe Gentoo    #>  flipper_length_mm       +1     15.9      11.37 1.40   0.1610  2.6 -6.34   38.2           43.9 Biscoe Chinstrap #>  #> Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, body_mass_g, bill_length_mm, island, flipper_length_mm, species  plot_comparisons(mod,   variables = \"flipper_length_mm\",   condition = c(\"bill_length_mm\", \"species\")) plot_comparisons(mod,   variables = list(\"flipper_length_mm\" = \"sd\"),   condition = c(\"bill_length_mm\", \"species\")) +  plot_comparisons(mod,   variables = list(\"flipper_length_mm\" = 10),   condition = c(\"bill_length_mm\", \"species\")) plot_comparisons(mod,   variables = \"species\",   condition = \"bill_length_mm\",   comparison = \"ratio\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/plot.html","id":"marginal-comparisons","dir":"Articles","previous_headings":"Comparisons","what":"Marginal comparisons","title":"Plots","text":", can also display marginal comparisons, subgroups:  Multiple contrasts :","code":"plot_comparisons(mod,   variables = \"flipper_length_mm\",   by = \"species\") +  plot_comparisons(mod,   variables = \"flipper_length_mm\",   by = c(\"species\", \"island\")) plot_comparisons(mod,   variables = c(\"flipper_length_mm\", \"bill_length_mm\"),   by = c(\"species\", \"island\"))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/plot.html","id":"slopes","dir":"Articles","previous_headings":"","what":"Slopes","title":"Plots","text":"read sections , behavior plot_slopes() function surprise. give two examples compute display elasticity body mass respect bill length:   example marginal effects (aka “slopes” “partial derivatives”) plot model multiplicative interactions continuous variables:","code":"# conditional plot_slopes(mod,   variables = \"bill_length_mm\",   slope = \"eyex\",   condition = c(\"species\", \"island\")) # marginal plot_slopes(mod,   variables = \"bill_length_mm\",   slope = \"eyex\",   by = c(\"species\", \"island\")) mod2 <- lm(mpg ~ wt * qsec * factor(gear), data = mtcars)  plot_slopes(mod2, variables = \"qsec\", condition = c(\"wt\", \"gear\"))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/plot.html","id":"uncertainty-estimates","dir":"Articles","previous_headings":"","what":"Uncertainty estimates","title":"Plots","text":"functions package, plot_*() functions conf_level argument vcov argument can used control size confidence intervals types standard errors used:","code":"plot_slopes(mod,   variables = \"bill_length_mm\", condition = \"flipper_length_mm\") +   ylim(c(-150, 200)) +  # clustered standard errors plot_slopes(mod,   vcov = ~island,   variables = \"bill_length_mm\", condition = \"flipper_length_mm\") +   ylim(c(-150, 200)) +  # alpha level plot_slopes(mod,   conf_level = .8,   variables = \"bill_length_mm\", condition = \"flipper_length_mm\") +   ylim(c(-150, 200))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/plot.html","id":"customization","dir":"Articles","previous_headings":"","what":"Customization","title":"Plots","text":"useful feature plotting functions package produce normal ggplot2 objects. can customize heart’s content, using ggplot2 , one many packages designed augment functionalities:  plotting functions work model supported marginaleffects package, can plot output logistic regression model. plot shows probability survival aboard Titanic, different ages different ticket classes:  Thanks Andrew Heiss inspired plot. Designing effective data visualizations requires lot customization specific context data. plotting functions marginaleffects offer powerful way iterate quickly plots models, obviously support features users may want. Thankfully, easy use slopes functions generate datasets can used ggplot2 data visualization tool. Just use draw argument: allows us feed data easily functions, useful ggdist distributional packages:","code":"library(ggrepel)  mt <- mtcars mt$label <- row.names(mt)  mod <- lm(mpg ~ hp * factor(cyl), data = mt)  plot_predictions(mod, condition = c(\"hp\", \"cyl\"), points = .5, rug = TRUE, vcov = FALSE) +     geom_text_repel(aes(x = hp, y = mpg, label = label),                     data = subset(mt, hp > 250),                     nudge_y = 2) +     theme_classic() library(ggdist) library(ggplot2)  dat <- \"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Titanic.csv\" dat <- read.csv(dat)  mod <- glm(Survived ~ Age * SexCode * PClass, data = dat, family = binomial)  plot_predictions(mod, condition = c(\"Age\", \"PClass\")) +     geom_dots(         alpha = .8,         scale = .3,         pch = 18,         data = dat, aes(         x = Age,         y = Survived,         side = ifelse(Survived == 1, \"bottom\", \"top\"))) p <- plot_predictions(mod, condition = c(\"Age\", \"PClass\"), draw = FALSE) head(p) #>   rowid  estimate      p.value   s.value  conf.low conf.high  Survived   SexCode     Age PClass #> 1     1 0.8679723 0.0013307148  9.553583 0.6754794 0.9540527 0.4140212 0.3809524 0.17000    1st #> 2     2 0.8956789 0.0001333343 12.872665 0.7401973 0.9627887 0.4140212 0.3809524 0.17000    2nd #> 3     3 0.4044513 0.2667759617  1.906299 0.2554245 0.5734603 0.4140212 0.3809524 0.17000    3rd #> 4     4 0.8631027 0.0011563593  9.756195 0.6749549 0.9503543 0.4140212 0.3809524 1.61551    1st #> 5     5 0.8813224 0.0001728862 12.497890 0.7228529 0.9548415 0.4140212 0.3809524 1.61551    2nd #> 6     6 0.3934924 0.1899483112  2.396321 0.2535791 0.5533716 0.4140212 0.3809524 1.61551    3rd library(ggdist) library(distributional) plot_slopes(mod, variables = \"SexCode\", condition = c(\"Age\", \"PClass\"), type = \"link\", draw = FALSE) |>   ggplot() +   stat_lineribbon(aes(     x = Age,     ydist = dist_normal(mu = estimate, sigma = std.error),     fill = PClass),     alpha = 1 / 4)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/plot.html","id":"fits-and-smooths","dir":"Articles","previous_headings":"","what":"Fits and smooths","title":"Plots","text":"can compare model predictors fits smoothers using geom_smooth() function ggplot2 package:","code":"dat <- \"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Titanic.csv\" dat <- read.csv(dat) mod <- glm(Survived ~ Age * PClass, data = dat, family = binomial)  plot_predictions(mod, condition = c(\"Age\", \"PClass\")) +     geom_smooth(data = dat, aes(Age, Survived), method = \"lm\", se = FALSE, color = \"black\") +     geom_smooth(data = dat, aes(Age, Survived), se = FALSE, color = \"black\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/plot.html","id":"groups-and-categorical-outcomes","dir":"Articles","previous_headings":"","what":"Groups and categorical outcomes","title":"Plots","text":"models, marginaleffects functions generate different estimates different groups, categorical outcomes. example, can plot estimates way , specifying group one conditional variable, adding column facet_wrap() call:","code":"library(MASS) mod <- polr(factor(gear) ~ mpg + hp, data = mtcars)  predictions(mod) #>  #>  Group Estimate Std. Error    z Pr(>|z|)    S   2.5 % 97.5 % #>      3   0.5316     0.1127 4.72   <0.001 18.7  0.3107  0.753 #>      3   0.5316     0.1127 4.72   <0.001 18.7  0.3107  0.753 #>      3   0.4492     0.1200 3.74   <0.001 12.4  0.2140  0.684 #>      3   0.4944     0.1111 4.45   <0.001 16.8  0.2765  0.712 #>      3   0.4213     0.1142 3.69   <0.001 12.1  0.1974  0.645 #> --- 86 rows omitted. See ?avg_predictions and ?print.marginaleffects ---  #>      5   0.6894     0.1956 3.52   <0.001 11.2  0.3059  1.073 #>      5   0.1650     0.1290 1.28   0.2010  2.3 -0.0879  0.418 #>      5   0.1245     0.0698 1.78   0.0744  3.7 -0.0123  0.261 #>      5   0.3779     0.3244 1.17   0.2440  2.0 -0.2579  1.014 #>      5   0.0667     0.0458 1.46   0.1455  2.8 -0.0231  0.157 #> Columns: rowid, group, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, gear, mpg, hp plot_predictions(mod, condition = c(\"mpg\", \"group\"), type = \"probs\", vcov = FALSE) plot_predictions(mod, condition = \"mpg\", type = \"probs\", vcov = FALSE) +   facet_wrap(~ group)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/plot.html","id":"plot-and-marginaleffects-objects","dir":"Articles","previous_headings":"","what":"plot() and marginaleffects objects","title":"Plots","text":"users may feel inclined call plot() object produced marginaleffects object. generate informative error like one: reason error user query underspecified. marginaleffects allows users compute many quantities interest clear user wants simply call plot(). Adding several new arguments compete main plotting functions, risk sowing confusion. marginaleffects developers thus decided support one main path plotting: plot_predictions(), plot_comparisons(), plot_slopes(). said, may useful remind users marginaleffects output standard “tidy” data frames. Although get pretty-printed console, listed columns accessible via standard R operators. example: allows us plot results easily standard plotting functions:","code":"mod <- lm(mpg ~ hp * wt * factor(cyl), data = mtcars) p <- predictions(mod) plot(p) #> Error: Please use the `plot_predictions()` function. p <- avg_predictions(mod, by = \"cyl\") p #>  #>  cyl Estimate Std. Error    z Pr(>|z|)     S 2.5 % 97.5 % #>    6     19.7      0.871 22.7   <0.001 375.1  18.0   21.5 #>    4     26.7      0.695 38.4   <0.001   Inf  25.3   28.0 #>    8     15.1      0.616 24.5   <0.001 438.2  13.9   16.3 #>  #> Columns: cyl, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  p$estimate #> [1] 19.74286 26.66364 15.10000  p$std.error #> [1] 0.8713835 0.6951236 0.6161612  p$conf.low #> [1] 18.03498 25.30122 13.89235 plot_predictions(mod, by = \"cyl\") plot(p$cyl, p$estimate) ggplot(p, aes(x = cyl, y = estimate, ymin = conf.low, ymax = conf.high)) +   geom_pointrange()"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/predictions.html","id":"prediction-type-or-scale","dir":"Articles","previous_headings":"","what":"Prediction type (or scale)","title":"Predictions","text":"Using type argument predictions() function can specify “scale” make predictions. refers either scale used estimate model (.e., link scale) interpretable scale (e.g., response scale). example, fitting linear regression model using lm() function, link scale response scale identical. “Adjusted Prediction” computed either scale expressed mean value response variable given values predictor variables. hand, fitting binary logistic regression model using glm() function (uses binomial family logit link ), link scale response scale different: “Adjusted Prediction” computed link scale expressed log odds “successful” response given values predictor variables, whereas “Adjusted Prediction” computed response scale expressed probability response variable equals 1. default value type argument models “response”, means predictions() function compute predicted probabilities (binomial family), Poisson means (poisson family), etc.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/predictions.html","id":"prediction-grid","dir":"Articles","previous_headings":"","what":"Prediction grid","title":"Predictions","text":"compute adjusted predictions must first specify values predictors consider: “reference grid.” example, model linear model fitted lm() function relates response variable Happiness predictor variables Age, Gender Income, reference grid data.frame values Age, Gender Income: Age = 40, Gender = Male, Income = 60000. “reference grid” may may correspond actual observations dataset used fit model; example values given match mean values variable, represent specific observed (hypothetical) individual. reference grid can include many different rows want make predictions different combinations predictors. default, predictions() function uses full original dataset reference grid, means compute adjusted predictions individuals observed dataset used fit model.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/predictions.html","id":"the-predictions-function","dir":"Articles","previous_headings":"","what":"The predictions() function","title":"Predictions","text":"default, predictions calculates regression-adjusted predicted values every observation original dataset: many cases, limiting, researchers want specify grid “typical” values compute adjusted predictions.","code":"library(marginaleffects)  mod <- lm(mpg ~ hp + factor(cyl), data = mtcars)  pred <- predictions(mod)  head(pred) #>  #>  Estimate Std. Error    z Pr(>|z|)     S 2.5 % 97.5 % #>      20.0      1.204 16.6   <0.001 204.1  17.7   22.4 #>      20.0      1.204 16.6   <0.001 204.1  17.7   22.4 #>      26.4      0.962 27.5   <0.001 549.0  24.5   28.3 #>      20.0      1.204 16.6   <0.001 204.1  17.7   22.4 #>      15.9      0.992 16.0   <0.001 190.0  14.0   17.9 #>      20.2      1.219 16.5   <0.001 201.8  17.8   22.5 #>  #> Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, mpg, hp, cyl"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/predictions.html","id":"adjusted-predictions-at-user-specified-values-aka-adjusted-predictions-at-representative-values-apr","dir":"Articles","previous_headings":"","what":"Adjusted Predictions at User-Specified values (aka Adjusted Predictions at Representative values, APR)","title":"Predictions","text":"two main ways select reference grid want compute adjusted predictions. first using variables argument. second newdata argument datagrid() function already introduced marginal effects vignette.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/predictions.html","id":"variables-counterfactual-predictions","dir":"Articles","previous_headings":"Adjusted Predictions at User-Specified values (aka Adjusted Predictions at Representative values, APR)","what":"variables: Counterfactual predictions","title":"Predictions","text":"variables argument handy way create make predictions counterfactual datasets. example, dataset used fit model 32 rows. counterfactual dataset two distinct values hp 64 rows: original rows appears twice, , values specified variables argument:","code":"p <- predictions(mod, variables = list(hp = c(100, 120))) head(p) #>  #>  Estimate Std. Error     z Pr(>|z|)     S 2.5 % 97.5 % #>      20.3      1.238 16.38   <0.001 198.0  17.9   22.7 #>      20.3      1.238 16.38   <0.001 198.0  17.9   22.7 #>      26.2      0.986 26.63   <0.001 516.6  24.3   28.2 #>      20.3      1.238 16.38   <0.001 198.0  17.9   22.7 #>      17.7      1.881  9.42   <0.001  67.6  14.0   21.4 #>      20.3      1.238 16.38   <0.001 198.0  17.9   22.7 #>  #> Columns: rowid, rowidcf, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, mpg, cyl, hp nrow(p) #> [1] 64"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/predictions.html","id":"newdata-and-datagrid","dir":"Articles","previous_headings":"Adjusted Predictions at User-Specified values (aka Adjusted Predictions at Representative values, APR)","what":"newdata and datagrid","title":"Predictions","text":"second strategy construct grids predictors adjusted predictions combine newdata argument datagrid function. Recall function creates “typical” dataset variables means modes, except explicitly define: can also use datagrid function predictions call (omitting model argument): Users can change summary function used summarize type variables using FUN_numeric, FUN_factor, related arguments. example: data.frame produced predictions “tidy”, makes easy manipulate R packages functions: table Adjusted Predictions","code":"datagrid(cyl = c(4, 6, 8), model = mod) #>        mpg       hp cyl #> 1 20.09062 146.6875   4 #> 2 20.09062 146.6875   6 #> 3 20.09062 146.6875   8 predictions(mod, newdata = datagrid()) #>  #>  Estimate Std. Error  z Pr(>|z|)     S 2.5 % 97.5 %  hp cyl #>      16.6       1.28 13   <0.001 125.6  14.1   19.1 147   8 #>  #> Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, mpg, hp, cyl  predictions(mod, newdata = datagrid(cyl = c(4, 6, 8))) #>  #>  Estimate Std. Error    z Pr(>|z|)     S 2.5 % 97.5 %  hp cyl #>      25.1       1.37 18.4   <0.001 247.5  22.4   27.8 147   4 #>      19.2       1.25 15.4   <0.001 174.5  16.7   21.6 147   6 #>      16.6       1.28 13.0   <0.001 125.6  14.1   19.1 147   8 #>  #> Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, mpg, hp, cyl m <- lm(mpg ~ hp + drat + factor(cyl) + factor(am), data = mtcars) predictions(m, newdata = datagrid(FUN_factor = unique, FUN_numeric = median)) #>  #>  Estimate Std. Error    z Pr(>|z|)     S 2.5 % 97.5 %  hp drat cyl am #>      22.0       1.29 17.0   <0.001 214.0  19.4   24.5 123  3.7   6  1 #>      18.2       1.27 14.3   <0.001 151.9  15.7   20.7 123  3.7   6  0 #>      25.5       1.32 19.3   <0.001 274.0  23.0   28.1 123  3.7   4  1 #>      21.8       1.54 14.1   <0.001 148.3  18.8   24.8 123  3.7   4  0 #>      22.6       2.14 10.6   <0.001  84.2  18.4   26.8 123  3.7   8  1 #>      18.9       1.73 10.9   <0.001  89.0  15.5   22.3 123  3.7   8  0 #>  #> Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, mpg, hp, drat, cyl, am library(kableExtra) library(tidyverse)  predictions(     mod,     newdata = datagrid(cyl = mtcars$cyl, hp = c(100, 110))) |>     select(hp, cyl, estimate) |>     pivot_wider(values_from = estimate, names_from = cyl) |>     kbl(caption = \"A table of Adjusted Predictions\") |>     kable_styling() |>     add_header_above(header = c(\" \" = 1, \"cyl\" = 3))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/predictions.html","id":"counterfactual-data-grid","dir":"Articles","previous_headings":"Adjusted Predictions at User-Specified values (aka Adjusted Predictions at Representative values, APR)","what":"counterfactual data grid","title":"Predictions","text":"alternative approach construct grids predictors use grid_type = \"counterfactual\" argument value. duplicate whole dataset, different values specified user. example, mtcars dataset 32 rows. command produces new dataset 64 rows, row original dataset duplicated two values variable supplied (0 1): , can use dataset predictions function create interesting visualizations:  graph, dot represents predicted probability vs=1 one observation dataset, counterfactual worlds either 0 1.","code":"mod <- glm(vs ~ hp + am, data = mtcars, family = binomial)  nd <- datagrid(model = mod, am = 0:1, grid_type = \"counterfactual\")  dim(nd) #> [1] 64  4 pred <- predictions(mod, newdata = datagrid(am = 0:1, grid_type = \"counterfactual\")) |>     select(am, estimate, rowidcf) |>     pivot_wider(id_cols = rowidcf,                  names_from = am,                 values_from = estimate)  ggplot(pred, aes(x = `0`, y = `1`)) +     geom_point() +     geom_abline(intercept = 0, slope = 1) +     labs(x = \"Predicted Pr(vs=1), when am = 0\",          y = \"Predicted Pr(vs=1), when am = 1\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/predictions.html","id":"adjusted-prediction-at-the-mean-apm","dir":"Articles","previous_headings":"","what":"Adjusted Prediction at the Mean (APM)","title":"Predictions","text":"analysts may want calculate “Adjusted Prediction Mean,” , predicted outcome regressors held mean (mode). achieve , use datagrid function. default, function produces grid data regressors means modes, need get APM : equivalent calling:","code":"predictions(mod, newdata = \"mean\") #>  #>  Estimate Pr(>|z|)   S   2.5 % 97.5 %  hp    am #>    0.0631   0.0656 3.9 0.00379  0.543 147 0.406 #>  #> Columns: rowid, estimate, p.value, s.value, conf.low, conf.high, vs, hp, am predictions(mod, newdata = datagrid()) #>  #>  Estimate Pr(>|z|)   S   2.5 % 97.5 %  hp    am #>    0.0631   0.0656 3.9 0.00379  0.543 147 0.406 #>  #> Columns: rowid, estimate, p.value, s.value, conf.low, conf.high, vs, hp, am"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/predictions.html","id":"average-adjusted-predictions-aap","dir":"Articles","previous_headings":"","what":"Average Adjusted Predictions (AAP)","title":"Predictions","text":"“Average Adjusted Prediction” outcome two step process: Create new dataset original regressor values, fixing regressors values interest. Take average predicted values new dataset. can obtain AAPs applying avg_*() functions argument: equivalent : Note GLM models non-linear link function, predictions first made link scale, averaged, back transformed. Thus, average prediction may exactly identical average predictions: Users want average individual-level predictions response scale can specify type argument explicitly:","code":"modlin <- lm(mpg ~ hp + factor(cyl), mtcars) avg_predictions(modlin) #>  #>  Estimate Std. Error    z Pr(>|z|)     S 2.5 % 97.5 % #>      20.1      0.556 36.1   <0.001 946.7    19   21.2 #>  #> Columns: estimate, std.error, statistic, p.value, s.value, conf.low, conf.high pred <- predictions(modlin) mean(pred$estimate) #> [1] 20.09062 mod <- glm(vs ~ hp + am, data = mtcars, family = binomial)  avg_predictions(mod)$estimate #> [1] 0.06308965  # Step 1: predict on the link scale p <- predictions(mod, type = \"link\")$estimate # Step 2: average p <- mean(p) # Step 3: backtransform mod$family$linkinv(p) #> [1] 0.06308965 avg_predictions(mod, type = \"response\") #>  #>  Estimate Std. Error    z Pr(>|z|)    S 2.5 % 97.5 % #>     0.437     0.0429 10.2   <0.001 78.8 0.353  0.522 #>  #> Columns: estimate, std.error, statistic, p.value, s.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/predictions.html","id":"average-adjusted-predictions-by-group","dir":"Articles","previous_headings":"","what":"Average Adjusted Predictions by Group","title":"Predictions","text":"can compute average adjusted predictions different subsets data argument. next example, create “counterfactual” data grid observation dataset repeated twice, different values variable, variables held observed values. also show equivalent results using dplyr: Note two results exactly identical specify type=\"response\" explicitly. However, differ slightly leave type unspecified, marginaleffects automatically make predictions average link scale, backtransforming:","code":"predictions(mod, by = \"am\") #>  #>  am Estimate Pr(>|z|)   S   2.5 % 97.5 % #>   1   0.0694   0.0755 3.7 0.00424  0.566 #>   0   0.0591   0.1163 3.1 0.00198  0.665 #>  #> Columns: am, estimate, p.value, s.value, conf.low, conf.high predictions(     mod,     type = \"response\",     by = \"am\",     newdata = datagridcf(am = 0:1)) #>  #>  am Estimate Std. Error     z Pr(>|z|)     S 2.5 % 97.5 % #>   0    0.526     0.0330 15.93   <0.001 187.3 0.461  0.591 #>   1    0.330     0.0646  5.11   <0.001  21.6 0.204  0.457 #>  #> Columns: am, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  predictions(     mod,     type = \"response\",     newdata = datagridcf(am = 0:1)) |>     group_by(am) |>     summarize(AAP = mean(estimate)) #> # A tibble: 2 × 2 #>      am   AAP #>   <int> <dbl> #> 1     0 0.526 #> 2     1 0.330 predictions(     mod,     by = \"am\",     newdata = datagridcf(am = 0:1)) #>  #>  am Estimate Pr(>|z|)   S    2.5 % 97.5 % #>   0  0.24043   0.3922 1.4 2.22e-02  0.815 #>   1  0.00696   0.0359 4.8 6.81e-05  0.419 #>  #> Columns: am, estimate, p.value, s.value, conf.low, conf.high  predictions(     mod,     type = \"link\",     newdata = datagridcf(am = 0:1)) |>     group_by(am) |>     summarize(AAP = mod$family$linkinv(mean(estimate))) #> # A tibble: 2 × 2 #>      am     AAP #>   <int>   <dbl> #> 1     0 0.240   #> 2     1 0.00696"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/predictions.html","id":"multinomial-models","dir":"Articles","previous_headings":"Average Adjusted Predictions by Group","what":"Multinomial models","title":"Predictions","text":"One place particularly useful multinomial models different response levels. example, compute average predicted outcome outcome level multinomial logit model. Note response levels identified “group” column. can use custom aggregations supplying data frame argument. columns data frame must present output predictions(), data frame must also include column labels. example, “collapse” response groups: can useful combination hypothesis argument. example, compute difference average adjusted predictions 3 4 response levels, compared 5 response level: can also use complicated aggregations. , compute predicted probability outcome levels value cyl, collapsing “3” “4” outcome levels: can compare different groups using hypothesis argument:","code":"library(nnet) nom <- multinom(factor(gear) ~ mpg + am * vs, data = mtcars, trace = FALSE)  # first 5 raw predictions predictions(nom, type = \"probs\") |> head() #>  #>  Group Estimate Std. Error        z Pr(>|z|)   S     2.5 %   97.5 % #>      3 3.62e-05   2.00e-03   0.0181   0.9856 0.0 -3.89e-03 3.96e-03 #>      3 3.62e-05   2.00e-03   0.0181   0.9856 0.0 -3.89e-03 3.96e-03 #>      3 9.35e-08   6.91e-06   0.0135   0.9892 0.0 -1.35e-05 1.36e-05 #>      3 4.04e-01   1.97e-01   2.0569   0.0397 4.7  1.91e-02 7.90e-01 #>      3 1.00e+00   1.25e-03 802.4451   <0.001 Inf  9.98e-01 1.00e+00 #>      3 5.18e-01   2.90e-01   1.7884   0.0737 3.8 -4.97e-02 1.09e+00 #>  #> Columns: rowid, group, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, gear, mpg, am, vs  # average predictions avg_predictions(nom, type = \"probs\", by = \"group\") #>  #>  Group Estimate Std. Error     z Pr(>|z|)     S  2.5 % 97.5 % #>      3    0.469     0.0404 11.60   <0.001 100.9 0.3895  0.548 #>      4    0.375     0.0614  6.11   <0.001  29.9 0.2546  0.495 #>      5    0.156     0.0462  3.38   <0.001  10.4 0.0656  0.247 #>  #> Columns: group, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high by <- data.frame(     group = c(\"3\", \"4\", \"5\"),     by = c(\"3,4\", \"3,4\", \"5\"))  predictions(nom, type = \"probs\", by = by) #>  #>  Estimate Std. Error     z Pr(>|z|)     S  2.5 % 97.5 %  By #>     0.422     0.0231 18.25   <0.001 244.7 0.3766  0.467 3,4 #>     0.156     0.0462  3.38   <0.001  10.4 0.0656  0.247 5   #>  #> Columns: estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, by predictions(nom, type = \"probs\", by = by, hypothesis = \"sequential\") #>  #>     Term Estimate Std. Error     z Pr(>|z|)    S  2.5 % 97.5 % #>  5 - 3,4   -0.266     0.0694 -3.83   <0.001 12.9 -0.402  -0.13 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high nom <- multinom(factor(gear) ~ mpg + factor(cyl), data = mtcars, trace = FALSE)  by <- expand.grid(     group = 3:5,     cyl = c(4, 6, 8),     stringsAsFactors = TRUE) |>     # define labels     transform(by = ifelse(         group %in% 3:4,         sprintf(\"3/4 Gears & %s Cylinders\", cyl),         sprintf(\"5 Gears & %s Cylinders\", cyl)))  predictions(nom, by = by) #>  #>  Estimate Std. Error    z Pr(>|z|)    S   2.5 % 97.5 %                      By #>     0.429     0.0661 6.49   <0.001 33.4  0.2991  0.558 3/4 Gears & 6 Cylinders #>     0.409     0.0580 7.06   <0.001 39.1  0.2956  0.523 3/4 Gears & 4 Cylinders #>     0.429     0.0458 9.35   <0.001 66.6  0.3387  0.518 3/4 Gears & 8 Cylinders #>     0.143     0.1321 1.08    0.280  1.8 -0.1161  0.402 5 Gears & 6 Cylinders   #>     0.182     0.1159 1.57    0.117  3.1 -0.0457  0.409 5 Gears & 4 Cylinders   #>     0.143     0.0917 1.56    0.119  3.1 -0.0368  0.323 5 Gears & 8 Cylinders   #>  #> Columns: estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, by predictions(nom, by = by, hypothesis = \"pairwise\") #>  #>                                               Term  Estimate Std. Error         z Pr(>|z|)   S    2.5 % 97.5 % #>  3/4 Gears & 6 Cylinders - 3/4 Gears & 4 Cylinders  1.93e-02     0.0879  0.219838   0.8260 0.3 -0.15294  0.192 #>  3/4 Gears & 6 Cylinders - 3/4 Gears & 8 Cylinders  2.84e-05     0.0804  0.000353   0.9997 0.0 -0.15757  0.158 #>  3/4 Gears & 6 Cylinders - 5 Gears & 6 Cylinders    2.86e-01     0.1982  1.441537   0.1494 2.7 -0.10275  0.674 #>  3/4 Gears & 6 Cylinders - 5 Gears & 4 Cylinders    2.47e-01     0.1334  1.851410   0.0641 4.0 -0.01449  0.509 #>  3/4 Gears & 6 Cylinders - 5 Gears & 8 Cylinders    2.86e-01     0.1130  2.527631   0.0115 6.4  0.06415  0.507 #>  3/4 Gears & 4 Cylinders - 3/4 Gears & 8 Cylinders -1.93e-02     0.0739 -0.261054   0.7941 0.3 -0.16414  0.126 #>  3/4 Gears & 4 Cylinders - 5 Gears & 6 Cylinders    2.66e-01     0.1443  1.846188   0.0649 3.9 -0.01642  0.549 #>  3/4 Gears & 4 Cylinders - 5 Gears & 4 Cylinders    2.28e-01     0.1739  1.309479   0.1904 2.4 -0.11312  0.569 #>  3/4 Gears & 4 Cylinders - 5 Gears & 8 Cylinders    2.66e-01     0.1085  2.455117   0.0141 6.1  0.05371  0.479 #>  3/4 Gears & 8 Cylinders - 5 Gears & 6 Cylinders    2.86e-01     0.1399  2.042634   0.0411 4.6  0.01156  0.560 #>  3/4 Gears & 8 Cylinders - 5 Gears & 4 Cylinders    2.47e-01     0.1247  1.981364   0.0476 4.4  0.00267  0.491 #>  3/4 Gears & 8 Cylinders - 5 Gears & 8 Cylinders    2.86e-01     0.1375  2.076746   0.0378 4.7  0.01606  0.555 #>  5 Gears & 6 Cylinders - 5 Gears & 4 Cylinders     -3.86e-02     0.1758 -0.219838   0.8260 0.3 -0.38317  0.306 #>  5 Gears & 6 Cylinders - 5 Gears & 8 Cylinders     -5.68e-05     0.1608 -0.000353   0.9997 0.0 -0.31526  0.315 #>  5 Gears & 4 Cylinders - 5 Gears & 8 Cylinders      3.86e-02     0.1478  0.261054   0.7941 0.3 -0.25112  0.328 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/predictions.html","id":"bayesian-models","dir":"Articles","previous_headings":"Average Adjusted Predictions by Group","what":"Bayesian models","title":"Predictions","text":"strategy works bayesian models: results show median posterior distribution group-wise means. Note take mean predicted values MCMC draw computing quantiles. equivalent :","code":"library(brms) mod <- brm(am ~ mpg * vs, data = mtcars, family = bernoulli) predictions(mod, by = \"vs\") #>  #>  vs Estimate 2.5 % 97.5 % #>   0    0.327 0.182  0.507 #>   1    0.499 0.366  0.672 #>  #> Columns: vs, estimate, conf.low, conf.high draws <- posterior_epred(mod) quantile(rowMeans(draws[, mtcars$vs == 0]), probs = c(.5, .025, .975)) #>       50%      2.5%     97.5%  #> 0.3271836 0.1824479 0.5072074 quantile(rowMeans(draws[, mtcars$vs == 1]), probs = c(.5, .025, .975)) #>       50%      2.5%     97.5%  #> 0.4993250 0.3657956 0.6721267"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/predictions.html","id":"conditional-adjusted-predictions-plot","dir":"Articles","previous_headings":"","what":"Conditional Adjusted Predictions (Plot)","title":"Predictions","text":"First, download ggplot2movies dataset RDatasets archive. , create variable called certified_fresh movies rating least 8. Finally, discard outliers fit logistic regression model: can plot adjusted predictions, conditional length variable using plot_predictions function:  can also introduce another condition display categorical variable like style different colors. can useful models interactions:  Since output plot_predictions() ggplot2 object, easy customize. example, can add points actual observations dataset like :  can also use plot_predictions() models multinomial outcomes grouped coefficients. example, notice call draw=FALSE, result includes group column: Now use group column:","code":"library(tidyverse) dat <- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/ggplot2movies/movies.csv\") |>     mutate(style = case_when(Action == 1 ~ \"Action\",                              Comedy == 1 ~ \"Comedy\",                              Drama == 1 ~ \"Drama\",                              TRUE ~ \"Other\"),            style = factor(style),            certified_fresh = rating >= 8) |>     dplyr::filter(length < 240)  mod <- glm(certified_fresh ~ length * style, data = dat, family = binomial) mod <- glm(certified_fresh ~ length, data = dat, family = binomial)  plot_predictions(mod, condition = \"length\") mod <- glm(certified_fresh ~ length * style, data = dat, family = binomial)  plot_predictions(mod, condition = c(\"length\", \"style\")) library(ggplot2) library(ggrepel)  mt <- mtcars mt$label <- row.names(mt)  mod <- lm(mpg ~ hp, data = mt)  plot_predictions(mod, condition = \"hp\") +     geom_point(aes(x = hp, y = mpg), data = mt) +     geom_rug(aes(x = hp, y = mpg), data = mt) +     geom_text_repel(aes(x = hp, y = mpg, label = label),                     data = subset(mt, hp > 250),                     nudge_y = 2) +     theme_classic() library(MASS) library(ggplot2)  mod <- nnet::multinom(factor(gear) ~ mpg, data = mtcars, trace = FALSE)  p <- plot_predictions(     mod,     type = \"probs\",     condition = \"mpg\",     draw = FALSE)  head(p) #>   rowid group  estimate  std.error statistic       p.value  s.value  conf.low conf.high gear      mpg #> 1     1     3 0.9714990 0.03872773  25.08536 7.185838e-139 458.9028 0.8955941  1.047404    3 10.40000 #> 2     2     3 0.9656724 0.04393256  21.98079 4.397495e-107 353.3096 0.8795661  1.051779    3 10.87959 #> 3     3     3 0.9586759 0.04963084  19.31613  3.930287e-83 273.7454 0.8614012  1.055951    3 11.35918 #> 4     4     3 0.9502914 0.05579948  17.03047  4.880938e-65 213.6382 0.8409265  1.059656    3 11.83878 #> 5     5     3 0.9402691 0.06238682  15.07160  2.490123e-51 168.1021 0.8179932  1.062545    3 12.31837 #> 6     6     3 0.9283274 0.06930549  13.39472  6.492421e-41 133.5003 0.7924911  1.064164    3 12.79796 plot_predictions(     mod,     type = \"probs\",     condition = \"mpg\") +     facet_wrap(~group)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/predictions.html","id":"prediction-types","dir":"Articles","previous_headings":"","what":"Prediction types","title":"Predictions","text":"predictions function computes model-adjusted means scale output predict(model) function. default, predict produces predictions \"response\" scale, adjusted predictions interpreted scale. However, users can pass string type argument, predictions consider different outcomes. Typical values include \"response\" \"link\", users refer documentation predict package used fit model know values allowable. documentation. can also plot predictions different outcome scales:","code":"mod <- glm(am ~ mpg, family = binomial, data = mtcars) pred <- predictions(mod, type = \"response\") head(pred) #>  #>  Estimate Std. Error    z Pr(>|z|)    S  2.5 % 97.5 % #>     0.461     0.1158 3.98  < 0.001 13.8 0.2340  0.688 #>     0.461     0.1158 3.98  < 0.001 13.8 0.2340  0.688 #>     0.598     0.1324 4.52  < 0.001 17.3 0.3384  0.857 #>     0.492     0.1196 4.11  < 0.001 14.6 0.2573  0.726 #>     0.297     0.1005 2.95  0.00314  8.3 0.0999  0.494 #>     0.260     0.0978 2.66  0.00787  7.0 0.0682  0.452 #>  #> Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, am, mpg  pred <- predictions(mod, type = \"link\") head(pred) #>  #>  Estimate Std. Error       z Pr(>|z|)   S  2.5 %  97.5 % #>   -0.1559      0.466 -0.3345   0.7380 0.4 -1.070  0.7578 #>   -0.1559      0.466 -0.3345   0.7380 0.4 -1.070  0.7578 #>    0.3967      0.551  0.7204   0.4713 1.1 -0.683  1.4761 #>   -0.0331      0.479 -0.0692   0.9448 0.1 -0.971  0.9049 #>   -0.8621      0.482 -1.7903   0.0734 3.8 -1.806  0.0817 #>   -1.0463      0.509 -2.0575   0.0396 4.7 -2.043 -0.0496 #>  #> Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, am, mpg plot_predictions(mod, condition = \"mpg\", type = \"response\") plot_predictions(mod, condition = \"mpg\", type = \"link\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/python.html","id":"fitting-a-numpyro-model","dir":"Articles","previous_headings":"","what":"Fitting a NumPyro model","title":"Python with `marginaleffects` and `reticulate`","text":"begin, load reticulate package allows us interact Python interpreter R session. , write NumPyro model load memory using source_python() function. important functions note Python code : load_df() downloads data pulmonary fibrosis. model() defines NumPyro model. fit_mcmc_model() fits model using Markov Chain Monte Carlo. predict_mcmc(): accepts data frame returns matrix draws posterior distribution adjusted predictions (fitted values).","code":"library(reticulate) library(marginaleffects)  model <- ' # Model code adapted from the NumPyro documtation under Apache License: # https://num.pyro.ai/en/latest/tutorials/bayesian_hierarchical_linear_regression.html  import pandas as pd import numpy as np import numpyro from numpyro.infer import SVI, Predictive, MCMC,NUTS, autoguide, TraceMeanField_ELBO import numpyro.distributions as dist from numpyro.infer.initialization import init_to_median, init_to_uniform,init_to_sample from jax import random from sklearn.preprocessing import LabelEncoder import pickle  def load_df():     train = pd.read_csv(\"https://raw.githubusercontent.com/vincentarelbundock/modelarchive/main/data-raw/osic_pulmonary_fibrosis.csv\")     return train   def model(data, predict = False):     FVC_obs = data[\"FVC\"].values  if predict == False else None     patient_encoder = LabelEncoder()     Age_obs = data[\"Age\"].values     patient_code = patient_encoder.fit_transform(data[\"Patient\"].values)     μ_α = numpyro.sample(\"μ_α\", dist.Normal(0.0, 500.0))     σ_α = numpyro.sample(\"σ_α\", dist.HalfNormal(100.0))      age = numpyro.sample(\"age\", dist.Normal(0.0, 500.0))      n_patients = len(np.unique(patient_code))      with numpyro.plate(\"plate_i\", n_patients):         α = numpyro.sample(\"α\", dist.Normal(μ_α, σ_α))      σ = numpyro.sample(\"σ\", dist.HalfNormal(100.0))     FVC_est = α[patient_code] + age * Age_obs      with numpyro.plate(\"data\", len(patient_code)):         numpyro.sample(\"obs\", dist.Normal(FVC_est, σ), obs=FVC_obs)   def fit_mcmc_model(train_df, samples = 1000):     numpyro.set_host_device_count(4)     rng_key = random.PRNGKey(0)     mcmc = MCMC(         NUTS(model),         num_samples=samples,         num_warmup=1000,         progress_bar=True,         num_chains = 4         )          mcmc.run(rng_key, train_df)      posterior_draws = mcmc.get_samples()      with open(\"mcmc_posterior_draws.pickle\", \"wb\") as handle:         pickle.dump(posterior_draws, handle, protocol=pickle.HIGHEST_PROTOCOL)  def predict_mcmc(data):      with open(\"mcmc_posterior_draws.pickle\", \"rb\") as handle:         posterior_draws = pickle.load(handle)      predictive = Predictive(model = model,posterior_samples=posterior_draws)     samples = predictive(random.PRNGKey(1), data, predict = True)     y_pred = samples[\"obs\"]     # transpose so that each column is a draw and each row is an observation     y_pred = np.transpose(np.array(y_pred))      return y_pred  '  # save python script to temp file tmp <- tempfile() cat(model, file = tmp)  # load functions source_python(tmp)  # download data df <- load_df()  # fit model fit_mcmc_model(df)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/python.html","id":"analyzing-the-results-in-marginaleffects","dir":"Articles","previous_headings":"","what":"Analyzing the results in marginaleffects","title":"Python with `marginaleffects` and `reticulate`","text":"functions marginaleffects package requires users supply model object function operate. estimating models outside R, model object. thus begin creating “fake” model object: empty data frame define class “custom”. , set global option tell marginaleffects “custom” class supported. Next, define get_predict method new custom class. method must accept three arguments: model, newdata, .... get_predict method must return data frame one row rows newdata, two columns (rowid estimate), attribute called posterior_draws hosts matrix posterior draws number rows newdata. method uses reticulate call predict_mcmc() function defined Python script . predict_mcmc() function accepts data frame returns matrix number rows. Now can use marginaleffects package functions analyze results. Since use “fake” model object, marginaleffects retrieve original data model object, always need supply newdata argument:","code":"mod <- data.frame() class(mod) <- \"custom\"  options(\"marginaleffects_model_classes\" = \"custom\") get_predict.custom <- function(model, newdata, ...) {     pred <- predict_mcmc(newdata)     out <- data.frame(         rowid = seq_len(nrow(newdata)),         predicted = apply(pred, 1, stats::median)     )     attr(out, \"posterior_draws\") <- pred     return(out) } # predictions on the original dataset predictions(mod, newdata = df) |> head()  # predictions for user-defined predictor values predictions(mod, newdata = datagrid(newdata = df, Age = c(60, 70)))  predictions(mod, newdata = datagrid(newdata = df, Age = range))  # average predictions by group predictions(mod, newdata = df, by = \"Sex\")  # contrasts (average) avg_comparisons(mod, variables = \"Age\", newdata = df)  avg_comparisons(mod, variables = list(\"Age\" = \"sd\"), newdata = df)  # slope (elasticity) avg_slopes(mod, variables = \"Age\", slope = \"eyex\", newdata = df)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/slopes.html","id":"definition","dir":"Articles","previous_headings":"","what":"Definition","title":"Slopes","text":"Slopes defined : Partial derivatives regression equation respect regressor interest. .k.. Marginal effects, trends. vignette follows econometrics tradition referring “slopes” “marginal effects” interchangeably. context, word “marginal” refers idea “small change,” calculus sense. marginal effect measures association change regressor \\(x\\), change response \\(y\\). Put differently, differently, marginal effect slope prediction function, measured specific value regressor \\(x\\). Marginal effects extremely useful, intuitive easy interpret. often main quantity interest empirical analysis. scientific practice, “Marginal Effect” falls toolbox “Contrast.” try answer counterfactual question: happen \\(y\\) \\(x\\) different? allow us model “effect” change/difference regressor \\(x\\) response \\(y\\).1 illustrate concept, consider quadratic function: \\[y = -x^2\\] definition , know marginal effect partial derivative \\(y\\) respect \\(x\\): \\[\\frac{\\partial y}{\\partial x} = -2x\\] get intuition interpret quantity, consider response \\(y\\) \\(x\\). looks like :  \\(x\\) increases, \\(y\\) starts increase. , \\(x\\) increases , \\(y\\) creeps back negative territory. marginal effect slope response function certain value \\(x\\). next plot adds three tangent lines, highlighting slopes response function three values \\(x\\). slopes tangents tell us three things: \\(x<0\\), slope positive: increase \\(x\\) associated increase \\(y\\): marginal effect positive. \\(x=0\\), slope null: (small) change \\(x\\) associated change \\(y\\). marginal effect null. \\(x>0\\), slope negative: increase \\(x\\) associated decrease \\(y\\). marginal effect negative.  , show reach conclusions estimation context, simulated data slopes function.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/slopes.html","id":"slopes-function","dir":"Articles","previous_headings":"","what":"slopes function","title":"Slopes","text":"marginal effect unit-level measure association changes regressor changes response. Except simplest linear models, value marginal effect different individual individual, depend values covariates individual. slopes function thus produces distinct estimates marginal effect row data used fit model. output marginaleffects simple data.frame, can inspected usual R commands. show , load library, download Palmer Penguins data Rdatasets archive, estimate GLM model:","code":"library(marginaleffects)  dat <- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\") dat$large_penguin <- ifelse(dat$body_mass_g > median(dat$body_mass_g, na.rm = TRUE), 1, 0)  mod <- glm(large_penguin ~ bill_length_mm + flipper_length_mm + species,            data = dat, family = binomial) mfx <- slopes(mod) head(mfx) #>  #>            Term Contrast Estimate Std. Error    z Pr(>|z|)    S   2.5 % 97.5 % #>  bill_length_mm    dY/dX   0.0176    0.00830 2.12  0.03359  4.9 0.00137 0.0339 #>  bill_length_mm    dY/dX   0.0359    0.01229 2.92  0.00354  8.1 0.01176 0.0600 #>  bill_length_mm    dY/dX   0.0844    0.02108 4.01  < 0.001 14.0 0.04312 0.1258 #>  bill_length_mm    dY/dX   0.0347    0.00642 5.41  < 0.001 23.9 0.02214 0.0473 #>  bill_length_mm    dY/dX   0.0509    0.01350 3.77  < 0.001 12.6 0.02444 0.0773 #>  bill_length_mm    dY/dX   0.0165    0.00770 2.14  0.03202  5.0 0.00142 0.0316 #>  #> Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, large_penguin, bill_length_mm, flipper_length_mm, species"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/slopes.html","id":"the-marginal-effects-zoo","dir":"Articles","previous_headings":"","what":"The Marginal Effects Zoo","title":"Slopes","text":"dataset one marginal effect estimate per unit observation bit unwieldy difficult interpret. ways make information easier digest, computing various quantities interest. characteristically excellent blog post, Professor Andrew Heiss introduces many quantities: Average Marginal Effects Group-Average Marginal Effects Marginal Effects User-Specified Values (Representative Values) Marginal Effects Mean Counterfactual Marginal Effects Conditional Marginal Effects rest vignette defines quantities explains use slopes() plot_slopes() functions compute . main differences quantities pertain () regressor values estimate marginal effects, (b) way unit-level marginal effects aggregated. Heiss drew exceedingly helpful graph summarizes information rest vignette:","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/slopes.html","id":"average-marginal-effect-ame","dir":"Articles","previous_headings":"","what":"Average Marginal Effect (AME)","title":"Slopes","text":"dataset one marginal effect estimate per unit observation bit unwieldy difficult interpret. Many analysts like report “Average Marginal Effect”, , average observation-specific marginal effects. easy compute based full data.frame shown , avg_slopes() function convenient: Note since marginal effects derivatives, properly defined continuous numeric variables. model also includes categorical regressors, summary function try display relevant (regression-adjusted) contrasts different categories, shown . can also extract average marginal effects using tidy glance methods conform broom package specification:","code":"avg_slopes(mod) #>  #>               Term           Contrast Estimate Std. Error      z Pr(>|z|)    S    2.5 %  97.5 % #>  bill_length_mm    dY/dX                0.0276    0.00578  4.772   <0.001 19.1  0.01625  0.0389 #>  flipper_length_mm dY/dX                0.0106    0.00235  4.509   <0.001 17.2  0.00598  0.0152 #>  species           Chinstrap - Adelie  -0.4148    0.05659 -7.330   <0.001 42.0 -0.52570 -0.3039 #>  species           Gentoo - Adelie      0.0617    0.10688  0.577    0.564  0.8 -0.14778  0.2712 #>  #> Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high tidy(mfx) #> # A tibble: 4 × 8 #>   term              contrast                       estimate std.error statistic  p.value conf.low conf.high #>   <chr>             <chr>                             <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl> #> 1 bill_length_mm    mean(dY/dX)                      0.0276   0.00578     4.77  1.82e- 6  0.0162     0.0389 #> 2 flipper_length_mm mean(dY/dX)                      0.0106   0.00235     4.51  6.52e- 6  0.00598    0.0152 #> 3 species           mean(Chinstrap) - mean(Adelie)  -0.415    0.0566     -7.33  2.31e-13 -0.526     -0.304  #> 4 species           mean(Gentoo) - mean(Adelie)      0.0617   0.107       0.577 5.64e- 1 -0.148      0.271  glance(mfx) #> # A tibble: 1 × 7 #>     aic   bic r2.tjur  rmse  nobs     F logLik    #>   <dbl> <dbl>   <dbl> <dbl> <int> <dbl> <logLik>  #> 1  180.  199.   0.695 0.276   342  15.7 -84.92257"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/slopes.html","id":"group-average-marginal-effect-g-ame","dir":"Articles","previous_headings":"","what":"Group-Average Marginal Effect (G-AME)","title":"Slopes","text":"can also use argument average marginal effects within different subgroups observed data, based values regressors. example, compute average marginal effects Bill Length Species, : equivalent manually taking mean observation-level marginal effect species sub-group: Note marginaleffects follows Stata margins package computing standard errors using group-wise averaged Jacobian.","code":"avg_slopes(   mod,   by = \"species\",   variables = \"bill_length_mm\") #>  #>            Term    Contrast   species Estimate Std. Error    z Pr(>|z|)    S   2.5 %  97.5 % #>  bill_length_mm mean(dY/dX) Adelie     0.04354    0.00879 4.95   <0.001 20.4  0.0263 0.06077 #>  bill_length_mm mean(dY/dX) Gentoo     0.00287    0.00284 1.01    0.312  1.7 -0.0027 0.00844 #>  bill_length_mm mean(dY/dX) Chinstrap  0.03680    0.00976 3.77   <0.001 12.6  0.0177 0.05594 #>  #> Columns: term, contrast, species, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo aggregate(   mfx$estimate,   by = list(mfx$species, mfx$term),   FUN = mean) #>     Group.1           Group.2            x #> 1    Adelie    bill_length_mm  0.043539914 #> 2 Chinstrap    bill_length_mm  0.036801185 #> 3    Gentoo    bill_length_mm  0.002871562 #> 4    Adelie flipper_length_mm  0.016710631 #> 5 Chinstrap flipper_length_mm  0.014124217 #> 6    Gentoo flipper_length_mm  0.001102231 #> 7    Adelie           species -0.054519623 #> 8 Chinstrap           species -0.313337522 #> 9    Gentoo           species -0.250726004"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/slopes.html","id":"marginal-effect-at-user-specified-values","dir":"Articles","previous_headings":"","what":"Marginal Effect at User-Specified Values","title":"Slopes","text":"Sometimes, interested unit-specific marginal effects, rather look estimated marginal effects certain “typical” individuals, user-specified values regressors. datagrid function helps us build data grid full “typical” rows. example, generate artificial Adelies Gentoos 180mm flippers: command can used (omitting model argument) marginaleffects’s newdata argument compute marginal effects (fictional) individuals: variables omitted datagrid call, automatically set mean mode (depending variable type).","code":"datagrid(flipper_length_mm = 180,          species = c(\"Adelie\", \"Gentoo\"),          model = mod) #>   large_penguin bill_length_mm flipper_length_mm species #> 1     0.4853801       43.92193               180  Adelie #> 2     0.4853801       43.92193               180  Gentoo slopes(   mod,   newdata = datagrid(     flipper_length_mm = 180,     species = c(\"Adelie\", \"Gentoo\"))) #>  #>               Term           Contrast Estimate Std. Error      z Pr(>|z|)    S    2.5 %   97.5 % bill_length_mm flipper_length_mm species #>  bill_length_mm    dY/dX                0.0607    0.03323  1.827   0.0677  3.9 -0.00443  0.12581           43.9               180  Adelie #>  bill_length_mm    dY/dX                0.0847    0.03939  2.150   0.0316  5.0  0.00747  0.16187           43.9               180  Gentoo #>  flipper_length_mm dY/dX                0.0233    0.00550  4.232   <0.001 15.4  0.01250  0.03408           43.9               180  Adelie #>  flipper_length_mm dY/dX                0.0325    0.00851  3.817   <0.001 12.9  0.01581  0.04918           43.9               180  Gentoo #>  species           Chinstrap - Adelie  -0.2111    0.10618 -1.988   0.0468  4.4 -0.41916 -0.00294           43.9               180  Adelie #>  species           Chinstrap - Adelie  -0.2111    0.10618 -1.988   0.0468  4.4 -0.41916 -0.00294           43.9               180  Gentoo #>  species           Gentoo - Adelie      0.1591    0.30242  0.526   0.5988  0.7 -0.43361  0.75185           43.9               180  Adelie #>  species           Gentoo - Adelie      0.1591    0.30242  0.526   0.5988  0.7 -0.43361  0.75185           43.9               180  Gentoo #>  #> Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, large_penguin, bill_length_mm, flipper_length_mm, species"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/slopes.html","id":"marginal-effect-at-the-mean-mem","dir":"Articles","previous_headings":"","what":"Marginal Effect at the Mean (MEM)","title":"Slopes","text":"“Marginal Effect Mean” marginal effect calculated hypothetical observation regressor set mean mode. default, datagrid function used previous section sets regressors means modes. calculate MEM, can set newdata argument, determines values predictors want compute marginal effects:","code":"slopes(mod, newdata = \"mean\") #>  #>               Term           Contrast Estimate Std. Error       z Pr(>|z|)    S    2.5 %  97.5 % #>  bill_length_mm    dY/dX                0.0502    0.01238   4.059   <0.001 14.3  0.02598  0.0745 #>  flipper_length_mm dY/dX                0.0193    0.00553   3.487   <0.001 11.0  0.00844  0.0301 #>  species           Chinstrap - Adelie  -0.8070    0.07636 -10.569   <0.001 84.3 -0.95670 -0.6574 #>  species           Gentoo - Adelie      0.0829    0.11453   0.723    0.469  1.1 -0.14161  0.3073 #>  #> Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, large_penguin, bill_length_mm, flipper_length_mm, species"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/slopes.html","id":"counterfactual-marginal-effects","dir":"Articles","previous_headings":"","what":"Counterfactual Marginal Effects","title":"Slopes","text":"datagrid function allowed us look completely fictional individuals. Setting grid_type argument function \"counterfactual\" lets us compute marginal effects actual observations dataset, manipulated values. example, code create data.frame twice long original dat, observation repeated different values flipper_length_mm variable: see rows 1, 2, 3 original dataset replicated twice, different values flipper_length_mm variable: can use observation-level marginal effects compute average (median, anything else) marginal effects counterfactual individuals:","code":"nd <- datagrid(flipper_length_mm = c(160, 180),                model = mod,                grid_type = \"counterfactual\") nd[nd$rowid %in% 1:3,] #>     rowidcf large_penguin bill_length_mm species flipper_length_mm #> 1         1             0           39.1  Adelie               160 #> 2         2             0           39.5  Adelie               160 #> 3         3             0           40.3  Adelie               160 #> 343       1             0           39.1  Adelie               180 #> 344       2             0           39.5  Adelie               180 #> 345       3             0           40.3  Adelie               180 library(dplyr)  slopes(mod, newdata = nd) |>     group_by(term) |>     summarize(estimate = median(estimate)) #> # A tibble: 3 × 2 #>   term               estimate #>   <chr>                 <dbl> #> 1 bill_length_mm    0.00985   #> 2 flipper_length_mm 0.00378   #> 3 species           0.0000226"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/slopes.html","id":"conditional-marginal-effects-plot","dir":"Articles","previous_headings":"","what":"Conditional Marginal Effects (Plot)","title":"Slopes","text":"plot_slopes function can used draw “Conditional Marginal Effects.” useful model includes interaction terms want plot marginal effect variable changes value “condition” (“moderator”) variable changes:  marginal effects plot computed values regressors – except variables condition – held means modes, depending variable type. Since plot_slopes() produces ggplot2 object, easy customize. example:","code":"mod <- lm(mpg ~ hp * wt + drat, data = mtcars)  plot_slopes(mod, variables = \"hp\", condition = \"wt\") plot_slopes(mod, variables = \"hp\", condition = \"wt\") +     geom_rug(aes(x = wt), data = mtcars) +     theme_classic()"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/slopes.html","id":"example-quadratic","dir":"Articles","previous_headings":"","what":"Example: Quadratic","title":"Slopes","text":"“Definition” section vignette, considered marginal effects can computed analytically simple quadratic equation context. can now use slopes function replicate analysis quadratic function regression application. Say estimate linear regression model quadratic term: \\[Y = \\beta_0 + \\beta_1 X^2 + \\varepsilon\\] obtain estimates \\(\\beta_0=1\\) \\(\\beta_1=2\\). Taking partial derivative respect \\(X\\) plugging estimates gives us marginal effect \\(X\\) \\(Y\\): \\[\\partial Y / \\partial X = \\beta_0 + 2 \\cdot \\beta_1 X\\] \\[\\partial Y / \\partial X = 1 + 4X\\] result suggests effect change \\(X\\) \\(Y\\) depends level \\(X\\). \\(X\\) large positive, increase \\(X\\) associated large increase \\(Y\\). \\(X\\) small positive, increase \\(X\\) associated small increase \\(Y\\). \\(X\\) large negative value, increase \\(X\\) associated decrease \\(Y\\). marginaleffects arrives conclusion simulated data: can plot conditional adjusted predictions plot_predictions function:  can plot conditional marginal effects plot_slopes function (see section ):  , conclusion . \\(x<0\\), increase \\(x\\) associated decrease \\(y\\). \\(x>1/4\\), marginal effect positive, suggests increase \\(x\\) associated increase \\(y\\).","code":"library(tidyverse) N <- 1e5 quad <- data.frame(x = rnorm(N)) quad$y <- 1 + 1 * quad$x + 2 * quad$x^2 + rnorm(N) mod <- lm(y ~ x + I(x^2), quad)  slopes(mod, newdata = datagrid(x = -2:2))  |>     mutate(truth = 1 + 4 * x) |>     select(estimate, truth) #>  #>  Estimate #>    -6.983 #>    -2.993 #>     0.997 #>     4.987 #>     8.977 #>  #> Columns: estimate, truth plot_predictions(mod, condition = \"x\") plot_slopes(mod, variables = \"x\", condition = \"x\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/slopes.html","id":"slopes-vs-predictions-a-visual-interpretation","dir":"Articles","previous_headings":"","what":"Slopes vs Predictions: A Visual Interpretation","title":"Slopes","text":"Often, analysts plot predicted values outcome best fit line:  slope line calculated using technique learned grade school: dividing rise run.  Instead computing slope manually, can just call: Now, consider fact model includes interaction hp qsec. means slope actually differ based value moderator variable qsec:  can estimate slopes three fit lines easily: see graph, three slopes negative, Q3 slope steepest. push one step , measure slope mpg respect hp, observed values qsec. achieved plot_slopes() function:  plot shows marginal effect hp mpg always negative (slope always zero), effect becomes even negative qsec increases.","code":"library(ggplot2)  mod <- lm(mpg ~ hp * qsec, data = mtcars)  plot_predictions(mod, condition = \"hp\", vcov = TRUE) +   geom_point(data = mtcars, aes(hp, mpg)) p <- plot_predictions(mod, condition = \"hp\", vcov = TRUE, draw = FALSE) plot_predictions(mod, condition = \"hp\", vcov = TRUE) +   geom_segment(aes(x = p$hp[10], xend = p$hp[10], y = p$estimate[10], yend = p$estimate[20])) +   geom_segment(aes(x = p$hp[10], xend = p$hp[20], y = p$estimate[20], yend = p$estimate[20])) +   annotate(\"text\", label = \"Rise\", y = 10, x = 140) +   annotate(\"text\", label = \"Run\", y = 2, x = 200) avg_slopes(mod, variables = \"hp\") #>  #>  Term Estimate Std. Error     z Pr(>|z|)    S  2.5 %  97.5 % #>    hp   -0.112     0.0126 -8.92   <0.001 60.9 -0.137 -0.0874 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high plot_predictions(mod, condition = list(\"hp\", \"qsec\" = \"quartile\")) slopes(   mod,   variables = \"hp\",   newdata = datagrid(qsec = quantile(mtcars$qsec, probs = c(.25, .5, .75)))) #>  #>  Term Estimate Std. Error     z Pr(>|z|)    S  2.5 %  97.5 %  hp qsec #>    hp  -0.0934     0.0111 -8.43   <0.001 54.7 -0.115 -0.0717 147 16.9 #>    hp  -0.1093     0.0123 -8.92   <0.001 60.9 -0.133 -0.0853 147 17.7 #>    hp  -0.1325     0.0154 -8.60   <0.001 56.9 -0.163 -0.1023 147 18.9 #>  #> Columns: rowid, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, mpg, hp, qsec plot_slopes(mod, variables = \"hp\", condition = \"qsec\") +   geom_hline(yintercept = 0, linetype = 3)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/slopes.html","id":"prediction-types","dir":"Articles","previous_headings":"","what":"Prediction types","title":"Slopes","text":"marginaleffect function takes derivative fitted (predicted) values model, typically generated predict(model) function. default, predict produces predictions \"response\" scale, marginal effects interpreted scale. However, users can pass string vector strings type argument, marginaleffects consider different outcomes. Typical values include \"response\" \"link\", users refer documentation predict package used fit model know values allowable. documentation.","code":"mod <- glm(am ~ mpg, family = binomial, data = mtcars) avg_slopes(mod, type = \"response\") #>  #>  Term Estimate Std. Error    z Pr(>|z|)    S  2.5 % 97.5 % #>   mpg   0.0465    0.00887 5.24   <0.001 22.6 0.0291 0.0639 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  avg_slopes(mod, type = \"link\") #>  #>  Term Estimate Std. Error    z Pr(>|z|)   S  2.5 % 97.5 % #>   mpg    0.307      0.115 2.67  0.00751 7.1 0.0819  0.532 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/tables.html","id":"marginal-effects","dir":"Articles","previous_headings":"","what":"Marginal effects","title":"Tables","text":"can summarize results comparisons() slopes() functions using modelsummary package. results can visualized modelplot():","code":"library(modelsummary) library(marginaleffects)  mod <- glm(am ~ wt + drat, family = binomial, data = mtcars) mfx <- slopes(mod)  modelsummary(mfx) modelplot(mfx)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/tables.html","id":"contrasts","dir":"Articles","previous_headings":"","what":"Contrasts","title":"Tables","text":"using comparisons() function (slopes() function categorical variables), output include two columns uniquely identify quantities interest: term contrast. can use shape argument modelsummary function structure table properly: Cross-contrasts can bit trickier, since multiple simultaneous groups. Consider example: can see , two relevant grouping columns: contrast_gear contrast_cyl. can simply plug names shape argument:","code":"dat <- mtcars dat$gear <- as.factor(dat$gear) mod <- glm(vs ~ gear + mpg, data = dat, family = binomial)  cmp <- comparisons(mod) get_estimates(cmp) #> # A tibble: 3 × 8 #>   term  contrast          estimate std.error statistic    p.value conf.low conf.high #>   <chr> <chr>                <dbl>     <dbl>     <dbl>      <dbl>    <dbl>     <dbl> #> 1 gear  mean(4) - mean(3)   0.0372    0.137      0.272 0.785       -0.230     0.305  #> 2 gear  mean(5) - mean(3)  -0.340     0.0988    -3.44  0.000588    -0.533    -0.146  #> 3 mpg   mean(+1)            0.0608    0.0128     4.74  0.00000218   0.0356    0.0860 modelsummary(cmp, shape = term + contrast ~ model) mod <- lm(mpg ~ factor(cyl) + factor(gear), data = mtcars) cmp <- comparisons(   mod,   variables = c(\"gear\", \"cyl\"),   cross = TRUE) get_estimates(cmp) #> # A tibble: 4 × 9 #>   term  contrast_gear     contrast_cyl      estimate std.error statistic p.value conf.low conf.high #>   <chr> <chr>             <chr>                <dbl>     <dbl>     <dbl>   <dbl>    <dbl>     <dbl> #> 1 cross mean(4) - mean(3) mean(6) - mean(4)    -5.33      2.77     -1.93 0.0542     -10.8  0.0953   #> 2 cross mean(4) - mean(3) mean(8) - mean(4)    -9.22      3.62     -2.55 0.0108     -16.3 -2.13     #> 3 cross mean(5) - mean(3) mean(6) - mean(4)    -5.16      2.63     -1.96 0.0500     -10.3  0.000166 #> 4 cross mean(5) - mean(3) mean(8) - mean(4)    -9.04      3.19     -2.84 0.00453    -15.3 -2.80 modelsummary(   cmp,   shape = contrast_gear + contrast_cyl ~ model)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/tables.html","id":"marginal-means","dir":"Articles","previous_headings":"","what":"Marginal means","title":"Tables","text":"Estimated Marginal Means","code":"library(\"marginaleffects\") library(\"modelsummary\")  dat <- mtcars dat$cyl <- as.factor(dat$cyl) dat$am <- as.logical(dat$am) mod <- lm(mpg ~ hp + cyl + am, data = dat) mm <- marginal_means(mod)  modelsummary(mm,              title = \"Estimated Marginal Means\",              estimate = \"{estimate} ({std.error}){stars}\",              statistic = NULL,              group = term + value ~ model)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/uncertainty.html","id":"delta-method","dir":"Articles","previous_headings":"","what":"Delta Method","title":"Standard Errors and Confidence Intervals","text":"standard errors generated slopes(), comparisons(), hypotheses() functions package estimated using delta method. Mathematical treatments method can found statistics textbooks Wikipedia. Roughly speaking, delta method allows us approximate distribution smooth function asymptotically normal estimator. Concretely, allows us generate standard errors around functions model’s coefficient estimates. Predictions, contrasts, marginal effects, marginal means functions coefficients, can use delta method estimate standard errors around quantities. Since lot mathematical treatments available elsewhere, vignette focuses “implementation” marginaleffects. Consider case marginal_means() function. user calls function, obtain vector marginal means. estimate standard errors around vector: Compute marginal means original model: \\(f(\\beta)\\) Increment first (first) coefficient held inside model object small amount, compute marginal means : \\(f(\\beta+\\varepsilon)\\) Calculate: \\(\\frac{f(\\beta+\\varepsilon) - f(\\beta)}{\\varepsilon}\\) Repeat step 1 every coefficient model construct \\(J\\) matrix. Extract variance-covariance matrix coefficient estimates: \\(V\\) Standard errors square root diagonal \\(JVJ'\\) Scroll page Numerical Derivatives section see detailed explanation, along code manual computation.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/uncertainty.html","id":"standard-errors-and-intervals-for-slopes-and-comparisons","dir":"Articles","previous_headings":"","what":"Standard errors and intervals for slopes() and comparisons()","title":"Standard Errors and Confidence Intervals","text":"standard errors slopes() comparisons() functions computed using delta method, described .","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/uncertainty.html","id":"standard-errors-and-intervals-for-marginal_means-and-predictions","dir":"Articles","previous_headings":"","what":"Standard errors and intervals for marginal_means() and predictions()","title":"Standard Errors and Confidence Intervals","text":"marginal_means() predictions() function can compute confidence intervals two ways. following conditions hold: user sets: type = \"response\" model class glm transform argument NULL marginal_means() predictions() first compute estimates link scale, back transform using inverse link function supplied insight::link_inverse(model) function. cases, standard errors computed using delta method described .","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/uncertainty.html","id":"robust-standard-errors","dir":"Articles","previous_headings":"","what":"Robust standard errors","title":"Standard Errors and Confidence Intervals","text":"functions marginaleffects package can compute robust standard errors fly model type supported sandwich package. vcov argument supports string shortcuts like \"HC3\", one-sided formula request clustered standard errors, variance-covariance matrices, functions return matrices. examples. Adjusted predictions classical heteroskedasticity-robust standard errors: Marginal effects cluster-robust standard errors: Comparing adjusted predictions classical robust standard errors:","code":"library(marginaleffects) library(patchwork) mod <- lm(mpg ~ hp, data = mtcars)  p <- predictions(mod) head(p, 2) #>  #>  Estimate Std. Error    z Pr(>|z|)     S 2.5 % 97.5 % #>      22.6      0.777 29.1   <0.001 614.7  21.1   24.1 #>      22.6      0.777 29.1   <0.001 614.7  21.1   24.1 #>  #> Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, mpg, hp  p <- predictions(mod, vcov = \"HC3\") head(p, 2) #>  #>  Estimate Std. Error    z Pr(>|z|)     S 2.5 % 97.5 % #>      22.6      0.863 26.2   <0.001 499.5  20.9   24.3 #>      22.6      0.863 26.2   <0.001 499.5  20.9   24.3 #>  #> Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, mpg, hp avg_slopes(mod, vcov = ~cyl) #>  #>  Term Estimate Std. Error     z Pr(>|z|)    S  2.5 %  97.5 % #>    hp  -0.0682     0.0187 -3.65   <0.001 11.9 -0.105 -0.0316 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high p1 <- plot_predictions(mod, condition = \"hp\") p2 <- plot_predictions(mod, condition = \"hp\", vcov = \"HC3\") p1 + p2"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/uncertainty.html","id":"simulation-based-inference","dir":"Articles","previous_headings":"","what":"Simulation-based inference","title":"Standard Errors and Confidence Intervals","text":"marginaleffects offers experimental inferences function conduct simulation-based inference following strategy proposed Krinsky & Robb (1986): Draw iter sets simulated coefficients multivariate normal distribution mean equal original model’s estimated coefficients variance equal model’s variance-covariance matrix (classical, “HC3”, ). Use iter sets coefficients compute iter sets estimands: predictions, comparisons, slopes. Take quantiles resulting distribution estimands obtain confidence interval standard deviation simulated estimates estimate standard error. examples: Since simulation based inference generates iter estimates quantities interest, can treat similarly draws posterior distribution bayesian models. example, can extract draws using posterior_draws() function, plot distributions using packages likeggplot2 ggdist:","code":"library(marginaleffects) library(ggplot2) library(ggdist)  mod <- glm(vs ~ hp * wt + factor(gear), data = mtcars, family = binomial)  mod |> predictions() |> inferences(method = \"simulation\") #>  #>  Estimate Std. Error    2.5 % 97.5 % #>  7.84e-01      0.192 2.77e-01  0.970 #>  7.84e-01      0.165 3.53e-01  0.956 #>  8.98e-01      0.137 4.72e-01  0.989 #>  8.74e-01      0.225 1.78e-01  0.996 #>  1.31e-02      0.185 4.82e-05  0.714 #> --- 22 rows omitted. See ?avg_predictions and ?print.marginaleffects ---  #>  3.83e-01      0.294 1.61e-02  0.965 #>  1.21e-06      0.124 1.94e-12  0.286 #>  6.89e-03      0.163 2.42e-05  0.672 #>  8.07e-11      0.124 2.22e-16  0.242 #>  7.95e-01      0.166 3.58e-01  0.962 #> Columns: rowid, estimate, std.error, conf.low, conf.high, vs, hp, wt, gear  mod |> avg_slopes(vcov = ~gear) |> inferences(method = \"simulation\") #>  #>  Term Contrast Estimate Std. Error   2.5 %  97.5 % #>  gear    4 - 3 -0.03835    0.05754 -0.0918 0.14395 #>  gear    5 - 3 -0.16442    0.27100 -0.4866 0.33515 #>  hp      dY/dX -0.00506    0.00435 -0.0113 0.00401 #>  wt      dY/dX  0.03135    0.31045 -0.6061 0.71764 #>  #> Columns: term, contrast, estimate, std.error, conf.low, conf.high mod |>   avg_comparisons(variables = \"gear\") |>   inferences(method = \"simulation\") |>   posterior_draws(\"rvar\") |>   ggplot(aes(y = contrast, xdist = rvar)) +   stat_slabinterval()"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/uncertainty.html","id":"bootstrap","dir":"Articles","previous_headings":"","what":"Bootstrap","title":"Standard Errors and Confidence Intervals","text":"easy use bootstrap alternative strategy compute standard errors confidence intervals. Several R packages can help us achieve , including long-established boot package: Note , code , set vcov=FALSE avoid computation delta method standard errors speed things . Compare delta method standard errors:","code":"library(boot) set.seed(123)  bootfun <- function(data, indices, ...) {     d <- data[indices, ]     mod <- lm(mpg ~ am + hp + factor(cyl), data = d)     cmp <- comparisons(mod, newdata = d, vcov = FALSE, variables = \"am\")     tidy(cmp)$estimate }  b <- boot(data = mtcars, statistic = bootfun, R = 1000)  b #>  #> ORDINARY NONPARAMETRIC BOOTSTRAP #>  #>  #> Call: #> boot(data = mtcars, statistic = bootfun, R = 1000) #>  #>  #> Bootstrap Statistics : #>     original     bias    std. error #> t1* 4.157856 0.01543426    1.003461 boot.ci(b, type = \"perc\") #> BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS #> Based on 1000 bootstrap replicates #>  #> CALL :  #> boot.ci(boot.out = b, type = \"perc\") #>  #> Intervals :  #> Level     Percentile      #> 95%   ( 2.240,  6.277 )   #> Calculations and Intervals on Original Scale mod <- lm(mpg ~ am + hp + factor(cyl), data = mtcars) avg_comparisons(mod, variables = \"am\") #>  #>  Term Contrast Estimate Std. Error    z Pr(>|z|)    S 2.5 % 97.5 % #>    am    1 - 0     4.16       1.26 3.31   <0.001 10.1   1.7   6.62 #>  #> Columns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/uncertainty.html","id":"mixed-effects-models-satterthwaite-and-kenward-roger-corrections","dir":"Articles","previous_headings":"","what":"Mixed effects models: Satterthwaite and Kenward-Roger corrections","title":"Standard Errors and Confidence Intervals","text":"linear mixed effects models can apply Satterthwaite Kenward-Roger corrections way : Marginal effects mean classical standard errors z-statistic: Marginal effects mean Kenward-Roger adjusted variance-covariance degrees freedom: can use option package’s core functions, including:","code":"library(marginaleffects) library(patchwork) library(lme4)  dat <- mtcars dat$cyl <- factor(dat$cyl) dat$am <- as.logical(dat$am) mod <- lmer(mpg ~ hp + am + (1 | cyl), data = dat) slopes(mod, newdata = \"mean\") #>  #>  Term     Contrast Estimate Std. Error     z Pr(>|z|)    S   2.5 %  97.5 % #>    hp dY/dX         -0.0518     0.0115 -4.52   <0.001 17.3 -0.0743 -0.0294 #>    am TRUE - FALSE   4.6661     1.1343  4.11   <0.001 14.6  2.4430  6.8892 #>  #> Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, mpg, hp, am, cyl slopes(mod,                 newdata = \"mean\",                 vcov = \"kenward-roger\") #>  #>  Term     Contrast Estimate Std. Error     t Pr(>|t|)   S  2.5 %  97.5 %   Df #>    hp dY/dX         -0.0518     0.0152 -3.41   0.0964 3.4 -0.131  0.0269 1.68 #>    am TRUE - FALSE   4.6661     1.2824  3.64   0.0874 3.5 -1.980 11.3121 1.68 #>  #> Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, df, predicted, predicted_hi, predicted_lo, mpg, hp, am, cyl plot_predictions(mod, condition = \"hp\", vcov = \"satterthwaite\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/uncertainty.html","id":"numerical-derivatives-sensitivity-to-step-size","dir":"Articles","previous_headings":"","what":"Numerical derivatives: Sensitivity to step size","title":"Standard Errors and Confidence Intervals","text":"marginaleffects uses numerical derivatives two contexts: Centered finite difference \\(\\frac{f(x + \\varepsilon_1 / 2) - f(x - \\varepsilon_1 / 2)}{\\varepsilon_1}\\), take derivative respect predictor interest, \\(f\\) predict() function. Forward finite difference \\(\\frac{g(\\hat{\\beta}) - g(\\hat{\\beta} + \\varepsilon_2)}{\\varepsilon_2}\\), take derivative respect model’s coefficients, \\(g\\) marginaleffects function returns quantity interest (e.g., slope, marginal means, predictions, etc.) Note step sizes used two contexts can differ. variables coefficients different scales, may make sense use different values \\(\\varepsilon_1\\) \\(\\varepsilon_2\\). default, \\(\\varepsilon_1\\) set 1e-4 times range variable respect taking derivative. default, \\(\\varepsilon_2\\) set maximum value 1e-8, 1e-4 times smallest absolute coefficient estimate. (choices arbitrary, found practice, smaller values can produce unstable results.) \\(\\varepsilon_1\\) can controlled eps argument slopes() function. \\(\\varepsilon_2\\) can controlled setting global option tells marginaleffects compute jacobian using numDeriv package instead internal functions. allows control step size, also gives access differentiation methods, Richardson’s. use numDeriv, define list arguments pushed forward numDeriv::jacobian: Notice standard errors can vary considerably using different step sizes. good practice analysts consider sensitivity results setting. Now, illustrate full process standard error computation, using raw R code. First, choose two step sizes: can get estimates manually steps: get standard errors, build jacobian matrix column holds derivatives vector valued slope function, respect coefficients. Using example: gives us first column \\(J\\), can recover full marginaleffects object attribute: build full matrix, simply iterate coefficients, incrementing one . Finally, get standard errors via: corresponds original standard errors: Reverting default settings: Note default results model similar – exactly identical – generated margins. expected, results margins also sensitive value eps model:","code":"dat <- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\") dat$large_penguin <- ifelse(dat$body_mass_g > median(dat$body_mass_g, na.rm = TRUE), 1, 0) mod <- glm(large_penguin ~ bill_length_mm * flipper_length_mm + species, data = dat, family = binomial) avg_slopes(mod, variables = \"bill_length_mm\") #>  #>            Term Estimate Std. Error    z Pr(>|z|)    S  2.5 % 97.5 % #>  bill_length_mm   0.0279    0.00595 4.68   <0.001 18.4 0.0162 0.0395 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  options(marginaleffects_numDeriv = list(method = \"Richardson\")) avg_slopes(mod, variables = \"bill_length_mm\") #>  #>            Term Estimate Std. Error    z Pr(>|z|)    S  2.5 % 97.5 % #>  bill_length_mm   0.0279    0.00595 4.68   <0.001 18.4 0.0162 0.0395 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  options(marginaleffects_numDeriv = list(method = \"simple\", method.args = list(eps = 1e-3))) avg_slopes(mod, variables = \"bill_length_mm\") #>  #>            Term Estimate Std. Error     z Pr(>|z|)   S 2.5 % 97.5 % #>  bill_length_mm   0.0279      0.568 0.049    0.961 0.1 -1.09   1.14 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  options(marginaleffects_numDeriv = list(method = \"simple\", method.args = list(eps = 1e-5))) avg_slopes(mod, variables = \"bill_length_mm\") #>  #>            Term Estimate Std. Error    z Pr(>|z|)    S  2.5 % 97.5 % #>  bill_length_mm   0.0279    0.00601 4.64   <0.001 18.1 0.0161 0.0396 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  options(marginaleffects_numDeriv = list(method = \"simple\", method.args = list(eps = 1e-7))) avg_slopes(mod, variables = \"bill_length_mm\") #>  #>            Term Estimate Std. Error    z Pr(>|z|)    S  2.5 % 97.5 % #>  bill_length_mm   0.0279    0.00595 4.68   <0.001 18.4 0.0162 0.0395 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high eps1 <- 1e-5 # slope eps2 <- 1e-7 # delta method  s <- slopes(mod, newdata = head(dat, 3), variables = \"bill_length_mm\", eps = eps1) print(s[, 1:5], digits = 6) #>  #>            Term  Estimate Std. Error       z #>  bill_length_mm 0.0179765 0.00872913 2.05937 #>  bill_length_mm 0.0359630 0.01254757 2.86613 #>  bill_length_mm 0.0849071 0.02128611 3.98885 #>  #> Columns: rowid, term, estimate, std.error, statistic linkinv <- mod$family$linkinv  # increment the variable of interest by h dat_hi <- transform(dat, bill_length_mm = bill_length_mm + eps1)  # model matrices: first 3 rows mm_lo <- insight::get_modelmatrix(mod, data = dat)[1:3,] mm_hi <- insight::get_modelmatrix(mod, data = dat_hi)[1:3,]  # predictions p_lo <- linkinv(mm_lo %*% coef(mod)) p_hi <- linkinv(mm_hi %*% coef(mod))  # slopes (p_hi - p_lo) / eps1 #>         [,1] #> 1 0.01797653 #> 2 0.03596304 #> 3 0.08490712 b_lo <- b_hi <- coef(mod) b_hi[1] <- b_hi[1] + eps2  dydx_lo <- (linkinv(mm_hi %*% b_lo) - linkinv(mm_lo %*% b_lo)) / eps1 dydx_hi <- (linkinv(mm_hi %*% b_hi) - linkinv(mm_lo %*% b_hi)) / eps1 (dydx_hi - dydx_lo) / eps2 #>         [,1] #> 1 0.01600803 #> 2 0.02768619 #> 3 0.02275957 J <- attr(s, \"jacobian\") J #>      (Intercept) bill_length_mm flipper_length_mm speciesChinstrap speciesGentoo bill_length_mm:flipper_length_mm #> [1,]  0.01600803      0.6777495          2.897252                0             0                         122.6916 #> [2,]  0.02768619      1.1961404          5.153100                0             0                         222.4993 #> [3,]  0.02275957      1.1492474          4.439948                0             0                         224.0825 sqrt(diag(J %*% vcov(mod) %*% t(J))) #> [1] 0.008729126 0.012547575 0.021286107 print(s[, 1:5], digits = 7) #>  #>            Term   Estimate  Std. Error        z #>  bill_length_mm 0.01797653 0.008729126 2.059374 #>  bill_length_mm 0.03596304 0.012547575 2.866135 #>  bill_length_mm 0.08490712 0.021286107 3.988851 #>  #> Columns: rowid, term, estimate, std.error, statistic options(marginaleffects_numDeriv = NULL) library(margins) margins(mod, variables = \"bill_length_mm\", data = head(dat, 3), unit_ses = TRUE)$SE_dydx_bill_length_mm #> [1] 0.008728009 0.012567102 0.021293271  margins(mod, variables = \"bill_length_mm\", data = head(dat, 3), eps = 1e-4, unit_ses = TRUE)$SE_dydx_bill_length_mm #> [1] 0.2269512 0.2255849 0.6636208  margins(mod, variables = \"bill_length_mm\", data = head(dat, 3), eps = 1e-5, unit_ses = TRUE)$SE_dydx_bill_length_mm #> [1] 0.02317078 0.02928266 0.05480282"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/articles/uncertainty.html","id":"bayesian-estimates-and-credible-intervals","dir":"Articles","previous_headings":"","what":"Bayesian estimates and credible intervals","title":"Standard Errors and Confidence Intervals","text":"See brms vignette discussion bayesian estimates credible intervals.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Vincent Arel-Bundock. Author, maintainer, copyright holder. Marcio Augusto Diniz. Contributor. Noah Greifer. Contributor. Etienne Bacher. Contributor.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Arel-Bundock V (2023). marginaleffects: Predictions, Comparisons, Slopes, Marginal Means, Hypothesis Tests. R package version 0.12.0.9008, https://vincentarelbundock.github.io/marginaleffects/.","code":"@Manual{,   title = {marginaleffects: Predictions, Comparisons, Slopes, Marginal Means, and Hypothesis Tests},   author = {Vincent Arel-Bundock},   year = {2023},   note = {R package version 0.12.0.9008},   url = {https://vincentarelbundock.github.io/marginaleffects/}, }"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/index.html","id":"the-marginaleffects-package-for-r-","dir":"","previous_headings":"","what":"Predictions, Comparisons, Slopes, Marginal Means, and Hypothesis Tests","title":"Predictions, Comparisons, Slopes, Marginal Means, and Hypothesis Tests","text":"Compute plot predictions, slopes, marginal means, comparisons (contrasts, risk ratios, odds, etc.) 80 classes statistical models R. Conduct linear non-linear hypothesis tests, equivalence tests. Calculate uncertainty estimates using delta method, bootstrapping, simulation-based inference. marginaleffects website includes “Get started” tutorial 25+ vignettes, case studies, technical notes.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Predictions, Comparisons, Slopes, Marginal Means, and Hypothesis Tests","text":"Install latest CRAN release: Install development version: Restart R completely moving .","code":"install.packages(\"marginaleffects\") install.packages(     c(\"marginaleffects\", \"insight\"),     repos = c(\"https://vincentarelbundock.r-universe.dev\", \"https://easystats.r-universe.dev\"))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/index.html","id":"citing-marginaleffects","dir":"","previous_headings":"","what":"Citing marginaleffects","title":"Predictions, Comparisons, Slopes, Marginal Means, and Hypothesis Tests","text":"Arel-Bundock V (2023). marginaleffects: Predictions, Comparisons, Slopes, Marginal Means, Hypothesis Tests. R package version 0.9.0, https://vincentarelbundock.github.io/marginaleffects/.","code":"@Manual{marginaleffects,   title = {marginaleffects: Predictions, Comparisons, Slopes, Marginal Means, and Hypothesis Tests},   author = {Vincent Arel-Bundock},   year = {2023},   note = {R package version 0.9.0},   url = {https://vincentarelbundock.github.io/marginaleffects/}, }"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/index.html","id":"why","dir":"","previous_headings":"","what":"Why?","title":"Predictions, Comparisons, Slopes, Marginal Means, and Hypothesis Tests","text":"Parameter estimates often hard interpret substantively, especially generated complex models non-linear components transformations. Many applied researchers rather focus simple quantities interest, straightforward scientific interpretations. Unfortunately, estimands (standard errors) tedious compute. Moreover, different modeling packages R often produce inconsistent objects require special treatment. marginaleffects offers single point entry easily interpret results 80 classes models, using simple consistent user interface. Benefits marginaleffects include: Powerful: can compute predictions, comparisons (contrasts, risk ratios, etc.), slopes, conduct hypothesis tests 80 different classes models R. Simple: functions share simple unified interface. Documented: function thoroughly documented abundant examples. website includes 20,000+ words vignettes case studies. Efficient: operations orders magnitude faster margins package, memory footprint much smaller. Thin: dependencies. Standards-compliant: marginaleffects follows “tidy” principles returns objects work standard functions like summary(), head(), tidy(), glance(). objects easy program feed packages like modelsummary. Valid: possible, numerical results checked alternative software like Stata R packages. Unfortunately, possible test every model type, users still strongly encouraged cross-check results. Extensible: Adding support new models easy, often requiring less 10 lines new code. Please submit feature requests Github. Active development: Bugs fixed promptly.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/index.html","id":"what","dir":"","previous_headings":"","what":"What?","title":"Predictions, Comparisons, Slopes, Marginal Means, and Hypothesis Tests","text":"marginaleffects package allows R users compute plot three principal quantities interest: (1) predictions, (2) comparisons, (3) slopes. addition, package includes convenience function compute fourth estimand, “marginal means”, special case averaged predictions. marginaleffects can also average (“marginalize”) unit-level (“conditional”) estimates quantities, conduct hypothesis tests . Predictions: outcome predicted fitted model specified scale given combination values predictor variables, observed values, means, factor levels. .k.. Fitted values, adjusted predictions. predictions(), avg_predictions(), plot_predictions(). Comparisons: Compare predictions made model different regressor values (e.g., college graduates vs. others): contrasts, differences, risk ratios, odds, etc. comparisons(), avg_comparisons(), plot_comparisons(). Slopes: Partial derivative regression equation respect regressor interest. .k.. Marginal effects, trends. slopes(), avg_slopes(), plot_slopes(). Marginal Means: Predictions model, averaged across “reference grid” categorical predictors. marginalmeans().","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/comparisons.html","id":null,"dir":"Reference","previous_headings":"","what":"Comparisons Between Predictions Made With Different Regressor Values — comparisons","title":"Comparisons Between Predictions Made With Different Regressor Values — comparisons","text":"Predict outcome variable different regressor values (e.g., college graduates vs. others), compare predictions computing difference, ratio, function. comparisons() can return many quantities interest, contrasts, differences, risk ratios, changes log odds, slopes, elasticities, etc. comparisons(): unit-level (conditional) estimates. avg_comparisons(): average (marginal) estimates. variables identifies focal regressors whose \"effect\" interested . comparison determines predictions different regressor values compared (difference, ratio, odds, etc.). newdata argument datagrid() function control statistics evaluated predictor space: \"observed values\", \"mean\", \"representative values\", etc. See comparisons vignette package website worked examples case studies: https://vincentarelbundock.github.io/marginaleffects/articles/comparisons.html https://vincentarelbundock.github.io/marginaleffects/","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/comparisons.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Comparisons Between Predictions Made With Different Regressor Values — comparisons","text":"","code":"comparisons(   model,   newdata = NULL,   variables = NULL,   comparison = \"difference\",   type = NULL,   vcov = TRUE,   by = FALSE,   conf_level = 0.95,   transform = NULL,   cross = FALSE,   wts = NULL,   hypothesis = NULL,   equivalence = NULL,   p_adjust = NULL,   df = Inf,   eps = NULL,   ... )  avg_comparisons(   model,   newdata = NULL,   variables = NULL,   type = NULL,   vcov = TRUE,   by = TRUE,   conf_level = 0.95,   comparison = \"difference\",   transform = NULL,   cross = FALSE,   wts = NULL,   hypothesis = NULL,   equivalence = NULL,   p_adjust = NULL,   df = Inf,   eps = NULL,   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/comparisons.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Comparisons Between Predictions Made With Different Regressor Values — comparisons","text":"model Model object newdata Grid predictor values evaluate comparisons. NULL (default): Unit-level contrasts observed value original dataset (empirical distribution). See insight::get_data() data frame: Unit-level contrasts row newdata data frame. string: \"mean\": Contrasts Mean. Contrasts predictor held mean mode. \"median\": Contrasts Median. Contrasts predictor held median mode. \"marginalmeans\": Contrasts Marginal Means. \"tukey\": Contrasts Tukey's 5 numbers. \"grid\": Contrasts grid representative numbers (Tukey's 5 numbers unique values categorical predictors). datagrid() call specify custom grid regressors. example: newdata = datagrid(cyl = c(4, 6)): cyl variable equal 4 6 regressors fixed means modes. newdata = datagrid(mpg = fivenum): mpg variable held Tukey's five numbers (using fivenum function), regressors fixed means modes. See Examples section datagrid documentation. variables Focal variables NULL: compute comparisons variables model object (can slow). Character vector: subset variables (usually faster). Named list: names identify subset variables interest, values define type contrast compute. Acceptable values depend variable type: Factor character variables: \"reference\": factor level compared factor reference (base) level \"\": combinations observed levels \"sequential\": factor level compared previous factor level \"pairwise\": factor level compared levels \"minmax\": highest lowest levels factor. \"revpairwise\", \"revreference\", \"revsequential\": inverse corresponding hypotheses. Vector length 2 two values compare. Logical variables: NULL: contrast TRUE FALSE Numeric variables: Numeric length 1: Contrast gap x, computed observed value plus minus x / 2. example, estimating +1 contrast compares adjusted predictions regressor equal observed value minus 0.5 observed value plus 0.5. Numeric vector length 2: Contrast 2nd element 1st element x vector. Data frame number rows newdata, two columns \"low\" \"high\" values compare. Function accepts numeric vector returns data frame two columns \"low\" \"high\" values compare. See examples . \"iqr\": Contrast across interquartile range regressor. \"sd\": Contrast across one standard deviation around regressor mean. \"2sd\": Contrast across two standard deviations around regressor mean. \"minmax\": Contrast maximum minimum values regressor. Examples: variables = list(gear = \"pairwise\", hp = 10) variables = list(gear = \"sequential\", hp = c(100, 120)) See Examples section . comparison pairs predictions compared? Difference, ratio, odds ratio, user-defined functions. string: shortcuts common contrast functions. Supported shortcuts strings: difference, differenceavg, differenceavgwts, dydx, eyex, eydx, dyex, dydxavg, eyexavg, eydxavg, dyexavg, dydxavgwts, eyexavgwts, eydxavgwts, dyexavgwts, ratio, ratioavg, ratioavgwts, lnratio, lnratioavg, lnratioavgwts, lnor, lnoravg, lnoravgwts, expdydx, expdydxavg, expdydxavgwts See Comparisons section definitions transformation. function: accept two equal-length numeric vectors adjusted predictions (hi lo) returns vector contrasts length, unique numeric value. See Transformations section examples valid functions. type string indicates type (scale) predictions used compute contrasts slopes. can differ based model type, typically string : \"response\", \"link\", \"probs\", \"zero\". unsupported string entered, model-specific list acceptable values returned error message. type NULL, default value used. default first model-related row marginaleffects:::type_dictionary dataframe. vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model)) Aggregate unit-level estimates (aka, marginalize, average ). Valid inputs: FALSE: return original unit-level estimates. TRUE: aggregate estimates term. Character vector column names newdata data frame produced calling function without argument. Data frame column group labels, merging columns shared newdata data frame produced calling function without argument. See examples . conf_level numeric value 0 1. Confidence level use build confidence interval. transform string function. Transformation applied unit-level estimates confidence intervals just function returns results. Functions must accept vector return vector length. Support string shortcuts: \"exp\", \"ln\" cross FALSE: Contrasts represent change adjusted predictions one predictor changes variables held constant. TRUE: Contrasts represent changes adjusted predictions predictors specified variables argument manipulated simultaneously (\"cross-contrast\"). wts string numeric: weights use computing average contrasts slopes. weights affect averaging avg_*() argument, unit-level estimates . Internally, estimates weights passed weighted.mean() function. string: column name weights variable newdata. supplying column name wts, recommended supply original data (including weights variable) explicitly newdata. numeric: vector length equal number rows original data newdata (supplied). hypothesis specify hypothesis test custom contrast using numeric value, vector, matrix, string, string formula. Numeric: Single value: null hypothesis used computation Z p (applying transform). Vector: Weights compute linear combination (custom contrast ) estimates. Length equal number rows generated function call, without hypothesis argument. Matrix: column vector weights, describe , used compute distinct linear combination (contrast ) estimates. column names matrix used labels output. String formula specify linear non-linear hypothesis tests. term column uniquely identifies rows, terms can used formula. Otherwise, use b1, b2, etc. identify position parameter. Examples: hp = drat hp + drat = 12 b1 + b2 + b3 = 0 String: \"pairwise\": pairwise differences estimates row. \"reference\": differences estimates row estimate first row. \"sequential\": difference estimate estimate next row. \"revpairwise\", \"revreference\", \"revsequential\": inverse corresponding hypotheses, described . See Examples section vignette: https://vincentarelbundock.github.io/marginaleffects/articles/hypothesis.html equivalence Numeric vector length 2: bounds used two-one-sided test (TOST) equivalence, non-inferiority non-superiority tests. See Details section . p_adjust Adjust p-values multiple comparisons: \"holm\", \"hochberg\", \"hommel\", \"bonferroni\", \"BH\", \"\", \"fdr\". See stats::p.adjust df Degrees freedom used compute p values confidence intervals. single numeric value 1 Inf. df Inf, normal distribution used. df finite, t distribution used. See insight::get_df convenient function extract degrees freedom. Ex: slopes(model, df = insight::get_df(model)) eps NULL numeric value determines step size use calculating numerical derivatives: (f(x+eps)-f(x))/eps. eps NULL, step size 0.0001 multiplied difference maximum minimum values variable respect taking derivative. Changing eps may necessary avoid numerical problems certain models. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/comparisons.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Comparisons Between Predictions Made With Different Regressor Values — comparisons","text":"data.frame one row per observation (per term/group) several columns: rowid: row number newdata data frame type: prediction type, defined type argument group: (optional) value grouped outcome (e.g., categorical outcome models) term: variable whose marginal effect computed dydx: slope outcome respect term, given combination predictor values std.error: standard errors computed via delta method. p.value: p value associated estimate column. null determined hypothesis argument (0 default), p values computed applying transform argument. s.value: Shannon information tranforms p values. many consecutive \"heads\" tosses provide amount evidence (\"suprise\") null hypothesis coin fair? See Greenland (2019) Cole et al. (2020). conf.low: lower bound confidence interval (equal-tailed interval bayesian models) conf.high: upper bound confidence interval (equal-tailed interval bayesian models) See ?print.marginaleffects printing options.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/comparisons.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Comparisons Between Predictions Made With Different Regressor Values — comparisons","text":"avg_comparisons(): Average comparisons","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/comparisons.html","id":"standard-errors-using-the-delta-method","dir":"Reference","previous_headings":"","what":"Standard errors using the delta method","title":"Comparisons Between Predictions Made With Different Regressor Values — comparisons","text":"Standard errors quantities estimated marginaleffects can obtained via delta method. requires differentiating function respect coefficients model using finite difference approach. models, delta method standard errors can sensitive various aspects numeric differentiation strategy, including step size. default, step size set 1e-8, 1e-4 times smallest absolute model coefficient, whichever largest. marginaleffects can delegate numeric differentiation numDeriv package, allows flexibility. , users can pass arguments numDeriv::jacobian function global option. example: options(marginaleffects_numDeriv = list(method = \"simple\", method.args = list(eps = 1e-6))) options(marginaleffects_numDeriv = list(method = \"Richardson\", method.args = list(eps = 1e-5))) options(marginaleffects_numDeriv = NULL) See \"Standard Errors Confidence Intervals\" vignette marginaleffects website details computation standard errors: https://vincentarelbundock.github.io/marginaleffects/articles/uncertainty.html Note inferences() function can used compute uncertainty estimates using bootstrap simulation-based inference. See vignette: https://vincentarelbundock.github.io/marginaleffects/articles/bootstrap.html","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/comparisons.html","id":"model-specific-arguments","dir":"Reference","previous_headings":"","what":"Model-Specific Arguments","title":"Comparisons Between Predictions Made With Different Regressor Values — comparisons","text":"model types allow model-specific arguments modify nature marginal effects, predictions, marginal means, contrasts. Please report package-specific predict() arguments Github can add table . https://github.com/vincentarelbundock/marginaleffects/issues","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/comparisons.html","id":"comparison-argument-functions","dir":"Reference","previous_headings":"","what":"comparison argument functions","title":"Comparisons Between Predictions Made With Different Regressor Values — comparisons","text":"following transformations can applied supplying one shortcut strings comparison argument. hi vector adjusted predictions \"high\" side contrast. lo vector adjusted predictions \"low\" side contrast. y vector adjusted predictions original data. x predictor original data. eps step size use compute derivatives elasticities.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/comparisons.html","id":"bayesian-posterior-summaries","dir":"Reference","previous_headings":"","what":"Bayesian posterior summaries","title":"Comparisons Between Predictions Made With Different Regressor Values — comparisons","text":"default, credible intervals bayesian models built equal-tailed intervals. can changed highest density interval setting global option: options(\"marginaleffects_posterior_interval\" = \"eti\") options(\"marginaleffects_posterior_interval\" = \"hdi\") default, center posterior distribution bayesian models identified median. Users can use different summary function setting global option: options(\"marginaleffects_posterior_center\" = \"mean\") options(\"marginaleffects_posterior_center\" = \"median\") estimates averaged using argument, tidy() function, summary() function, posterior distribution marginalized twice . First, take average across units within iteration MCMC chain, according user requested argument tidy()/summary() functions. , identify center resulting posterior using function supplied \"marginaleffects_posterior_center\" option (median default).","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/comparisons.html","id":"equivalence-inferiority-superiority","dir":"Reference","previous_headings":"","what":"Equivalence, Inferiority, Superiority","title":"Comparisons Between Predictions Made With Different Regressor Values — comparisons","text":"\\(\\theta\\) estimate, \\(\\sigma_\\theta\\) estimated standard error, \\([, b]\\) bounds interval supplied equivalence argument. Non-inferiority: \\(H_0\\): \\(\\theta \\leq \\) \\(H_1\\): \\(\\theta > \\) \\(t=(\\theta - )/\\sigma_\\theta\\) p: Upper-tail probability Non-superiority: \\(H_0\\): \\(\\theta \\geq b\\) \\(H_1\\): \\(\\theta < b\\) \\(t=(\\theta - b)/\\sigma_\\theta\\) p: Lower-tail probability Equivalence: Two One-Sided Tests (TOST) p: Maximum non-inferiority non-superiority p values. Thanks Russell V. Lenth excellent emmeans package documentation inspired feature.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/comparisons.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Comparisons Between Predictions Made With Different Regressor Values — comparisons","text":"Greenland S. 2019. \"Valid P-Values Behave Exactly : Misleading Criticisms P-Values Resolution S-Values.\" American Statistician. 73(S1): 106–114. Cole, Stephen R, Jessie K Edwards, Sander Greenland. 2020. \"Surprise!\" American Journal Epidemiology 190 (2): 191–93. https://doi.org/10.1093/aje/kwaa136.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/comparisons.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Comparisons Between Predictions Made With Different Regressor Values — comparisons","text":"","code":"if (FALSE) { library(marginaleffects)  # Linear model tmp <- mtcars tmp$am <- as.logical(tmp$am) mod <- lm(mpg ~ am + factor(cyl), tmp) avg_comparisons(mod, variables = list(cyl = \"reference\")) avg_comparisons(mod, variables = list(cyl = \"sequential\")) avg_comparisons(mod, variables = list(cyl = \"pairwise\"))  # GLM with different scale types mod <- glm(am ~ factor(gear), data = mtcars) avg_comparisons(mod, type = \"response\") avg_comparisons(mod, type = \"link\")  # Contrasts at the mean comparisons(mod, newdata = \"mean\")  # Contrasts between marginal means comparisons(mod, newdata = \"marginalmeans\")  # Contrasts at user-specified values comparisons(mod, newdata = datagrid(am = 0, gear = tmp$gear)) comparisons(mod, newdata = datagrid(am = unique, gear = max))  m <- lm(mpg ~ hp + drat + factor(cyl) + factor(am), data = mtcars) comparisons(m, variables = \"hp\", newdata = datagrid(FUN_factor = unique, FUN_numeric = median))  # Numeric contrasts mod <- lm(mpg ~ hp, data = mtcars) avg_comparisons(mod, variables = list(hp = 1)) avg_comparisons(mod, variables = list(hp = 5)) avg_comparisons(mod, variables = list(hp = c(90, 100))) avg_comparisons(mod, variables = list(hp = \"iqr\")) avg_comparisons(mod, variables = list(hp = \"sd\")) avg_comparisons(mod, variables = list(hp = \"minmax\"))  # using a function to specify a custom difference in one regressor dat <- mtcars dat$new_hp <- 49 * (dat$hp - min(dat$hp)) / (max(dat$hp) - min(dat$hp)) + 1 modlog <- lm(mpg ~ log(new_hp) + factor(cyl), data = dat) fdiff <- \\(x) data.frame(x, x + 10) avg_comparisons(modlog, variables = list(new_hp = fdiff))  # Adjusted Risk Ratio: see the contrasts vignette mod <- glm(vs ~ mpg, data = mtcars, family = binomial) avg_comparisons(mod, comparison = \"lnratioavg\", transform = exp)  # Adjusted Risk Ratio: Manual specification of the `comparison` avg_comparisons(      mod,      comparison = function(hi, lo) log(mean(hi) / mean(lo)),      transform = exp) # cross contrasts mod <- lm(mpg ~ factor(cyl) * factor(gear) + hp, data = mtcars) avg_comparisons(mod, variables = c(\"cyl\", \"gear\"), cross = TRUE)  # variable-specific contrasts avg_comparisons(mod, variables = list(gear = \"sequential\", hp = 10))  # hypothesis test: is the `hp` marginal effect at the mean equal to the `drat` marginal effect mod <- lm(mpg ~ wt + drat, data = mtcars)  comparisons(     mod,     newdata = \"mean\",     hypothesis = \"wt = drat\")  # same hypothesis test using row indices comparisons(     mod,     newdata = \"mean\",     hypothesis = \"b1 - b2 = 0\")  # same hypothesis test using numeric vector of weights comparisons(     mod,     newdata = \"mean\",     hypothesis = c(1, -1))  # two custom contrasts using a matrix of weights lc <- matrix(c(     1, -1,     2, 3),     ncol = 2) comparisons(     mod,     newdata = \"mean\",     hypothesis = lc)   # `by` argument mod <- lm(mpg ~ hp * am * vs, data = mtcars) comparisons(mod, by = TRUE)  mod <- lm(mpg ~ hp * am * vs, data = mtcars) avg_comparisons(mod, variables = \"hp\", by = c(\"vs\", \"am\"))  library(nnet) mod <- multinom(factor(gear) ~ mpg + am * vs, data = mtcars, trace = FALSE) by <- data.frame(     group = c(\"3\", \"4\", \"5\"),     by = c(\"3,4\", \"3,4\", \"5\")) comparisons(mod, type = \"probs\", by = by) }"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/complete_levels.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a data.frame with all factor or character levels — complete_levels","title":"Create a data.frame with all factor or character levels — complete_levels","text":"model.matrix breaks newdata includes factor variable, levels present data. bad us often want get predictions one () rows, factor levels inevitably missing.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/complete_levels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a data.frame with all factor or character levels — complete_levels","text":"","code":"complete_levels(x, character_levels = NULL)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/datagrid.html","id":null,"dir":"Reference","previous_headings":"","what":"Data grids — datagrid","title":"Data grids — datagrid","text":"Generate data grid user-specified values use newdata argument predictions(), comparisons(), slopes() functions. useful define predictor space want evaluate quantities interest. Ex: predicted outcome slope 37 year old college graduate. datagrid() generates data frames combinations \"typical\" user-supplied predictor values. datagridcf() generates \"counter-factual\" data frames, replicating entire dataset every combination predictor values supplied user.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/datagrid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data grids — datagrid","text":"","code":"datagrid(   ...,   model = NULL,   newdata = NULL,   by = NULL,   FUN_character = get_mode,   FUN_factor = get_mode,   FUN_logical = get_mode,   FUN_numeric = function(x) mean(x, na.rm = TRUE),   FUN_integer = function(x) round(mean(x, na.rm = TRUE)),   FUN_other = function(x) mean(x, na.rm = TRUE),   grid_type = \"typical\" )  datagridcf(..., model = NULL, newdata = NULL)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/datagrid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Data grids — datagrid","text":"... named arguments vectors values functions user-specified variables. Functions applied variable model dataset newdata, must return vector appropriate type. Character vectors automatically transformed factors necessary. +output include combinations variables (see Examples .) model Model object newdata data.frame (one one model newdata arguments can used.) character vector grouping variables within FUN_* functions applied create \"sub-grids\" unspecified variables. FUN_character function applied character variables. FUN_factor function applied factor variables. FUN_logical function applied factor variables. FUN_numeric function applied numeric variables. FUN_integer function applied integer variables. FUN_other function applied variable types. grid_type character \"typical\": variables whose values explicitly specified user ... set mean mode, output functions supplied FUN_type arguments. \"counterfactual\": entire dataset duplicated combination variable values specified .... Variables explicitly supplied datagrid() set observed values original dataset.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/datagrid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Data grids — datagrid","text":"data.frame row corresponds one combination named predictors supplied user via ... dots. Variables explicitly defined held mean mode.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/datagrid.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Data grids — datagrid","text":"datagrid used predictions(), comparisons(), slopes() call newdata argument, model automatically inserted model argument datagrid() call, users need specify either model newdata arguments. users supply model, data used fit model retrieved using insight::get_data function.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/datagrid.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Data grids — datagrid","text":"datagridcf(): Counterfactual data grid","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/datagrid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data grids — datagrid","text":"","code":"# The output only has 2 rows, and all the variables except `hp` are at their # mean or mode. datagrid(newdata = mtcars, hp = c(100, 110)) #>        mpg    cyl     disp     drat      wt     qsec     vs      am   gear #> 1 20.09062 6.1875 230.7219 3.596563 3.21725 17.84875 0.4375 0.40625 3.6875 #> 2 20.09062 6.1875 230.7219 3.596563 3.21725 17.84875 0.4375 0.40625 3.6875 #>     carb  hp #> 1 2.8125 100 #> 2 2.8125 110  # We get the same result by feeding a model instead of a data.frame mod <- lm(mpg ~ hp, mtcars) datagrid(model = mod, hp = c(100, 110)) #>        mpg  hp #> 1 20.09062 100 #> 2 20.09062 110  # Use in `marginaleffects` to compute \"Typical Marginal Effects\". When used # in `slopes()` or `predictions()` we do not need to specify the #`model` or `newdata` arguments. slopes(mod, newdata = datagrid(hp = c(100, 110))) #>  #>  Term Estimate Std. Error     z Pr(>|z|)    S   2.5 %  97.5 %  hp #>    hp  -0.0682     0.0101 -6.74   <0.001 35.9 -0.0881 -0.0484 100 #>    hp  -0.0682     0.0101 -6.74   <0.001 35.9 -0.0881 -0.0484 110 #>  #> Columns: rowid, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, mpg, hp  #>   # datagrid accepts functions datagrid(hp = range, cyl = unique, newdata = mtcars) #>        mpg     disp     drat      wt     qsec     vs      am   gear   carb  hp #> 1 20.09062 230.7219 3.596563 3.21725 17.84875 0.4375 0.40625 3.6875 2.8125  52 #> 2 20.09062 230.7219 3.596563 3.21725 17.84875 0.4375 0.40625 3.6875 2.8125  52 #> 3 20.09062 230.7219 3.596563 3.21725 17.84875 0.4375 0.40625 3.6875 2.8125  52 #> 4 20.09062 230.7219 3.596563 3.21725 17.84875 0.4375 0.40625 3.6875 2.8125 335 #> 5 20.09062 230.7219 3.596563 3.21725 17.84875 0.4375 0.40625 3.6875 2.8125 335 #> 6 20.09062 230.7219 3.596563 3.21725 17.84875 0.4375 0.40625 3.6875 2.8125 335 #>   cyl #> 1   6 #> 2   4 #> 3   8 #> 4   6 #> 5   4 #> 6   8 comparisons(mod, newdata = datagrid(hp = fivenum)) #>  #>  Term Contrast Estimate Std. Error     z Pr(>|z|)    S   2.5 %  97.5 % #>    hp       +1  -0.0682     0.0101 -6.74   <0.001 35.9 -0.0881 -0.0484 #>    hp       +1  -0.0682     0.0101 -6.74   <0.001 35.9 -0.0881 -0.0484 #>    hp       +1  -0.0682     0.0101 -6.74   <0.001 35.9 -0.0881 -0.0484 #>    hp       +1  -0.0682     0.0101 -6.74   <0.001 35.9 -0.0881 -0.0484 #>    hp       +1  -0.0682     0.0101 -6.74   <0.001 35.9 -0.0881 -0.0484 #>  #> Columns: rowid, term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, mpg, hp  #>   # The full dataset is duplicated with each observation given counterfactual # values of 100 and 110 for the `hp` variable. The original `mtcars` includes # 32 rows, so the resulting dataset includes 64 rows. dg <- datagrid(newdata = mtcars, hp = c(100, 110), grid_type = \"counterfactual\") nrow(dg) #> [1] 64  # We get the same result by feeding a model instead of a data.frame mod <- lm(mpg ~ hp, mtcars) dg <- datagrid(model = mod, hp = c(100, 110), grid_type = \"counterfactual\") nrow(dg) #> [1] 64"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/deltamethod.html","id":null,"dir":"Reference","previous_headings":"","what":"deltamethod() is an alias to hypotheses() — deltamethod","title":"deltamethod() is an alias to hypotheses() — deltamethod","text":"alias kept backward compatibility.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/deltamethod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"deltamethod() is an alias to hypotheses() — deltamethod","text":"","code":"deltamethod(   model,   hypothesis = NULL,   vcov = NULL,   conf_level = 0.95,   df = Inf,   equivalence = NULL,   joint = FALSE,   joint_test = \"f\",   FUN = NULL,   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/expect_marginal_means.html","id":null,"dir":"Reference","previous_headings":"","what":"tinytest helper — expect_marginal_means","title":"tinytest helper — expect_marginal_means","text":"tinytest helper","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/expect_marginal_means.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"tinytest helper — expect_marginal_means","text":"","code":"expect_marginal_means(object, se = TRUE, n_row = NULL)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/expect_margins.html","id":null,"dir":"Reference","previous_headings":"","what":"tinytest helper — expect_margins","title":"tinytest helper — expect_margins","text":"tinytest helper","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/expect_margins.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"tinytest helper — expect_margins","text":"","code":"expect_margins(   results,   margins_object,   se = TRUE,   tolerance = 1e-05,   verbose = FALSE )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/expect_predictions.html","id":null,"dir":"Reference","previous_headings":"","what":"tinytest helper — expect_predictions","title":"tinytest helper — expect_predictions","text":"tinytest helper","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/expect_predictions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"tinytest helper — expect_predictions","text":"","code":"expect_predictions(object, se = TRUE, n_row = NULL, n_col = NULL)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/expect_slopes.html","id":null,"dir":"Reference","previous_headings":"","what":"tinytest helper — expect_slopes","title":"tinytest helper — expect_slopes","text":"tinytest helper","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/expect_slopes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"tinytest helper — expect_slopes","text":"","code":"expect_slopes(object, n_unique = NULL, pct_na = 5, se = TRUE, ...)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_averages.html","id":null,"dir":"Reference","previous_headings":"","what":"Average Estimates (aka ","title":"Average Estimates (aka ","text":"Calculate average estimates taking (group-wise) mean unit-level estimates computed predictions(), comparisons(), slopes() functions. Warning: generally faster safer use argument one three functions listed . Alternatively, one can call one step: avg_slopes(model) slopes(model, = TRUE) Proceeding two steps assigning unit-level estimates typically slower, estimates must computed twice. Note tidy() summary() methods slower wrappers around avg_*() functions.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_averages.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Average Estimates (aka ","text":"","code":"get_averages(x, by = TRUE, ...)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_averages.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Average Estimates (aka ","text":"x Object produced predictions(), comparisons(), slopes() functions. Character vector variable names compute group-wise average estimates. =NULL, global average (per term) reported. ... additional arguments passed original fitting function override original call options: conf_level, transform, etc. See ?predictions, ?comparisons, ?slopes.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_averages.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Average Estimates (aka ","text":"data.frame estimates uncertainty estimates","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_averages.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Average Estimates (aka ","text":"Standard errors estimated using delta method. See marginaleffects website details. Bayesian models (e.g., brms), estimates aggregated applying median (mean) function twice. First, apply marginal effects posterior draw, thereby estimating one Average (Median) Marginal Effect per iteration MCMC chain. Second, calculate mean quantile function results Step 1 obtain Average Marginal Effect associated interval.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_averages.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Average Estimates (aka ","text":"","code":"mod <- lm(mpg ~ factor(gear), data = mtcars) contr <- comparisons(mod, variables = list(gear = \"sequential\")) #> Warning: The `gear` variable is treated as a categorical (factor) variable, but #>   the original data is of class numeric. It is safer and faster to convert #>   such variables to factor before fitting the model and calling `slopes` #>   functions. #>    #>   This warning appears once per session. tidy(contr) #> # A tibble: 2 × 8 #>   term  contrast         estimate std.error statistic p.value conf.low conf.high #>   <chr> <chr>               <dbl>     <dbl>     <dbl>   <dbl>    <dbl>     <dbl> #> 1 gear  mean(4) - mean(…     8.43      1.82      4.62 3.81e-6     4.85     12.0  #> 2 gear  mean(5) - mean(…    -3.15      2.51     -1.26 2.08e-1    -8.07      1.76"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_coef.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a named vector of coefficients from a model object (internal function) — get_coef","title":"Get a named vector of coefficients from a model object (internal function) — get_coef","text":"Get named vector coefficients model object (internal function)","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_coef.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a named vector of coefficients from a model object (internal function) — get_coef","text":"","code":"get_coef(model, ...)  # S3 method for default get_coef(model, ...)  # S3 method for polr get_coef(model, ...)  # S3 method for afex_aov get_coef(model, ...)  # S3 method for betareg get_coef(model, ...)  # S3 method for multinom get_coef(model, ...)  # S3 method for brmultinom get_coef(model, ...)  # S3 method for bracl get_coef(model, ...)  # S3 method for brmsfit get_coef(model, ...)  # S3 method for gamlss get_coef(model, ...)  # S3 method for glmmTMB get_coef(model, ...)  # S3 method for merMod get_coef(model, ...)  # S3 method for lmerModLmerTest get_coef(model, ...)  # S3 method for lmerMod get_coef(model, ...)  # S3 method for mblogit get_coef(model, ...)  # S3 method for gam get_coef(model, ...)  # S3 method for mlm get_coef(model, ...)  # S3 method for selection get_coef(model, ...)  # S3 method for scam get_coef(model, ...)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_coef.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a named vector of coefficients from a model object (internal function) — get_coef","text":"model Model object ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_coef.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get a named vector of coefficients from a model object (internal function) — get_coef","text":"named vector coefficients. names must match variance matrix.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_group_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Get levels of the outcome variable in grouped or multivariate models — get_group_names","title":"Get levels of the outcome variable in grouped or multivariate models — get_group_names","text":"Get levels outcome variable grouped multivariate models","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_group_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get levels of the outcome variable in grouped or multivariate models — get_group_names","text":"","code":"get_group_names(model, ...)  # S3 method for default get_group_names(model, ...)  # S3 method for polr get_group_names(model, ...)  # S3 method for multinom get_group_names(model, ...)  # S3 method for bracl get_group_names(model, ...)  # S3 method for brmsfit get_group_names(model, ...)  # S3 method for mblogit get_group_names(model, type, ...)  # S3 method for mlm get_group_names(model, ...)  # S3 method for clm get_group_names(model, ...)  # S3 method for hurdle get_group_names(model, type = \"count\", ...)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_group_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get levels of the outcome variable in grouped or multivariate models — get_group_names","text":"model Model object ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments. type string indicates type (scale) predictions used compute contrasts slopes. can differ based model type, typically string : \"response\", \"link\", \"probs\", \"zero\". unsupported string entered, model-specific list acceptable values returned error message. type NULL, default value used. default first model-related row marginaleffects:::type_dictionary dataframe.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_group_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get levels of the outcome variable in grouped or multivariate models — get_group_names","text":"character vector","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_model_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a named model matrix — get_model_matrix","title":"Get a named model matrix — get_model_matrix","text":"Get named model matrix","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_model_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a named model matrix — get_model_matrix","text":"","code":"get_model_matrix(model, newdata)  # S3 method for default get_model_matrix(model, newdata)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_model_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a named model matrix — get_model_matrix","text":"model Model object newdata Grid predictor values evaluate slopes. NULL (default): Unit-level slopes observed value original dataset. See insight::get_data() data frame: Unit-level slopes row newdata data frame. datagrid() call specify custom grid regressors. example: newdata = datagrid(cyl = c(4, 6)): cyl variable equal 4 6 regressors fixed means modes. See Examples section datagrid() documentation. string: \"mean\": Marginal Effects Mean. Slopes predictor held mean mode. \"median\": Marginal Effects Median. Slopes predictor held median mode. \"marginalmeans\": Marginal Effects Marginal Means. See Details section . \"tukey\": Marginal Effects Tukey's 5 numbers. \"grid\": Marginal Effects grid representative numbers (Tukey's 5 numbers unique values categorical predictors).","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_predict.html","id":null,"dir":"Reference","previous_headings":"","what":"Get predicted values from a model object (internal function) — get_predict","title":"Get predicted values from a model object (internal function) — get_predict","text":"Get predicted values model object (internal function)","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_predict.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get predicted values from a model object (internal function) — get_predict","text":"","code":"get_predict(model, newdata, type, ...)  # S3 method for default get_predict(model, newdata = insight::get_data(model), type = \"response\", ...)  # S3 method for polr get_predict(model, newdata = insight::get_data(model), type = \"probs\", ...)  # S3 method for glmmPQL get_predict(model, newdata = insight::get_data(model), type = \"response\", ...)  # S3 method for MCMCglmm get_predict(model, newdata, type = \"response\", ndraws = 1000, ...)  # S3 method for afex_aov get_predict(model, newdata = NULL, ...)  # S3 method for glimML get_predict(model, newdata = insight::get_data(model), type = \"response\", ...)  # S3 method for betareg get_predict(model, newdata, ...)  # S3 method for bife get_predict(model, newdata = insight::get_data(model), type = \"response\", ...)  # S3 method for biglm get_predict(model, newdata = insight::get_data(model), type = \"response\", ...)  # S3 method for multinom get_predict(model, newdata = insight::get_data(model), type = \"probs\", ...)  # S3 method for brmultinom get_predict(model, newdata = insight::get_data(model), type = \"probs\", ...)  # S3 method for brmsfit get_predict(model, newdata = insight::get_data(model), type = \"response\", ...)  # S3 method for crch get_predict(model, newdata = NULL, type = \"location\", ...)  # S3 method for fixest get_predict(model, newdata = insight::get_data(model), type = \"response\", ...)  # S3 method for gamlss get_predict(model, newdata = insight::get_data(model), type = \"response\", ...)  # S3 method for glmmTMB get_predict(model, newdata = insight::get_data(model), type = \"response\", ...)  # S3 method for inferences_simulation get_predict(model, newdata, ...)  # S3 method for merMod get_predict(model, newdata = insight::get_data(model), type = \"response\", ...)  # S3 method for lmerModLmerTest get_predict(model, newdata = insight::get_data(model), type = \"response\", ...)  # S3 method for lmerMod get_predict(model, newdata = insight::get_data(model), type = \"response\", ...)  # S3 method for mblogit get_predict(model, newdata = insight::get_data(model), type = \"response\", ...)  # S3 method for mhurdle get_predict(model, newdata = insight::get_data(model), type = \"response\", ...)  # S3 method for mlogit get_predict(model, newdata, ...)  # S3 method for clm get_predict(model, newdata = insight::get_data(model), type = \"prob\", ...)  # S3 method for rq get_predict(model, newdata = insight::get_data(model), type = NULL, ...)  # S3 method for rms get_predict(model, newdata = insight::get_data(model), type = NULL, ...)  # S3 method for orm get_predict(model, newdata = insight::get_data(model), type = NULL, ...)  # S3 method for lrm get_predict(model, newdata = insight::get_data(model), type = NULL, ...)  # S3 method for ols get_predict(model, newdata = insight::get_data(model), type = NULL, ...)  # S3 method for rlmerMod get_predict(model, newdata = insight::get_data(model), type = \"response\", ...)  # S3 method for stanreg get_predict(model, newdata = insight::get_data(model), type = \"response\", ...)  # S3 method for lm get_predict(model, newdata = insight::get_data(model), type = \"response\", ...)  # S3 method for glm get_predict(model, newdata = insight::get_data(model), type = \"response\", ...)  # S3 method for coxph get_predict(model, newdata = insight::get_data(model), type = \"lp\", ...)  # S3 method for tobit1 get_predict(model, newdata = insight::get_data(model), type = \"response\", ...)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_predict.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get predicted values from a model object (internal function) — get_predict","text":"model Model object newdata Grid predictor values evaluate slopes. NULL (default): Unit-level slopes observed value original dataset. See insight::get_data() data frame: Unit-level slopes row newdata data frame. datagrid() call specify custom grid regressors. example: newdata = datagrid(cyl = c(4, 6)): cyl variable equal 4 6 regressors fixed means modes. See Examples section datagrid() documentation. string: \"mean\": Marginal Effects Mean. Slopes predictor held mean mode. \"median\": Marginal Effects Median. Slopes predictor held median mode. \"marginalmeans\": Marginal Effects Marginal Means. See Details section . \"tukey\": Marginal Effects Tukey's 5 numbers. \"grid\": Marginal Effects grid representative numbers (Tukey's 5 numbers unique values categorical predictors). type string indicates type (scale) predictions used compute contrasts slopes. can differ based model type, typically string : \"response\", \"link\", \"probs\", \"zero\". unsupported string entered, model-specific list acceptable values returned error message. type NULL, default value used. default first model-related row marginaleffects:::type_dictionary dataframe. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_predict.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get predicted values from a model object (internal function) — get_predict","text":"data.frame predicted values number rows equal number rows newdata columns \"rowid\" \"estimate\". \"group\" column added multivariate models models categorical outcomes.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_varcov_args.html","id":null,"dir":"Reference","previous_headings":"","what":"Take a summary() style vcov argument and convert it to\ninsight::get_varcov() — get_varcov_args","title":"Take a summary() style vcov argument and convert it to\ninsight::get_varcov() — get_varcov_args","text":"Take summary() style vcov argument convert insight::get_varcov()","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_varcov_args.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Take a summary() style vcov argument and convert it to\ninsight::get_varcov() — get_varcov_args","text":"","code":"get_varcov_args(model, vcov)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_vcov.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a named variance-covariance matrix from a model object (internal function) — get_vcov","title":"Get a named variance-covariance matrix from a model object (internal function) — get_vcov","text":"Get named variance-covariance matrix model object (internal function)","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_vcov.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a named variance-covariance matrix from a model object (internal function) — get_vcov","text":"","code":"get_vcov(model, ...)  # S3 method for default get_vcov(model, vcov = NULL, ...)  # S3 method for MCMCglmm get_vcov(model, vcov = NULL, ...)  # S3 method for afex_aov get_vcov(model, vcov = NULL, ...)  # S3 method for glimML get_vcov(model, vcov = NULL, ...)  # S3 method for biglm get_vcov(model, vcov = NULL, ...)  # S3 method for brmsfit get_vcov(model, vcov = NULL, ...)  # S3 method for gamlss get_vcov(model, ...)  # S3 method for inferences_simulation get_vcov(model, ...)  # S3 method for mhurdle get_vcov(model, vcov = NULL, ...)  # S3 method for orm get_vcov(model, vcov = NULL, ...)  # S3 method for scam get_vcov(model, vcov = NULL, ...)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_vcov.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a named variance-covariance matrix from a model object (internal function) — get_vcov","text":"model Model object ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments. vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model))","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/get_vcov.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get a named variance-covariance matrix from a model object (internal function) — get_vcov","text":"named square matrix variance covariances. names must match coefficient names.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/hypotheses.html","id":null,"dir":"Reference","previous_headings":"","what":"(Non-)Linear Tests for Null Hypotheses, Joint Hypotheses, Equivalence, Non Superiority, and Non Inferiority — hypotheses","title":"(Non-)Linear Tests for Null Hypotheses, Joint Hypotheses, Equivalence, Non Superiority, and Non Inferiority — hypotheses","text":"Uncertainty estimates calculated first-order approximate standard errors linear non-linear functions vector random variables known estimated covariance matrix. sense, hypotheses emulates behavior excellent well-established car::deltaMethod car::linearHypothesis functions, supports models; requires fewer dependencies; expands range tests equivalence superiority/inferiority; offers convenience features like robust standard errors. learn , read hypothesis tests vignette, visit package website, scroll page full list vignettes: https://vincentarelbundock.github.io/marginaleffects/articles/hypothesis.html https://vincentarelbundock.github.io/marginaleffects/ Warning #1: Tests conducted directly scale defined type argument. models, can make sense conduct hypothesis equivalence tests \"link\" scale instead \"response\" scale often default. Warning #2: hypothesis tests objects produced marginaleffects package, safer use hypothesis argument original function.  Using hypotheses() may work certain environments, lists, working programmatically *apply style functions.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/hypotheses.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"(Non-)Linear Tests for Null Hypotheses, Joint Hypotheses, Equivalence, Non Superiority, and Non Inferiority — hypotheses","text":"","code":"hypotheses(   model,   hypothesis = NULL,   vcov = NULL,   conf_level = 0.95,   df = Inf,   equivalence = NULL,   joint = FALSE,   joint_test = \"f\",   FUN = NULL,   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/hypotheses.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"(Non-)Linear Tests for Null Hypotheses, Joint Hypotheses, Equivalence, Non Superiority, and Non Inferiority — hypotheses","text":"model Model object object generated comparisons(), slopes(), predictions(), marginal_means() functions. hypothesis specify hypothesis test custom contrast using numeric value, vector, matrix, string, string formula. Numeric: Single value: null hypothesis used computation Z p (applying transform). Vector: Weights compute linear combination (custom contrast ) estimates. Length equal number rows generated function call, without hypothesis argument. Matrix: column vector weights, describe , used compute distinct linear combination (contrast ) estimates. column names matrix used labels output. String formula specify linear non-linear hypothesis tests. term column uniquely identifies rows, terms can used formula. Otherwise, use b1, b2, etc. identify position parameter. Examples: hp = drat hp + drat = 12 b1 + b2 + b3 = 0 String: \"pairwise\": pairwise differences estimates row. \"reference\": differences estimates row estimate first row. \"sequential\": difference estimate estimate next row. \"revpairwise\", \"revreference\", \"revsequential\": inverse corresponding hypotheses, described . See Examples section vignette: https://vincentarelbundock.github.io/marginaleffects/articles/hypothesis.html vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model)) conf_level numeric value 0 1. Confidence level use build confidence interval. df Degrees freedom used compute p values confidence intervals. single numeric value 1 Inf. df Inf, normal distribution used. df finite, t distribution used. See insight::get_df convenient function extract degrees freedom. Ex: slopes(model, df = insight::get_df(model)) equivalence Numeric vector length 2: bounds used two-one-sided test (TOST) equivalence, non-inferiority non-superiority tests. See Details section . joint Joint test statistical significance. null hypothesis value can set using hypothesis argument. FALSE: Hypotheses tested jointly. TRUE: parameters tested jointly. String: regular expression match parameters tested jointly. grep(joint, perl = TRUE) Character vector parameter names tested. Characters refer names vector returned coef(object). Integer vector indices. parameters positions test jointly. joint_test character string specifying type test, either \"f\" \"chisq\". null hypothesis set hypothesis argument, default null equal 0 parameters. FUN NULL function. NULL (default): hypothesis test model's coefficients, quantities estimated one marginaleffects package functions. Function accepts model object returns numeric vector data.frame two columns called term estimate. argument can useful users want conduct hypothesis test arbitrary function quantities held model object. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/hypotheses.html","id":"joint-hypothesis-tests","dir":"Reference","previous_headings":"","what":"Joint hypothesis tests","title":"(Non-)Linear Tests for Null Hypotheses, Joint Hypotheses, Equivalence, Non Superiority, and Non Inferiority — hypotheses","text":"test statistic joint Wald test calculated (R * theta_hat - r)' * inv(R * V_hat * R') * (R * theta_hat - r) / Q, theta_hat vector estimated parameters, V_hat estimated covariance matrix, R Q x P matrix testing Q hypotheses P parameters, r Q x 1 vector null hypothesis, Q number rows R. test Chi-squared test, test statistic normalized. p-value calculated based either F-distribution (F-test) Chi-squared distribution (Chi-squared test). F-test, degrees freedom Q (n - P), n sample size P number parameters. Chi-squared test, degrees freedom Q.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/hypotheses.html","id":"equivalence-inferiority-superiority","dir":"Reference","previous_headings":"","what":"Equivalence, Inferiority, Superiority","title":"(Non-)Linear Tests for Null Hypotheses, Joint Hypotheses, Equivalence, Non Superiority, and Non Inferiority — hypotheses","text":"\\(\\theta\\) estimate, \\(\\sigma_\\theta\\) estimated standard error, \\([, b]\\) bounds interval supplied equivalence argument. Non-inferiority: \\(H_0\\): \\(\\theta \\leq \\) \\(H_1\\): \\(\\theta > \\) \\(t=(\\theta - )/\\sigma_\\theta\\) p: Upper-tail probability Non-superiority: \\(H_0\\): \\(\\theta \\geq b\\) \\(H_1\\): \\(\\theta < b\\) \\(t=(\\theta - b)/\\sigma_\\theta\\) p: Lower-tail probability Equivalence: Two One-Sided Tests (TOST) p: Maximum non-inferiority non-superiority p values. Thanks Russell V. Lenth excellent emmeans package documentation inspired feature.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/hypotheses.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"(Non-)Linear Tests for Null Hypotheses, Joint Hypotheses, Equivalence, Non Superiority, and Non Inferiority — hypotheses","text":"","code":"library(marginaleffects) mod <- lm(mpg ~ hp + wt + factor(cyl), data = mtcars)  # When `FUN` and `hypotheses` are `NULL`, `hypotheses()` returns a data.frame of parameters hypotheses(mod) #>  #>  Term Estimate Std. Error     z Pr(>|z|)   2.5 %    97.5 %     S #>    b1  35.8460      2.041 17.56   <0.001 31.8457 39.846319 227.0 #>    b2  -0.0231      0.012 -1.93   0.0531 -0.0465  0.000306   4.2 #>    b3  -3.1814      0.720 -4.42   <0.001 -4.5918 -1.771012  16.6 #>    b4  -3.3590      1.402 -2.40   0.0166 -6.1062 -0.611803   5.9 #>    b5  -3.1859      2.170 -1.47   0.1422 -7.4399  1.068169   2.8 #>  #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high, s.value  #>   # Test of equality between coefficients hypotheses(mod, hypothesis = \"hp = wt\") #>  #>     Term Estimate Std. Error    z Pr(>|z|) 2.5 % 97.5 %    S #>  hp = wt     3.16       0.72 4.39   <0.001  1.75   4.57 16.4 #>  #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high, s.value  #>   # Non-linear function hypotheses(mod, hypothesis = \"exp(hp + wt) = 0.1\") #>  #>                Term Estimate Std. Error     z Pr(>|z|)  2.5 %  97.5 %   S #>  exp(hp + wt) = 0.1  -0.0594     0.0292 -2.04   0.0418 -0.117 -0.0022 4.6 #>  #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high, s.value  #>   # Robust standard errors hypotheses(mod, hypothesis = \"hp = wt\", vcov = \"HC3\") #>  #>     Term Estimate Std. Error    z Pr(>|z|) 2.5 % 97.5 %    S #>  hp = wt     3.16      0.805 3.92   <0.001  1.58   4.74 13.5 #>  #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high, s.value  #>   # b1, b2, ... shortcuts can be used to identify the position of the # parameters of interest in the output of FUN hypotheses(mod, hypothesis = \"b2 = b3\") #>  #>     Term Estimate Std. Error    z Pr(>|z|) 2.5 % 97.5 %    S #>  b2 = b3     3.16       0.72 4.39   <0.001  1.75   4.57 16.4 #>  #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high, s.value  #>   # term names with special characters have to be enclosed in backticks hypotheses(mod, hypothesis = \"`factor(cyl)6` = `factor(cyl)8`\") #>  #>                             Term Estimate Std. Error      z Pr(>|z|) 2.5 % #>  `factor(cyl)6` = `factor(cyl)8`   -0.173       1.65 -0.105    0.917 -3.41 #>  97.5 %   S #>    3.07 0.1 #>  #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high, s.value  #>   mod2 <- lm(mpg ~ hp * drat, data = mtcars) hypotheses(mod2, hypothesis = \"`hp:drat` = drat\") #>  #>              Term Estimate Std. Error    z Pr(>|z|) 2.5 % 97.5 %   S #>  `hp:drat` = drat    -6.08       2.89 -2.1   0.0357 -11.8 -0.405 4.8 #>  #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high, s.value  #>   # predictions(), comparisons(), and slopes() mod <- glm(am ~ hp + mpg, data = mtcars, family = binomial) cmp <- comparisons(mod, newdata = \"mean\") hypotheses(cmp, hypothesis = \"b1 = b2\") #>  #>   Term Estimate Std. Error     z Pr(>|z|)   S  2.5 %  97.5 % #>  b1=b2   -0.288      0.125 -2.31   0.0209 5.6 -0.532 -0.0435 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  #>   mfx <- slopes(mod, newdata = \"mean\") hypotheses(cmp, hypothesis = \"b2 = 0.2\") #>  #>    Term Estimate Std. Error     z Pr(>|z|)   S  2.5 % 97.5 % #>  b2=0.2    0.101      0.131 0.774    0.439 1.2 -0.155  0.358 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  #>   pre <- predictions(mod, newdata = datagrid(hp = 110, mpg = c(30, 35))) hypotheses(pre, hypothesis = \"b1 = b2\") #>  #>   Term  Estimate Std. Error      z Pr(>|z|)   S     2.5 %   97.5 % #>  b1=b2 -3.57e-05   0.000172 -0.207    0.836 0.3 -0.000373 0.000302 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  #>   # The `FUN` argument can be used to compute standard errors for fitted values mod <- glm(am ~ hp + mpg, data = mtcars, family = binomial)  f <- function(x) predict(x, type = \"link\", newdata = mtcars) p <- hypotheses(mod, FUN = f) head(p) #>  #>  Term Estimate Std. Error      z Pr(>|z|) 2.5 % 97.5 %   S #>    b1   -1.098      0.716 -1.534    0.125 -2.50  0.305 3.0 #>    b2   -1.098      0.716 -1.534    0.125 -2.50  0.305 3.0 #>    b3    0.233      0.781  0.299    0.765 -1.30  1.764 0.4 #>    b4   -0.595      0.647 -0.919    0.358 -1.86  0.674 1.5 #>    b5   -0.418      0.647 -0.645    0.519 -1.69  0.851 0.9 #>    b6   -5.026      2.195 -2.290    0.022 -9.33 -0.725 5.5 #>  #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high, s.value  #>   f <- function(x) predict(x, type = \"response\", newdata = mtcars) p <- hypotheses(mod, FUN = f) head(p) #>  #>  Term Estimate Std. Error     z Pr(>|z|)   2.5 % 97.5 %   S #>    b1  0.25005     0.1342 1.863  0.06243 -0.0130 0.5131 4.0 #>    b2  0.25005     0.1342 1.863  0.06243 -0.0130 0.5131 4.0 #>    b3  0.55803     0.1926 2.898  0.00376  0.1806 0.9355 8.1 #>    b4  0.35560     0.1483 2.399  0.01646  0.0650 0.6462 5.9 #>    b5  0.39710     0.1550 2.561  0.01043  0.0932 0.7010 6.6 #>    b6  0.00652     0.0142 0.459  0.64635 -0.0213 0.0344 0.6 #>  #> Columns: term, estimate, std.error, statistic, p.value, conf.low, conf.high, s.value  #>   # Equivalence, non-inferiority, and non-superiority tests mod <- lm(mpg ~ hp + factor(gear), data = mtcars) p <- predictions(mod, newdata = \"median\") hypotheses(p, equivalence = c(17, 18)) #>  #>  Estimate Std. Error    z Pr(>|z|)     S 2.5 % 97.5 %  hp gear p (NonInf) #>      19.7          1 19.6   <0.001 281.3  17.7   21.6 123    3    0.00404 #>  p (NonSup) p (Equiv) #>       0.951     0.951 #>  #> Columns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, mpg, hp, gear, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv  #>   mfx <- avg_slopes(mod, variables = \"hp\") hypotheses(mfx, equivalence = c(-.1, .1)) #>  #>  Term Estimate Std. Error     z Pr(>|z|)    S   2.5 %  97.5 % p (NonInf) #>    hp  -0.0669      0.011 -6.05   <0.001 29.4 -0.0885 -0.0452    0.00135 #>  p (NonSup) p (Equiv) #>      <0.001   0.00135 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv  #>   cmp <- avg_comparisons(mod, variables = \"gear\", hypothesis = \"pairwise\") hypotheses(cmp, equivalence = c(0, 10)) #>  #>               Term Estimate Std. Error     z Pr(>|z|)   S 2.5 % 97.5 % #>  (4 - 3) - (5 - 3)    -3.94       2.05 -1.92   0.0543 4.2 -7.95 0.0727 #>  p (NonInf) p (NonSup) p (Equiv) #>       0.973     <0.001     0.973 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, statistic.noninf, statistic.nonsup, p.value.noninf, p.value.nonsup, p.value.equiv  #>   # joint hypotheses: character vector model <- lm(mpg ~ as.factor(cyl) * hp, data = mtcars) hypotheses(model, joint = c(\"as.factor(cyl)6:hp\", \"as.factor(cyl)8:hp\")) #>  #>  #> Joint hypothesis test: #> as.factor(cyl)6:hp = 0 #> as.factor(cyl)8:hp = 0 #>   #>     F Pr(>|F|) Df 1 Df 2 #>  2.11    0.142    2   26 #>  #> Columns: statistic, p.value, df1, df2  #>   # joint hypotheses: regular expression hypotheses(model, joint = \"cyl\") #>  #>  #> Joint hypothesis test: #>  as.factor(cyl)6 = 0 #>  as.factor(cyl)8 = 0 #>  as.factor(cyl)6:hp = 0 #>  as.factor(cyl)8:hp = 0 #>   #>    F Pr(>|F|) Df 1 Df 2 #>  5.7  0.00197    4   26 #>  #> Columns: statistic, p.value, df1, df2  #>   # joint hypotheses: integer indices hypotheses(model, joint = 2:3) #>  #>  #> Joint hypothesis test: #>  as.factor(cyl)6 = 0 #>  as.factor(cyl)8 = 0 #>   #>     F Pr(>|F|) Df 1 Df 2 #>  6.12  0.00665    2   26 #>  #> Columns: statistic, p.value, df1, df2  #>   # joint hypotheses: different null hypotheses hypotheses(model, joint = 2:3, hypothesis = 1) #>  #>  #> Joint hypothesis test: #>  as.factor(cyl)6 = 1 #>  as.factor(cyl)8 = 1 #>   #>     F Pr(>|F|) Df 1 Df 2 #>  6.84  0.00411    2   26 #>  #> Columns: statistic, p.value, df1, df2  #>  hypotheses(model, joint = 2:3, hypothesis = 1:2) #>  #>  #> Joint hypothesis test: #>  as.factor(cyl)6 = 1 #>  as.factor(cyl)8 = 2 #>   #>     F Pr(>|F|) Df 1 Df 2 #>  7.47  0.00273    2   26 #>  #> Columns: statistic, p.value, df1, df2  #>   # joint hypotheses: marginaleffects object cmp <- avg_comparisons(model) hypotheses(cmp, joint = \"cyl\") #>  #>  #> Joint hypothesis test: #>  cyl 6 - 4 = 0 #>  cyl 8 - 4 = 0 #>   #>    F Pr(>|F|) Df 1 Df 2 #>  1.6    0.219    2   29 #>  #> Columns: statistic, p.value, df1, df2  #>"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/inferences.html","id":null,"dir":"Reference","previous_headings":"","what":"(EXPERIMENTAL) Bootstrap and Simulation-Based Inference — inferences","title":"(EXPERIMENTAL) Bootstrap and Simulation-Based Inference — inferences","text":"Warning: function experimental. may renamed, user interface may change, functionality may migrate arguments marginaleffects functions. Apply function marginaleffects object change inferential method used compute uncertainty estimates.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/inferences.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"(EXPERIMENTAL) Bootstrap and Simulation-Based Inference — inferences","text":"","code":"inferences(x, method, R = 1000, conf_type = \"perc\", ...)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/inferences.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"(EXPERIMENTAL) Bootstrap and Simulation-Based Inference — inferences","text":"x Object produced one core marginaleffects functions. method String \"delta\": delta method standard errors \"boot\" package \"fwb\": fractional weighted bootstrap \"rsample\" package \"simulation\" multivariate normal distribution (Krinsky & Robb, 1986) \"mi\" multiple imputation missing data R Number resamples simulations. conf_type String: type bootstrap interval construct. boot: \"perc\", \"norm\", \"basic\", \"bca\" fwb: \"perc\", \"norm\", \"basic\", \"bc\", \"bca\" rsample: \"perc\" \"bca\" simulation: argument ignored. ... method=\"boot\", additional arguments passed boot::boot(). method=\"fwb\", additional arguments passed fwb::fwb(). method=\"rsample\", additional arguments passed rsample::bootstraps(). method=\"simulation\", additional arguments ignored.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/inferences.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"(EXPERIMENTAL) Bootstrap and Simulation-Based Inference — inferences","text":"marginaleffects object simulation bootstrap resamples objects attached.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/inferences.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"(EXPERIMENTAL) Bootstrap and Simulation-Based Inference — inferences","text":"method=\"simulation\", conduct simulation-based inference following method discussed Krinsky & Robb (1986): Draw R sets simulated coefficients multivariate normal distribution mean equal original model's estimated coefficients variance equal model's variance-covariance matrix (classical, \"HC3\", ). Use R sets coefficients compute R sets estimands: predictions, comparisons, slopes. Take quantiles resulting distribution estimands obtain confidence interval standard deviation simulated estimates estimate standard error. method=\"fwb\", drawn weights supplied model fitting function's weights argument; model accept non-integer weights, method used. weights included original model fit, extracted weights() multiplied drawn weights. weights supplied wts argument estimation function (e.g., comparisons()).","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/inferences.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"(EXPERIMENTAL) Bootstrap and Simulation-Based Inference — inferences","text":"Krinsky, ., . L. Robb. 1986. “Approximating Statistical Properties Elasticities.” Review Economics Statistics 68 (4): 715–9. King, Gary, Michael Tomz, Jason Wittenberg. \"Making statistical analyses: Improving interpretation presentation.\" American journal political science (2000): 347-361 Dowd, Bryan E., William H. Greene, Edward C. Norton. \"Computation standard errors.\" Health services research 49.2 (2014): 731-750.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/inferences.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"(EXPERIMENTAL) Bootstrap and Simulation-Based Inference — inferences","text":"","code":"if (FALSE) { library(marginaleffects) library(magrittr) set.seed(1024) mod <- lm(Sepal.Length ~ Sepal.Width * Species, data = iris)  # bootstrap avg_predictions(mod, by = \"Species\") %>%   inferences(method = \"boot\")  avg_predictions(mod, by = \"Species\") %>%   inferences(method = \"rsample\")  # Fractional (bayesian) bootstrap avg_slopes(mod, by = \"Species\") %>%   inferences(method = \"fwb\") %>%   posterior_draws(\"rvar\") %>%   data.frame()  # Simulation-based inference slopes(mod) %>%   inferences(method = \"simulation\") %>%   head() }"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginal_means.html","id":null,"dir":"Reference","previous_headings":"","what":"Marginal Means — marginal_means","title":"Marginal Means — marginal_means","text":"Marginal means adjusted predictions, averaged across grid categorical predictors, holding numeric predictors means. learn , read marginal means vignette, visit package website, scroll page full list vignettes: https://vincentarelbundock.github.io/marginaleffects/articles/marginalmeans.html https://vincentarelbundock.github.io/marginaleffects/","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginal_means.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Marginal Means — marginal_means","text":"","code":"marginal_means(   model,   variables = NULL,   newdata = NULL,   vcov = TRUE,   conf_level = 0.95,   type = NULL,   transform = NULL,   cross = FALSE,   hypothesis = NULL,   equivalence = NULL,   p_adjust = NULL,   df = Inf,   wts = \"equal\",   by = NULL,   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginal_means.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Marginal Means — marginal_means","text":"model Model object variables Focal variables Character vector variable names: compute marginal means category listed variables. NULL: calculate marginal means logical, character, factor variables dataset used fit model. Hint:  Set cross=TRUE compute marginal means combinations focal variables. newdata Grid predictor values marginalize. NULL create grid combinations categorical predictors model. Warning: can expensive. Character vector: subset categorical variables use building balanced grid predictors. variables held mean mode. Data frame: data frame includes predictors original model. full dataset replicated every combination focal variables variables argument, using datagridcf() function. vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model)) conf_level numeric value 0 1. Confidence level use build confidence interval. type string indicates type (scale) predictions used compute marginal effects contrasts. can differ based model type, typically string : \"response\", \"link\", \"probs\", \"zero\". unsupported string entered, model-specific list acceptable values returned error message. type NULL, default value used. default first model-related row marginaleffects:::type_dictionary dataframe. type NULL default value \"response\", function tries compute marginal means link scale backtransforming using inverse link function. transform function applied unit-level adjusted predictions confidence intervals just function returns results. bayesian models, function applied individual draws posterior distribution, computing summaries. cross TRUE FALSE FALSE (default): Marginal means computed predictor individually. TRUE: Marginal means computed combination predictors specified variables argument. hypothesis specify hypothesis test custom contrast using numeric value, vector, matrix, string, string formula. Numeric: Single value: null hypothesis used computation Z p (applying transform). Vector: Weights compute linear combination (custom contrast ) estimates. Length equal number rows generated function call, without hypothesis argument. Matrix: column vector weights, describe , used compute distinct linear combination (contrast ) estimates. column names matrix used labels output. String formula specify linear non-linear hypothesis tests. term column uniquely identifies rows, terms can used formula. Otherwise, use b1, b2, etc. identify position parameter. Examples: hp = drat hp + drat = 12 b1 + b2 + b3 = 0 String: \"pairwise\": pairwise differences estimates row. \"reference\": differences estimates row estimate first row. \"sequential\": difference estimate estimate next row. \"revpairwise\", \"revreference\", \"revsequential\": inverse corresponding hypotheses, described . See Examples section vignette: https://vincentarelbundock.github.io/marginaleffects/articles/hypothesis.html equivalence Numeric vector length 2: bounds used two-one-sided test (TOST) equivalence, non-inferiority non-superiority tests. See Details section . p_adjust Adjust p-values multiple comparisons: \"holm\", \"hochberg\", \"hommel\", \"bonferroni\", \"BH\", \"\", \"fdr\". See stats::p.adjust df Degrees freedom used compute p values confidence intervals. single numeric value 1 Inf. df Inf, normal distribution used. df finite, t distribution used. See insight::get_df convenient function extract degrees freedom. Ex: slopes(model, df = insight::get_df(model)) wts character value. Weights use averaging. \"equal\": combination variables newdata gets equal weight. \"cells\": combination values variables newdata gets weight proportional frequency original data. \"proportional\": combination values variables newdata -- except variables argument -- gets weight proportional frequency original data. Collapse marginal means categories. Data frame column group labels, merging columns shared newdata data frame produced calling function without argument. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginal_means.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Marginal Means — marginal_means","text":"Data frame marginal means one row per variable-value combination.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginal_means.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Marginal Means — marginal_means","text":"function begins calling predictions function obtain grid predictors, adjusted predictions cell. grid includes combinations categorical variables listed variables newdata arguments, combinations categorical variables used fit model newdata NULL. prediction grid, numeric variables held means. constructing grid filling grid adjusted predictions, marginal_means computes marginal means variables listed variables argument, average across categories grid. marginal_means can compute standard errors linear models, predictions link scale, , type argument set \"link\". marginaleffects website compares output function popular emmeans package, provides similar advanced functionality: https://vincentarelbundock.github.io/marginaleffects/","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginal_means.html","id":"standard-errors-using-the-delta-method","dir":"Reference","previous_headings":"","what":"Standard errors using the delta method","title":"Marginal Means — marginal_means","text":"Standard errors quantities estimated marginaleffects can obtained via delta method. requires differentiating function respect coefficients model using finite difference approach. models, delta method standard errors can sensitive various aspects numeric differentiation strategy, including step size. default, step size set 1e-8, 1e-4 times smallest absolute model coefficient, whichever largest. marginaleffects can delegate numeric differentiation numDeriv package, allows flexibility. , users can pass arguments numDeriv::jacobian function global option. example: options(marginaleffects_numDeriv = list(method = \"simple\", method.args = list(eps = 1e-6))) options(marginaleffects_numDeriv = list(method = \"Richardson\", method.args = list(eps = 1e-5))) options(marginaleffects_numDeriv = NULL) See \"Standard Errors Confidence Intervals\" vignette marginaleffects website details computation standard errors: https://vincentarelbundock.github.io/marginaleffects/articles/uncertainty.html Note inferences() function can used compute uncertainty estimates using bootstrap simulation-based inference. See vignette: https://vincentarelbundock.github.io/marginaleffects/articles/bootstrap.html","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginal_means.html","id":"model-specific-arguments","dir":"Reference","previous_headings":"","what":"Model-Specific Arguments","title":"Marginal Means — marginal_means","text":"model types allow model-specific arguments modify nature marginal effects, predictions, marginal means, contrasts. Please report package-specific predict() arguments Github can add table . https://github.com/vincentarelbundock/marginaleffects/issues","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginal_means.html","id":"bayesian-posterior-summaries","dir":"Reference","previous_headings":"","what":"Bayesian posterior summaries","title":"Marginal Means — marginal_means","text":"default, credible intervals bayesian models built equal-tailed intervals. can changed highest density interval setting global option: options(\"marginaleffects_posterior_interval\" = \"eti\") options(\"marginaleffects_posterior_interval\" = \"hdi\") default, center posterior distribution bayesian models identified median. Users can use different summary function setting global option: options(\"marginaleffects_posterior_center\" = \"mean\") options(\"marginaleffects_posterior_center\" = \"median\") estimates averaged using argument, tidy() function, summary() function, posterior distribution marginalized twice . First, take average across units within iteration MCMC chain, according user requested argument tidy()/summary() functions. , identify center resulting posterior using function supplied \"marginaleffects_posterior_center\" option (median default).","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginal_means.html","id":"equivalence-inferiority-superiority","dir":"Reference","previous_headings":"","what":"Equivalence, Inferiority, Superiority","title":"Marginal Means — marginal_means","text":"\\(\\theta\\) estimate, \\(\\sigma_\\theta\\) estimated standard error, \\([, b]\\) bounds interval supplied equivalence argument. Non-inferiority: \\(H_0\\): \\(\\theta \\leq \\) \\(H_1\\): \\(\\theta > \\) \\(t=(\\theta - )/\\sigma_\\theta\\) p: Upper-tail probability Non-superiority: \\(H_0\\): \\(\\theta \\geq b\\) \\(H_1\\): \\(\\theta < b\\) \\(t=(\\theta - b)/\\sigma_\\theta\\) p: Lower-tail probability Equivalence: Two One-Sided Tests (TOST) p: Maximum non-inferiority non-superiority p values. Thanks Russell V. Lenth excellent emmeans package documentation inspired feature.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginal_means.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Marginal Means — marginal_means","text":"Greenland S. 2019. \"Valid P-Values Behave Exactly : Misleading Criticisms P-Values Resolution S-Values.\" American Statistician. 73(S1): 106–114. Cole, Stephen R, Jessie K Edwards, Sander Greenland. 2020. \"Surprise!\" American Journal Epidemiology 190 (2): 191–93. https://doi.org/10.1093/aje/kwaa136.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginal_means.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Marginal Means — marginal_means","text":"","code":"library(marginaleffects)  # simple marginal means for each level of `cyl` dat <- mtcars dat$carb <- factor(dat$carb) dat$cyl <- factor(dat$cyl) dat$am <- as.logical(dat$am) mod <- lm(mpg ~ carb + cyl + am, dat)  marginal_means(   mod,   variables = \"cyl\") #>  #>  Term Value Mean Std. Error    z Pr(>|z|)     S 2.5 % 97.5 % #>   cyl     6 20.4       1.34 15.2   <0.001 171.9  17.8   23.0 #>   cyl     4 23.1       1.66 13.9   <0.001 144.3  19.9   26.4 #>   cyl     8 16.2       1.07 15.1   <0.001 169.0  14.1   18.3 #>  #> Results averaged over levels of: carb, am, cyl  #> Columns: term, value, cyl, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  #>   # collapse levels of cyl by averaging by <- data.frame(   cyl = c(4, 6, 8),   by = c(\"4 & 6\", \"4 & 6\", \"8\")) marginal_means(mod,   variables = \"cyl\",   by = by) #>  #>     By Mean Std. Error    z Pr(>|z|)     S 2.5 % 97.5 % #>  4 & 6 21.7       1.13 19.2   <0.001 270.8  19.5   24.0 #>  8     16.2       1.07 15.1   <0.001 169.0  14.1   18.3 #>  #> Results averaged over levels of: carb, am, cyl  #> Columns: by, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  #>   # pairwise differences between collapsed levels marginal_means(mod,   variables = \"cyl\",   by = by,   hypothesis = \"pairwise\") #>  #>       Term Mean Std. Error    z Pr(>|z|)    S 2.5 % 97.5 % #>  4 & 6 - 8 5.54       1.51 3.66   <0.001 12.0  2.57    8.5 #>  #> Results averaged over levels of: carb, am, cyl  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  #>   # cross marginal_means(mod,   variables = c(\"cyl\", \"carb\"),   cross = TRUE) #>  #>  Mean Std. Error     z Pr(>|z|)     S 2.5 % 97.5 % #>  19.1       1.34 14.31   <0.001 151.8 16.53   21.8 #>  23.1       1.77 13.08   <0.001 127.4 19.63   26.5 #>  22.9       1.87 12.24   <0.001 112.0 19.20   26.5 #>  22.6       2.37  9.56   <0.001  69.5 17.98   27.2 #>  17.6       3.00  5.85   <0.001  27.6 11.68   23.5 #>  17.0       3.48  4.89   <0.001  19.9 10.21   23.9 #>  21.9       1.90 11.51   <0.001  99.4 18.15   25.6 #>  25.8       1.26 20.43   <0.001 305.7 23.34   28.3 #>  25.6       1.17 21.93   <0.001 351.8 23.30   27.9 #>  25.3       2.37 10.71   <0.001  86.6 20.70   30.0 #>  20.3       3.77  5.39   <0.001  23.7 12.91   27.7 #>  19.8       3.81  5.18   <0.001  22.1 12.29   27.2 #>  15.0       1.20 12.53   <0.001 117.2 12.63   17.3 #>  18.9       1.94  9.74   <0.001  72.1 15.11   22.7 #>  18.7       1.57 11.90   <0.001 106.0 15.61   21.8 #>  18.4       1.83 10.07   <0.001  76.8 14.85   22.0 #>  13.4       3.36  3.99   <0.001  13.9  6.81   20.0 #>  12.9       3.00  4.28   <0.001  15.7  6.98   18.8 #>  #> Results averaged over levels of: am  #> Columns: cyl, carb, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  #>   # collapsed cross by <- expand.grid(   cyl = unique(mtcars$cyl),   carb = unique(mtcars$carb)) by$by <- ifelse(   by$cyl == 4,   paste(\"Control:\", by$carb),   paste(\"Treatment:\", by$carb))   # Convert numeric variables to categorical before fitting the model dat <- mtcars dat$am <- as.logical(dat$am) dat$carb <- as.factor(dat$carb) mod <- lm(mpg ~ hp + am + carb, data = dat)  # Compute and summarize marginal means marginal_means(mod) #>  #>  Term Value Mean Std. Error     z Pr(>|z|)     S 2.5 % 97.5 % #>  am   TRUE  23.1      0.974 23.72   <0.001 410.9  21.2   25.0 #>  am   FALSE 17.9      1.244 14.37   <0.001 153.0  15.4   20.3 #>  carb 4     18.8      1.042 18.06   <0.001 239.9  16.8   20.9 #>  carb 1     22.0      1.345 16.35   <0.001 197.2  19.4   24.6 #>  carb 2     21.5      1.025 20.95   <0.001 321.5  19.5   23.5 #>  carb 3     20.6      1.780 11.55   <0.001 100.1  17.1   24.0 #>  carb 6     18.5      3.019  6.12   <0.001  30.0  12.6   24.4 #>  carb 8     21.6      4.055  5.33   <0.001  23.3  13.7   29.6 #>  #> Results averaged over levels of: hp, am, carb  #> Columns: term, value, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  #>   # Contrast between marginal means (carb2 - carb1), or \"is the 1st marginal means equal to the 2nd?\" # see the vignette on \"Hypothesis Tests and Custom Contrasts\" on the `marginaleffects` website. lc <- c(-1, 1, 0, 0, 0, 0) marginal_means(mod, variables = \"carb\", hypothesis = \"b2 = b1\") #>  #>   Term Mean Std. Error    z Pr(>|z|)   S  2.5 % 97.5 % #>  b2=b1 3.18        1.9 1.67   0.0949 3.4 -0.552    6.9 #>  #> Results averaged over levels of: am, carb  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  #>   marginal_means(mod, variables = \"carb\", hypothesis = lc) #>  #>    Term Mean Std. Error    z Pr(>|z|)   S  2.5 % 97.5 % #>  custom 3.18        1.9 1.67   0.0949 3.4 -0.552    6.9 #>  #> Results averaged over levels of: am, carb  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  #>   # Multiple custom contrasts lc <- matrix(c(     -2, 1, 1, 0, -1, 1,     -1, 1, 0, 0, 0, 0     ),   ncol = 2,   dimnames = list(NULL, c(\"A\", \"B\"))) marginal_means(mod, variables = \"carb\", hypothesis = lc) #>  #>  Term Mean Std. Error    z Pr(>|z|)   S  2.5 % 97.5 % #>     A 8.99       4.73 1.90   0.0572 4.1 -0.273   18.2 #>     B 3.18       1.90 1.67   0.0949 3.4 -0.552    6.9 #>  #> Results averaged over levels of: am, carb  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  #>"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginaleffects.html","id":null,"dir":"Reference","previous_headings":"","what":"marginaleffects() is an alias to slopes() — marginaleffects","title":"marginaleffects() is an alias to slopes() — marginaleffects","text":"alias kept backward compatibility users may prefer name.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginaleffects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"marginaleffects() is an alias to slopes() — marginaleffects","text":"","code":"marginaleffects(   model,   newdata = NULL,   variables = NULL,   type = NULL,   by = FALSE,   vcov = TRUE,   conf_level = 0.95,   slope = \"dydx\",   wts = NULL,   hypothesis = NULL,   equivalence = NULL,   p_adjust = NULL,   df = Inf,   eps = NULL,   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginalmeans.html","id":null,"dir":"Reference","previous_headings":"","what":"marginal_means() is an alias to marginal_means() — marginalmeans","title":"marginal_means() is an alias to marginal_means() — marginalmeans","text":"alias kept backward compatibility users may prefer name.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginalmeans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"marginal_means() is an alias to marginal_means() — marginalmeans","text":"","code":"marginalmeans(   model,   variables = NULL,   newdata = NULL,   vcov = TRUE,   conf_level = 0.95,   type = NULL,   transform = NULL,   cross = FALSE,   hypothesis = NULL,   equivalence = NULL,   p_adjust = NULL,   df = Inf,   wts = \"equal\",   by = NULL,   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginalmeans.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"marginal_means() is an alias to marginal_means() — marginalmeans","text":"model Model object variables Focal variables Character vector variable names: compute marginal means category listed variables. NULL: calculate marginal means logical, character, factor variables dataset used fit model. Hint:  Set cross=TRUE compute marginal means combinations focal variables. newdata Grid predictor values marginalize. NULL create grid combinations categorical predictors model. Warning: can expensive. Character vector: subset categorical variables use building balanced grid predictors. variables held mean mode. Data frame: data frame includes predictors original model. full dataset replicated every combination focal variables variables argument, using datagridcf() function. vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model)) conf_level numeric value 0 1. Confidence level use build confidence interval. type string indicates type (scale) predictions used compute marginal effects contrasts. can differ based model type, typically string : \"response\", \"link\", \"probs\", \"zero\". unsupported string entered, model-specific list acceptable values returned error message. type NULL, default value used. default first model-related row marginaleffects:::type_dictionary dataframe. type NULL default value \"response\", function tries compute marginal means link scale backtransforming using inverse link function. transform function applied unit-level adjusted predictions confidence intervals just function returns results. bayesian models, function applied individual draws posterior distribution, computing summaries. cross TRUE FALSE FALSE (default): Marginal means computed predictor individually. TRUE: Marginal means computed combination predictors specified variables argument. hypothesis specify hypothesis test custom contrast using numeric value, vector, matrix, string, string formula. Numeric: Single value: null hypothesis used computation Z p (applying transform). Vector: Weights compute linear combination (custom contrast ) estimates. Length equal number rows generated function call, without hypothesis argument. Matrix: column vector weights, describe , used compute distinct linear combination (contrast ) estimates. column names matrix used labels output. String formula specify linear non-linear hypothesis tests. term column uniquely identifies rows, terms can used formula. Otherwise, use b1, b2, etc. identify position parameter. Examples: hp = drat hp + drat = 12 b1 + b2 + b3 = 0 String: \"pairwise\": pairwise differences estimates row. \"reference\": differences estimates row estimate first row. \"sequential\": difference estimate estimate next row. \"revpairwise\", \"revreference\", \"revsequential\": inverse corresponding hypotheses, described . See Examples section vignette: https://vincentarelbundock.github.io/marginaleffects/articles/hypothesis.html equivalence Numeric vector length 2: bounds used two-one-sided test (TOST) equivalence, non-inferiority non-superiority tests. See Details section . p_adjust Adjust p-values multiple comparisons: \"holm\", \"hochberg\", \"hommel\", \"bonferroni\", \"BH\", \"\", \"fdr\". See stats::p.adjust df Degrees freedom used compute p values confidence intervals. single numeric value 1 Inf. df Inf, normal distribution used. df finite, t distribution used. See insight::get_df convenient function extract degrees freedom. Ex: slopes(model, df = insight::get_df(model)) wts character value. Weights use averaging. \"equal\": combination variables newdata gets equal weight. \"cells\": combination values variables newdata gets weight proportional frequency original data. \"proportional\": combination values variables newdata -- except variables argument -- gets weight proportional frequency original data. Collapse marginal means categories. Data frame column group labels, merging columns shared newdata data frame produced calling function without argument. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginalmeans.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"marginal_means() is an alias to marginal_means() — marginalmeans","text":"Data frame marginal means one row per variable-value combination.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginalmeans.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"marginal_means() is an alias to marginal_means() — marginalmeans","text":"function begins calling predictions function obtain grid predictors, adjusted predictions cell. grid includes combinations categorical variables listed variables newdata arguments, combinations categorical variables used fit model newdata NULL. prediction grid, numeric variables held means. constructing grid filling grid adjusted predictions, marginal_means computes marginal means variables listed variables argument, average across categories grid. marginal_means can compute standard errors linear models, predictions link scale, , type argument set \"link\". marginaleffects website compares output function popular emmeans package, provides similar advanced functionality: https://vincentarelbundock.github.io/marginaleffects/","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginalmeans.html","id":"standard-errors-using-the-delta-method","dir":"Reference","previous_headings":"","what":"Standard errors using the delta method","title":"marginal_means() is an alias to marginal_means() — marginalmeans","text":"Standard errors quantities estimated marginaleffects can obtained via delta method. requires differentiating function respect coefficients model using finite difference approach. models, delta method standard errors can sensitive various aspects numeric differentiation strategy, including step size. default, step size set 1e-8, 1e-4 times smallest absolute model coefficient, whichever largest. marginaleffects can delegate numeric differentiation numDeriv package, allows flexibility. , users can pass arguments numDeriv::jacobian function global option. example: options(marginaleffects_numDeriv = list(method = \"simple\", method.args = list(eps = 1e-6))) options(marginaleffects_numDeriv = list(method = \"Richardson\", method.args = list(eps = 1e-5))) options(marginaleffects_numDeriv = NULL) See \"Standard Errors Confidence Intervals\" vignette marginaleffects website details computation standard errors: https://vincentarelbundock.github.io/marginaleffects/articles/uncertainty.html Note inferences() function can used compute uncertainty estimates using bootstrap simulation-based inference. See vignette: https://vincentarelbundock.github.io/marginaleffects/articles/bootstrap.html","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginalmeans.html","id":"model-specific-arguments","dir":"Reference","previous_headings":"","what":"Model-Specific Arguments","title":"marginal_means() is an alias to marginal_means() — marginalmeans","text":"model types allow model-specific arguments modify nature marginal effects, predictions, marginal means, contrasts. Please report package-specific predict() arguments Github can add table . https://github.com/vincentarelbundock/marginaleffects/issues","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginalmeans.html","id":"bayesian-posterior-summaries","dir":"Reference","previous_headings":"","what":"Bayesian posterior summaries","title":"marginal_means() is an alias to marginal_means() — marginalmeans","text":"default, credible intervals bayesian models built equal-tailed intervals. can changed highest density interval setting global option: options(\"marginaleffects_posterior_interval\" = \"eti\") options(\"marginaleffects_posterior_interval\" = \"hdi\") default, center posterior distribution bayesian models identified median. Users can use different summary function setting global option: options(\"marginaleffects_posterior_center\" = \"mean\") options(\"marginaleffects_posterior_center\" = \"median\") estimates averaged using argument, tidy() function, summary() function, posterior distribution marginalized twice . First, take average across units within iteration MCMC chain, according user requested argument tidy()/summary() functions. , identify center resulting posterior using function supplied \"marginaleffects_posterior_center\" option (median default).","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginalmeans.html","id":"equivalence-inferiority-superiority","dir":"Reference","previous_headings":"","what":"Equivalence, Inferiority, Superiority","title":"marginal_means() is an alias to marginal_means() — marginalmeans","text":"\\(\\theta\\) estimate, \\(\\sigma_\\theta\\) estimated standard error, \\([, b]\\) bounds interval supplied equivalence argument. Non-inferiority: \\(H_0\\): \\(\\theta \\leq \\) \\(H_1\\): \\(\\theta > \\) \\(t=(\\theta - )/\\sigma_\\theta\\) p: Upper-tail probability Non-superiority: \\(H_0\\): \\(\\theta \\geq b\\) \\(H_1\\): \\(\\theta < b\\) \\(t=(\\theta - b)/\\sigma_\\theta\\) p: Lower-tail probability Equivalence: Two One-Sided Tests (TOST) p: Maximum non-inferiority non-superiority p values. Thanks Russell V. Lenth excellent emmeans package documentation inspired feature.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginalmeans.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"marginal_means() is an alias to marginal_means() — marginalmeans","text":"Greenland S. 2019. \"Valid P-Values Behave Exactly : Misleading Criticisms P-Values Resolution S-Values.\" American Statistician. 73(S1): 106–114. Cole, Stephen R, Jessie K Edwards, Sander Greenland. 2020. \"Surprise!\" American Journal Epidemiology 190 (2): 191–93. https://doi.org/10.1093/aje/kwaa136.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/marginalmeans.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"marginal_means() is an alias to marginal_means() — marginalmeans","text":"","code":"library(marginaleffects)  # simple marginal means for each level of `cyl` dat <- mtcars dat$carb <- factor(dat$carb) dat$cyl <- factor(dat$cyl) dat$am <- as.logical(dat$am) mod <- lm(mpg ~ carb + cyl + am, dat)  marginal_means(   mod,   variables = \"cyl\") #>  #>  Term Value Mean Std. Error    z Pr(>|z|)     S 2.5 % 97.5 % #>   cyl     6 20.4       1.34 15.2   <0.001 171.9  17.8   23.0 #>   cyl     4 23.1       1.66 13.9   <0.001 144.3  19.9   26.4 #>   cyl     8 16.2       1.07 15.1   <0.001 169.0  14.1   18.3 #>  #> Results averaged over levels of: carb, am, cyl  #> Columns: term, value, cyl, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  #>   # collapse levels of cyl by averaging by <- data.frame(   cyl = c(4, 6, 8),   by = c(\"4 & 6\", \"4 & 6\", \"8\")) marginal_means(mod,   variables = \"cyl\",   by = by) #>  #>     By Mean Std. Error    z Pr(>|z|)     S 2.5 % 97.5 % #>  4 & 6 21.7       1.13 19.2   <0.001 270.8  19.5   24.0 #>  8     16.2       1.07 15.1   <0.001 169.0  14.1   18.3 #>  #> Results averaged over levels of: carb, am, cyl  #> Columns: by, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  #>   # pairwise differences between collapsed levels marginal_means(mod,   variables = \"cyl\",   by = by,   hypothesis = \"pairwise\") #>  #>       Term Mean Std. Error    z Pr(>|z|)    S 2.5 % 97.5 % #>  4 & 6 - 8 5.54       1.51 3.66   <0.001 12.0  2.57    8.5 #>  #> Results averaged over levels of: carb, am, cyl  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  #>   # cross marginal_means(mod,   variables = c(\"cyl\", \"carb\"),   cross = TRUE) #>  #>  Mean Std. Error     z Pr(>|z|)     S 2.5 % 97.5 % #>  19.1       1.34 14.31   <0.001 151.8 16.53   21.8 #>  23.1       1.77 13.08   <0.001 127.4 19.63   26.5 #>  22.9       1.87 12.24   <0.001 112.0 19.20   26.5 #>  22.6       2.37  9.56   <0.001  69.5 17.98   27.2 #>  17.6       3.00  5.85   <0.001  27.6 11.68   23.5 #>  17.0       3.48  4.89   <0.001  19.9 10.21   23.9 #>  21.9       1.90 11.51   <0.001  99.4 18.15   25.6 #>  25.8       1.26 20.43   <0.001 305.7 23.34   28.3 #>  25.6       1.17 21.93   <0.001 351.8 23.30   27.9 #>  25.3       2.37 10.71   <0.001  86.6 20.70   30.0 #>  20.3       3.77  5.39   <0.001  23.7 12.91   27.7 #>  19.8       3.81  5.18   <0.001  22.1 12.29   27.2 #>  15.0       1.20 12.53   <0.001 117.2 12.63   17.3 #>  18.9       1.94  9.74   <0.001  72.1 15.11   22.7 #>  18.7       1.57 11.90   <0.001 106.0 15.61   21.8 #>  18.4       1.83 10.07   <0.001  76.8 14.85   22.0 #>  13.4       3.36  3.99   <0.001  13.9  6.81   20.0 #>  12.9       3.00  4.28   <0.001  15.7  6.98   18.8 #>  #> Results averaged over levels of: am  #> Columns: cyl, carb, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  #>   # collapsed cross by <- expand.grid(   cyl = unique(mtcars$cyl),   carb = unique(mtcars$carb)) by$by <- ifelse(   by$cyl == 4,   paste(\"Control:\", by$carb),   paste(\"Treatment:\", by$carb))   # Convert numeric variables to categorical before fitting the model dat <- mtcars dat$am <- as.logical(dat$am) dat$carb <- as.factor(dat$carb) mod <- lm(mpg ~ hp + am + carb, data = dat)  # Compute and summarize marginal means marginal_means(mod) #>  #>  Term Value Mean Std. Error     z Pr(>|z|)     S 2.5 % 97.5 % #>  am   TRUE  23.1      0.974 23.72   <0.001 410.9  21.2   25.0 #>  am   FALSE 17.9      1.244 14.37   <0.001 153.0  15.4   20.3 #>  carb 4     18.8      1.042 18.06   <0.001 239.9  16.8   20.9 #>  carb 1     22.0      1.345 16.35   <0.001 197.2  19.4   24.6 #>  carb 2     21.5      1.025 20.95   <0.001 321.5  19.5   23.5 #>  carb 3     20.6      1.780 11.55   <0.001 100.1  17.1   24.0 #>  carb 6     18.5      3.019  6.12   <0.001  30.0  12.6   24.4 #>  carb 8     21.6      4.055  5.33   <0.001  23.3  13.7   29.6 #>  #> Results averaged over levels of: hp, am, carb  #> Columns: term, value, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  #>   # Contrast between marginal means (carb2 - carb1), or \"is the 1st marginal means equal to the 2nd?\" # see the vignette on \"Hypothesis Tests and Custom Contrasts\" on the `marginaleffects` website. lc <- c(-1, 1, 0, 0, 0, 0) marginal_means(mod, variables = \"carb\", hypothesis = \"b2 = b1\") #>  #>   Term Mean Std. Error    z Pr(>|z|)   S  2.5 % 97.5 % #>  b2=b1 3.18        1.9 1.67   0.0949 3.4 -0.552    6.9 #>  #> Results averaged over levels of: am, carb  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  #>   marginal_means(mod, variables = \"carb\", hypothesis = lc) #>  #>    Term Mean Std. Error    z Pr(>|z|)   S  2.5 % 97.5 % #>  custom 3.18        1.9 1.67   0.0949 3.4 -0.552    6.9 #>  #> Results averaged over levels of: am, carb  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  #>   # Multiple custom contrasts lc <- matrix(c(     -2, 1, 1, 0, -1, 1,     -1, 1, 0, 0, 0, 0     ),   ncol = 2,   dimnames = list(NULL, c(\"A\", \"B\"))) marginal_means(mod, variables = \"carb\", hypothesis = lc) #>  #>  Term Mean Std. Error    z Pr(>|z|)   S  2.5 % 97.5 % #>     A 8.99       4.73 1.90   0.0572 4.1 -0.273   18.2 #>     B 3.18       1.90 1.67   0.0949 3.4 -0.552    6.9 #>  #> Results averaged over levels of: am, carb  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  #>"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/meffects.html","id":null,"dir":"Reference","previous_headings":"","what":"meffects() is an alias to slopes() — meffects","title":"meffects() is an alias to slopes() — meffects","text":"alias kept backward compatibility users may prefer name.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/meffects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"meffects() is an alias to slopes() — meffects","text":"","code":"meffects(   model,   newdata = NULL,   variables = NULL,   type = NULL,   by = FALSE,   vcov = TRUE,   conf_level = 0.95,   slope = \"dydx\",   wts = NULL,   hypothesis = NULL,   equivalence = NULL,   p_adjust = NULL,   df = Inf,   eps = NULL,   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_cap.html","id":null,"dir":"Reference","previous_headings":"","what":"plot_predictions() is an alias to plot_predictions() — plot_cap","title":"plot_predictions() is an alias to plot_predictions() — plot_cap","text":"alias kept backward compatibility.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_cap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"plot_predictions() is an alias to plot_predictions() — plot_cap","text":"","code":"plot_cap(   model,   condition = NULL,   by = NULL,   newdata = NULL,   type = NULL,   vcov = NULL,   conf_level = 0.95,   wts = NULL,   transform = NULL,   points = 0,   rug = FALSE,   gray = FALSE,   draw = TRUE,   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_cap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"plot_predictions() is an alias to plot_predictions() — plot_cap","text":"model Model object condition Conditional predictions Character vector (max length 3): Names predictors display. Named list (max length 3): List names correspond predictors. List elements can : Numeric vector Function returns numeric vector set unique categorical values Shortcut strings common reference values: \"minmax\", \"quartile\", \"threenum\" 1: x-axis. 2: color/shape. 3: facets. Numeric variables positions 2 3 summarized Tukey's five numbers ?stats::fivenum Marginal predictions Character vector (max length 3): Names categorical predictors marginalize across. 1: x-axis. 2: color. 3: facets. newdata newdata NULL, grid determined condition argument. newdata NULL, argument behaves way predictions() function. type string indicates type (scale) predictions used compute contrasts slopes. can differ based model type, typically string : \"response\", \"link\", \"probs\", \"zero\". unsupported string entered, model-specific list acceptable values returned error message. type NULL, default value used. default first model-related row marginaleffects:::type_dictionary dataframe. vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model)) conf_level numeric value 0 1. Confidence level use build confidence interval. wts string numeric: weights use computing average contrasts slopes. weights affect averaging avg_*() argument, unit-level estimates . Internally, estimates weights passed weighted.mean() function. string: column name weights variable newdata. supplying column name wts, recommended supply original data (including weights variable) explicitly newdata. numeric: vector length equal number rows original data newdata (supplied). transform function applied unit-level adjusted predictions confidence intervals just function returns results. bayesian models, function applied individual draws posterior distribution, computing summaries. points Number 0 1 controls transparency raw data points. 0 (default) display points. rug TRUE displays tick marks axes mark distribution raw data. gray FALSE grayscale color plot draw TRUE returns ggplot2 plot. FALSE returns data.frame underlying data. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_cap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"plot_predictions() is an alias to plot_predictions() — plot_cap","text":"ggplot2 object data frame (draw=FALSE)","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_cap.html","id":"model-specific-arguments","dir":"Reference","previous_headings":"","what":"Model-Specific Arguments","title":"plot_predictions() is an alias to plot_predictions() — plot_cap","text":"model types allow model-specific arguments modify nature marginal effects, predictions, marginal means, contrasts. Please report package-specific predict() arguments Github can add table . https://github.com/vincentarelbundock/marginaleffects/issues","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_cap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"plot_predictions() is an alias to plot_predictions() — plot_cap","text":"","code":"mod <- lm(mpg ~ hp + wt, data = mtcars) plot_predictions(mod, condition = \"wt\")   mod <- lm(mpg ~ hp * wt * am, data = mtcars) plot_predictions(mod, condition = c(\"hp\", \"wt\"))   plot_predictions(mod, condition = list(\"hp\", wt = \"threenum\"))   plot_predictions(mod, condition = list(\"hp\", wt = range))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_cco.html","id":null,"dir":"Reference","previous_headings":"","what":"plot_comparisons() is an alias to plot_comparisons() — plot_cco","title":"plot_comparisons() is an alias to plot_comparisons() — plot_cco","text":"alias kept backward compatibility.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_cco.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"plot_comparisons() is an alias to plot_comparisons() — plot_cco","text":"","code":"plot_cco(   model,   variables = NULL,   condition = NULL,   by = NULL,   newdata = NULL,   type = \"response\",   vcov = NULL,   conf_level = 0.95,   wts = NULL,   comparison = \"difference\",   transform = NULL,   rug = FALSE,   gray = FALSE,   draw = TRUE,   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_cco.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"plot_comparisons() is an alias to plot_comparisons() — plot_cco","text":"model Model object condition Conditional predictions Character vector (max length 3): Names predictors display. Named list (max length 3): List names correspond predictors. List elements can : Numeric vector Function returns numeric vector set unique categorical values Shortcut strings common reference values: \"minmax\", \"quartile\", \"threenum\" 1: x-axis. 2: color/shape. 3: facets. Numeric variables positions 2 3 summarized Tukey's five numbers ?stats::fivenum Marginal predictions Character vector (max length 3): Names categorical predictors marginalize across. 1: x-axis. 2: color. 3: facets. newdata newdata NULL, grid determined condition argument. newdata NULL, argument behaves way predictions() function. type string indicates type (scale) predictions used compute contrasts slopes. can differ based model type, typically string : \"response\", \"link\", \"probs\", \"zero\". unsupported string entered, model-specific list acceptable values returned error message. type NULL, default value used. default first model-related row marginaleffects:::type_dictionary dataframe. vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model)) conf_level numeric value 0 1. Confidence level use build confidence interval. wts string numeric: weights use computing average contrasts slopes. weights affect averaging avg_*() argument, unit-level estimates . Internally, estimates weights passed weighted.mean() function. string: column name weights variable newdata. supplying column name wts, recommended supply original data (including weights variable) explicitly newdata. numeric: vector length equal number rows original data newdata (supplied). transform function applied unit-level adjusted predictions confidence intervals just function returns results. bayesian models, function applied individual draws posterior distribution, computing summaries. rug TRUE displays tick marks axes mark distribution raw data. gray FALSE grayscale color plot draw TRUE returns ggplot2 plot. FALSE returns data.frame underlying data. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_cco.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"plot_comparisons() is an alias to plot_comparisons() — plot_cco","text":"ggplot2 object data frame (draw=FALSE)","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_cco.html","id":"model-specific-arguments","dir":"Reference","previous_headings":"","what":"Model-Specific Arguments","title":"plot_comparisons() is an alias to plot_comparisons() — plot_cco","text":"model types allow model-specific arguments modify nature marginal effects, predictions, marginal means, contrasts. Please report package-specific predict() arguments Github can add table . https://github.com/vincentarelbundock/marginaleffects/issues","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_cco.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"plot_comparisons() is an alias to plot_comparisons() — plot_cco","text":"","code":"mod <- lm(mpg ~ hp + wt, data = mtcars) plot_predictions(mod, condition = \"wt\")   mod <- lm(mpg ~ hp * wt * am, data = mtcars) plot_predictions(mod, condition = c(\"hp\", \"wt\"))   plot_predictions(mod, condition = list(\"hp\", wt = \"threenum\"))   plot_predictions(mod, condition = list(\"hp\", wt = range))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_cme.html","id":null,"dir":"Reference","previous_headings":"","what":"plot_slopes() is an alias to plot_slopes() — plot_cme","title":"plot_slopes() is an alias to plot_slopes() — plot_cme","text":"alias kept backward compatibility.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_cme.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"plot_slopes() is an alias to plot_slopes() — plot_cme","text":"","code":"plot_cme(   model,   variables = NULL,   condition = NULL,   by = NULL,   newdata = NULL,   type = \"response\",   vcov = NULL,   conf_level = 0.95,   wts = NULL,   slope = \"dydx\",   rug = FALSE,   gray = FALSE,   draw = TRUE,   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_cme.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"plot_slopes() is an alias to plot_slopes() — plot_cme","text":"model Model object condition Conditional predictions Character vector (max length 3): Names predictors display. Named list (max length 3): List names correspond predictors. List elements can : Numeric vector Function returns numeric vector set unique categorical values Shortcut strings common reference values: \"minmax\", \"quartile\", \"threenum\" 1: x-axis. 2: color/shape. 3: facets. Numeric variables positions 2 3 summarized Tukey's five numbers ?stats::fivenum Marginal predictions Character vector (max length 3): Names categorical predictors marginalize across. 1: x-axis. 2: color. 3: facets. newdata newdata NULL, grid determined condition argument. newdata NULL, argument behaves way predictions() function. type string indicates type (scale) predictions used compute contrasts slopes. can differ based model type, typically string : \"response\", \"link\", \"probs\", \"zero\". unsupported string entered, model-specific list acceptable values returned error message. type NULL, default value used. default first model-related row marginaleffects:::type_dictionary dataframe. vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model)) conf_level numeric value 0 1. Confidence level use build confidence interval. wts string numeric: weights use computing average contrasts slopes. weights affect averaging avg_*() argument, unit-level estimates . Internally, estimates weights passed weighted.mean() function. string: column name weights variable newdata. supplying column name wts, recommended supply original data (including weights variable) explicitly newdata. numeric: vector length equal number rows original data newdata (supplied). rug TRUE displays tick marks axes mark distribution raw data. gray FALSE grayscale color plot draw TRUE returns ggplot2 plot. FALSE returns data.frame underlying data. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_cme.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"plot_slopes() is an alias to plot_slopes() — plot_cme","text":"ggplot2 object data frame (draw=FALSE)","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_cme.html","id":"model-specific-arguments","dir":"Reference","previous_headings":"","what":"Model-Specific Arguments","title":"plot_slopes() is an alias to plot_slopes() — plot_cme","text":"model types allow model-specific arguments modify nature marginal effects, predictions, marginal means, contrasts. Please report package-specific predict() arguments Github can add table . https://github.com/vincentarelbundock/marginaleffects/issues","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_cme.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"plot_slopes() is an alias to plot_slopes() — plot_cme","text":"","code":"mod <- lm(mpg ~ hp + wt, data = mtcars) plot_predictions(mod, condition = \"wt\")   mod <- lm(mpg ~ hp * wt * am, data = mtcars) plot_predictions(mod, condition = c(\"hp\", \"wt\"))   plot_predictions(mod, condition = list(\"hp\", wt = \"threenum\"))   plot_predictions(mod, condition = list(\"hp\", wt = range))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_comparisons.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Conditional or Marginal Comparisons — plot_comparisons","title":"Plot Conditional or Marginal Comparisons — plot_comparisons","text":"Plot comparisons y-axis values one predictors (x-axis, colors/shapes, facets). argument used plot marginal comparisons, , comparisons made original data, averaged subgroups. analogous using argument comparisons() function. condition argument used plot conditional comparisons, , comparisons made user-specified grid. analogous using newdata argument datagrid() function comparisons() call. unspecified variables held mean mode. includes grouping variables mixed-effects models, analysts fit models may want specify groups interest using variables argument, supply model-specific arguments compute population-level estimates. See details . See \"Plots\" vignette website tutorials information customize plots: https://vincentarelbundock.github.io/marginaleffects/articles/plot.html https://vincentarelbundock.github.io/marginaleffects","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_comparisons.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Conditional or Marginal Comparisons — plot_comparisons","text":"","code":"plot_comparisons(   model,   variables = NULL,   condition = NULL,   by = NULL,   newdata = NULL,   type = \"response\",   vcov = NULL,   conf_level = 0.95,   wts = NULL,   comparison = \"difference\",   transform = NULL,   rug = FALSE,   gray = FALSE,   draw = TRUE,   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_comparisons.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Conditional or Marginal Comparisons — plot_comparisons","text":"model Model object variables Name variable whose contrast want plot y-axis. condition Conditional slopes Character vector (max length 3): Names predictors display. Named list (max length 3): List names correspond predictors. List elements can : Numeric vector Function returns numeric vector set unique categorical values Shortcut strings common reference values: \"minmax\", \"quartile\", \"threenum\" 1: x-axis. 2: color/shape. 3: facets. Numeric variables positions 2 3 summarized Tukey's five numbers ?stats::fivenum. Aggregate unit-level estimates (aka, marginalize, average ). Valid inputs: FALSE: return original unit-level estimates. TRUE: aggregate estimates term. Character vector column names newdata data frame produced calling function without argument. Data frame column group labels, merging columns shared newdata data frame produced calling function without argument. See examples . newdata newdata NULL, grid determined condition argument. newdata NULL, argument behaves way comparisons() function. type string indicates type (scale) predictions used compute contrasts slopes. can differ based model type, typically string : \"response\", \"link\", \"probs\", \"zero\". unsupported string entered, model-specific list acceptable values returned error message. type NULL, default value used. default first model-related row marginaleffects:::type_dictionary dataframe. vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model)) conf_level numeric value 0 1. Confidence level use build confidence interval. wts string numeric: weights use computing average contrasts slopes. weights affect averaging avg_*() argument, unit-level estimates . Internally, estimates weights passed weighted.mean() function. string: column name weights variable newdata. supplying column name wts, recommended supply original data (including weights variable) explicitly newdata. numeric: vector length equal number rows original data newdata (supplied). comparison pairs predictions compared? Difference, ratio, odds ratio, user-defined functions. string: shortcuts common contrast functions. Supported shortcuts strings: difference, differenceavg, differenceavgwts, dydx, eyex, eydx, dyex, dydxavg, eyexavg, eydxavg, dyexavg, dydxavgwts, eyexavgwts, eydxavgwts, dyexavgwts, ratio, ratioavg, ratioavgwts, lnratio, lnratioavg, lnratioavgwts, lnor, lnoravg, lnoravgwts, expdydx, expdydxavg, expdydxavgwts See Comparisons section definitions transformation. function: accept two equal-length numeric vectors adjusted predictions (hi lo) returns vector contrasts length, unique numeric value. See Transformations section examples valid functions. transform string function. Transformation applied unit-level estimates confidence intervals just function returns results. Functions must accept vector return vector length. Support string shortcuts: \"exp\", \"ln\" rug TRUE displays tick marks axes mark distribution raw data. gray FALSE grayscale color plot draw TRUE returns ggplot2 plot. FALSE returns data.frame underlying data. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_comparisons.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Conditional or Marginal Comparisons — plot_comparisons","text":"ggplot2 object","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_comparisons.html","id":"model-specific-arguments","dir":"Reference","previous_headings":"","what":"Model-Specific Arguments","title":"Plot Conditional or Marginal Comparisons — plot_comparisons","text":"model types allow model-specific arguments modify nature marginal effects, predictions, marginal means, contrasts. Please report package-specific predict() arguments Github can add table . https://github.com/vincentarelbundock/marginaleffects/issues","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_comparisons.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Conditional or Marginal Comparisons — plot_comparisons","text":"","code":"mod <- lm(mpg ~ hp * drat * factor(am), data = mtcars)  plot_comparisons(mod, variables = \"hp\", condition = \"drat\")   plot_comparisons(mod, variables = \"hp\", condition = c(\"drat\", \"am\"))   plot_comparisons(mod, variables = \"hp\", condition = list(\"am\", \"drat\" = 3:5))   plot_comparisons(mod, variables = \"am\", condition = list(\"hp\", \"drat\" = range))   plot_comparisons(mod, variables = \"am\", condition = list(\"hp\", \"drat\" = \"threenum\"))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_predictions.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Conditional or Marginal Predictions — plot_predictions","title":"Plot Conditional or Marginal Predictions — plot_predictions","text":"Plot predictions y-axis values one predictors (x-axis, colors/shapes, facets). argument used plot marginal predictions, , predictions made original data, averaged subgroups. analogous using argument predictions() function. condition argument used plot conditional predictions, , predictions made user-specified grid. analogous using newdata argument datagrid() function predictions() call. unspecified variables held mean mode. includes grouping variables mixed-effects models, analysts fit models may want specify groups interest using variables argument, supply model-specific arguments compute population-level estimates. See details . See \"Plots\" vignette website tutorials information customize plots: https://vincentarelbundock.github.io/marginaleffects/articles/plot.html https://vincentarelbundock.github.io/marginaleffects","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_predictions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Conditional or Marginal Predictions — plot_predictions","text":"","code":"plot_predictions(   model,   condition = NULL,   by = NULL,   newdata = NULL,   type = NULL,   vcov = NULL,   conf_level = 0.95,   wts = NULL,   transform = NULL,   points = 0,   rug = FALSE,   gray = FALSE,   draw = TRUE,   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_predictions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Conditional or Marginal Predictions — plot_predictions","text":"model Model object condition Conditional predictions Character vector (max length 3): Names predictors display. Named list (max length 3): List names correspond predictors. List elements can : Numeric vector Function returns numeric vector set unique categorical values Shortcut strings common reference values: \"minmax\", \"quartile\", \"threenum\" 1: x-axis. 2: color/shape. 3: facets. Numeric variables positions 2 3 summarized Tukey's five numbers ?stats::fivenum Marginal predictions Character vector (max length 3): Names categorical predictors marginalize across. 1: x-axis. 2: color. 3: facets. newdata newdata NULL, grid determined condition argument. newdata NULL, argument behaves way predictions() function. type string indicates type (scale) predictions used compute contrasts slopes. can differ based model type, typically string : \"response\", \"link\", \"probs\", \"zero\". unsupported string entered, model-specific list acceptable values returned error message. type NULL, default value used. default first model-related row marginaleffects:::type_dictionary dataframe. vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model)) conf_level numeric value 0 1. Confidence level use build confidence interval. wts string numeric: weights use computing average contrasts slopes. weights affect averaging avg_*() argument, unit-level estimates . Internally, estimates weights passed weighted.mean() function. string: column name weights variable newdata. supplying column name wts, recommended supply original data (including weights variable) explicitly newdata. numeric: vector length equal number rows original data newdata (supplied). transform function applied unit-level adjusted predictions confidence intervals just function returns results. bayesian models, function applied individual draws posterior distribution, computing summaries. points Number 0 1 controls transparency raw data points. 0 (default) display points. rug TRUE displays tick marks axes mark distribution raw data. gray FALSE grayscale color plot draw TRUE returns ggplot2 plot. FALSE returns data.frame underlying data. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_predictions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Conditional or Marginal Predictions — plot_predictions","text":"ggplot2 object data frame (draw=FALSE)","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_predictions.html","id":"model-specific-arguments","dir":"Reference","previous_headings":"","what":"Model-Specific Arguments","title":"Plot Conditional or Marginal Predictions — plot_predictions","text":"model types allow model-specific arguments modify nature marginal effects, predictions, marginal means, contrasts. Please report package-specific predict() arguments Github can add table . https://github.com/vincentarelbundock/marginaleffects/issues","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_predictions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Conditional or Marginal Predictions — plot_predictions","text":"","code":"mod <- lm(mpg ~ hp + wt, data = mtcars) plot_predictions(mod, condition = \"wt\")   mod <- lm(mpg ~ hp * wt * am, data = mtcars) plot_predictions(mod, condition = c(\"hp\", \"wt\"))   plot_predictions(mod, condition = list(\"hp\", wt = \"threenum\"))   plot_predictions(mod, condition = list(\"hp\", wt = range))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_slopes.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Conditional or Marginal Slopes — plot_slopes","title":"Plot Conditional or Marginal Slopes — plot_slopes","text":"Plot slopes y-axis values one predictors (x-axis, colors/shapes, facets). argument used plot marginal slopes, , slopes made original data, averaged subgroups. analogous using argument slopes() function. condition argument used plot conditional slopes, , slopes made user-specified grid. analogous using newdata argument datagrid() function slopes() call. unspecified variables held mean mode. includes grouping variables mixed-effects models, analysts fit models may want specify groups interest using variables argument, supply model-specific arguments compute population-level estimates. See details . See \"Plots\" vignette website tutorials information customize plots: https://vincentarelbundock.github.io/marginaleffects/articles/plot.html https://vincentarelbundock.github.io/marginaleffects","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_slopes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Conditional or Marginal Slopes — plot_slopes","text":"","code":"plot_slopes(   model,   variables = NULL,   condition = NULL,   by = NULL,   newdata = NULL,   type = \"response\",   vcov = NULL,   conf_level = 0.95,   wts = NULL,   slope = \"dydx\",   rug = FALSE,   gray = FALSE,   draw = TRUE,   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_slopes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Conditional or Marginal Slopes — plot_slopes","text":"model Model object variables Name variable whose marginal effect (slope) want plot y-axis. condition Conditional slopes Character vector (max length 3): Names predictors display. Named list (max length 3): List names correspond predictors. List elements can : Numeric vector Function returns numeric vector set unique categorical values Shortcut strings common reference values: \"minmax\", \"quartile\", \"threenum\" 1: x-axis. 2: color/shape. 3: facets. Numeric variables positions 2 3 summarized Tukey's five numbers ?stats::fivenum. Aggregate unit-level estimates (aka, marginalize, average ). Valid inputs: FALSE: return original unit-level estimates. TRUE: aggregate estimates term. Character vector column names newdata data frame produced calling function without argument. Data frame column group labels, merging columns shared newdata data frame produced calling function without argument. See examples . newdata newdata NULL, grid determined condition argument. newdata NULL, argument behaves way slopes() function. type string indicates type (scale) predictions used compute contrasts slopes. can differ based model type, typically string : \"response\", \"link\", \"probs\", \"zero\". unsupported string entered, model-specific list acceptable values returned error message. type NULL, default value used. default first model-related row marginaleffects:::type_dictionary dataframe. vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model)) conf_level numeric value 0 1. Confidence level use build confidence interval. wts string numeric: weights use computing average contrasts slopes. weights affect averaging avg_*() argument, unit-level estimates . Internally, estimates weights passed weighted.mean() function. string: column name weights variable newdata. supplying column name wts, recommended supply original data (including weights variable) explicitly newdata. numeric: vector length equal number rows original data newdata (supplied). slope string indicates type slope (semi-)elasticity compute: \"dydx\": dY/dX \"eyex\": dY/dX * Y / X \"eydx\": dY/dX * Y \"dyex\": dY/dX / X Y predicted value outcome; X observed value predictor. rug TRUE displays tick marks axes mark distribution raw data. gray FALSE grayscale color plot draw TRUE returns ggplot2 plot. FALSE returns data.frame underlying data. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_slopes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Conditional or Marginal Slopes — plot_slopes","text":"ggplot2 object","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_slopes.html","id":"model-specific-arguments","dir":"Reference","previous_headings":"","what":"Model-Specific Arguments","title":"Plot Conditional or Marginal Slopes — plot_slopes","text":"model types allow model-specific arguments modify nature marginal effects, predictions, marginal means, contrasts. Please report package-specific predict() arguments Github can add table . https://github.com/vincentarelbundock/marginaleffects/issues","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/plot_slopes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Conditional or Marginal Slopes — plot_slopes","text":"","code":"library(marginaleffects) mod <- lm(mpg ~ hp * drat * factor(am), data = mtcars)  plot_slopes(mod, variables = \"hp\", condition = \"drat\")   plot_slopes(mod, variables = \"hp\", condition = c(\"drat\", \"am\"))   plot_slopes(mod, variables = \"hp\", condition = list(\"am\", \"drat\" = 3:5))   plot_slopes(mod, variables = \"am\", condition = list(\"hp\", \"drat\" = range))   plot_slopes(mod, variables = \"am\", condition = list(\"hp\", \"drat\" = \"threenum\"))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/posterior_draws.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Posterior Draws or Bootstrap Resamples from marginaleffects Objects — posterior_draws","title":"Extract Posterior Draws or Bootstrap Resamples from marginaleffects Objects — posterior_draws","text":"Extract Posterior Draws Bootstrap Resamples marginaleffects Objects","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/posterior_draws.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Posterior Draws or Bootstrap Resamples from marginaleffects Objects — posterior_draws","text":"","code":"posterior_draws(x, shape = \"long\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/posterior_draws.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Posterior Draws or Bootstrap Resamples from marginaleffects Objects — posterior_draws","text":"x object produced marginaleffects package function, predictions(), avg_slopes(), hypotheses(), etc. shape string indicating shape output format: \"long\": long format data frame \"DxP\": Matrix draws rows parameters columns \"PxD\": Matrix draws rows parameters columns \"rvar\": Random variable datatype (see posterior package documentation).","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/posterior_draws.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Posterior Draws or Bootstrap Resamples from marginaleffects Objects — posterior_draws","text":"data.frame drawid draw columns.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/posteriordraws.html","id":null,"dir":"Reference","previous_headings":"","what":"posteriordraws() is an alias to posterior_draws() — posteriordraws","title":"posteriordraws() is an alias to posterior_draws() — posteriordraws","text":"alias kept backward compatibility users may prefer name.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/posteriordraws.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"posteriordraws() is an alias to posterior_draws() — posteriordraws","text":"","code":"posteriordraws(x, shape = \"long\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/posteriordraws.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"posteriordraws() is an alias to posterior_draws() — posteriordraws","text":"x object produced marginaleffects package function, predictions(), avg_slopes(), hypotheses(), etc. shape string indicating shape output format: \"long\": long format data frame \"DxP\": Matrix draws rows parameters columns \"PxD\": Matrix draws rows parameters columns \"rvar\": Random variable datatype (see posterior package documentation).","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/posteriordraws.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"posteriordraws() is an alias to posterior_draws() — posteriordraws","text":"data.frame drawid draw columns.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/predictions.html","id":null,"dir":"Reference","previous_headings":"","what":"Predictions — predictions","title":"Predictions — predictions","text":"Outcome predicted fitted model specified scale given combination values predictor variables, observed values, means, factor levels (.k.. \"reference grid\"). predictions(): unit-level (conditional) estimates. avg_predictions(): average (marginal) estimates. newdata argument datagrid() function can used control statistics evaluated predictor space: \"observed values\", \"mean\", \"representative values\", etc. See predictions vignette package website worked examples case studies: https://vincentarelbundock.github.io/marginaleffects/articles/predictions.html https://vincentarelbundock.github.io/marginaleffects/","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/predictions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predictions — predictions","text":"","code":"predictions(   model,   newdata = NULL,   variables = NULL,   vcov = TRUE,   conf_level = 0.95,   type = NULL,   by = FALSE,   byfun = NULL,   wts = NULL,   transform = NULL,   hypothesis = NULL,   equivalence = NULL,   p_adjust = NULL,   df = Inf,   ... )  avg_predictions(   model,   newdata = NULL,   variables = NULL,   vcov = TRUE,   conf_level = 0.95,   type = NULL,   by = TRUE,   byfun = NULL,   wts = NULL,   transform = NULL,   hypothesis = NULL,   equivalence = NULL,   p_adjust = NULL,   df = Inf,   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/predictions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predictions — predictions","text":"model Model object newdata Grid predictor values evaluate predictions. NULL (default): Predictions observed value original dataset. See insight::get_data() data frame: Predictions row newdata data frame. string: \"mean\": Predictions Mean. Predictions predictor held mean mode. \"median\": Predictions Median. Predictions predictor held median mode. \"marginalmeans\": Predictions Marginal Means. See Details section . \"tukey\": Predictions Tukey's 5 numbers. \"grid\": Predictions grid representative numbers (Tukey's 5 numbers unique values categorical predictors). datagrid() call specify custom grid regressors. example: newdata = datagrid(cyl = c(4, 6)): cyl variable equal 4 6 regressors fixed means modes. See Examples section datagrid() documentation. variables Counterfactual variables. Output: predictions(): entire dataset replicated unique combination variables, predictions made. avg_predictions(): entire dataset replicated, predictions made, marginalized variables categories. Warning: can expensive large datasets. Warning: Users need \"conditional\" predictions use newdata argument instead variables. Input: NULL: computes one prediction per row newdata Character vector: dataset replicated every combination unique values variables identified variables. Named list: names identify subset variables interest values. numeric variables, variables argument supports functions string shortcuts: function returns numeric value Numeric vector: Contrast 2nd element 1st element x vector. \"iqr\": Contrast across interquartile range regressor. \"sd\": Contrast across one standard deviation around regressor mean. \"2sd\": Contrast across two standard deviations around regressor mean. \"minmax\": Contrast maximum minimum values regressor. \"threenum\": mean 1 standard deviation sides \"fivenum\": Tukey's five numbers vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model)) conf_level numeric value 0 1. Confidence level use build confidence interval. type string indicates type (scale) predictions used compute contrasts slopes. can differ based model type, typically string : \"response\", \"link\", \"probs\", \"zero\". unsupported string entered, model-specific list acceptable values returned error message. type NULL, default value used. default first model-related row marginaleffects:::type_dictionary dataframe. See details section note backtransformation. Aggregate unit-level estimates (aka, marginalize, average ). Valid inputs: FALSE: return original unit-level estimates. TRUE: aggregate estimates term. Character vector column names newdata data frame produced calling function without argument. Data frame column group labels, merging columns shared newdata data frame produced calling function without argument. See examples . byfun function mean() sum() used aggregate estimates within subgroups defined argument. NULL uses mean() function. Must accept numeric vector return single numeric value. sometimes used take sum mean predicted probabilities across outcome predictor levels. See examples section. wts string numeric: weights use computing average contrasts slopes. weights affect averaging avg_*() argument, unit-level estimates . Internally, estimates weights passed weighted.mean() function. string: column name weights variable newdata. supplying column name wts, recommended supply original data (including weights variable) explicitly newdata. numeric: vector length equal number rows original data newdata (supplied). transform function applied unit-level adjusted predictions confidence intervals just function returns results. bayesian models, function applied individual draws posterior distribution, computing summaries. hypothesis specify hypothesis test custom contrast using numeric value, vector, matrix, string, string formula. Numeric: Single value: null hypothesis used computation Z p (applying transform). Vector: Weights compute linear combination (custom contrast ) estimates. Length equal number rows generated function call, without hypothesis argument. Matrix: column vector weights, describe , used compute distinct linear combination (contrast ) estimates. column names matrix used labels output. String formula specify linear non-linear hypothesis tests. term column uniquely identifies rows, terms can used formula. Otherwise, use b1, b2, etc. identify position parameter. Examples: hp = drat hp + drat = 12 b1 + b2 + b3 = 0 String: \"pairwise\": pairwise differences estimates row. \"reference\": differences estimates row estimate first row. \"sequential\": difference estimate estimate next row. \"revpairwise\", \"revreference\", \"revsequential\": inverse corresponding hypotheses, described . See Examples section vignette: https://vincentarelbundock.github.io/marginaleffects/articles/hypothesis.html equivalence Numeric vector length 2: bounds used two-one-sided test (TOST) equivalence, non-inferiority non-superiority tests. See Details section . p_adjust Adjust p-values multiple comparisons: \"holm\", \"hochberg\", \"hommel\", \"bonferroni\", \"BH\", \"\", \"fdr\". See stats::p.adjust df Degrees freedom used compute p values confidence intervals. single numeric value 1 Inf. df Inf, normal distribution used. df finite, t distribution used. See insight::get_df convenient function extract degrees freedom. Ex: slopes(model, df = insight::get_df(model)) ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/predictions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predictions — predictions","text":"data.frame one row per observation several columns: rowid: row number newdata data frame type: prediction type, defined type argument group: (optional) value grouped outcome (e.g., categorical outcome models) estimate: predicted outcome std.error: standard errors computed using delta method. p.value: p value associated estimate column. null determined hypothesis argument (0 default), p values computed applying transform argument. models class feglm, Gam, glm negbin, p values computed link scale default unless type argument specified explicitly. s.value: Shannon information tranforms p values. many consecutive \"heads\" tosses provide amount evidence (\"suprise\") null hypothesis coin fair? See Greenland (2019) Cole et al. (2020). conf.low: lower bound confidence interval (equal-tailed interval bayesian models) conf.high: upper bound confidence interval (equal-tailed interval bayesian models) See ?print.marginaleffects printing options.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/predictions.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Predictions — predictions","text":"glm(), MASS::glm.nb, gam::gam(), feols::feglm models type, transform hypothesis equal NULL (default), predictions() first predicts link scale, backtransforms estimates confidence intervals. implies estimate produced avg_predictions() exactly equal average estimate column produced predictions(). Users can circumvent behavior average predictions directly response scale setting type=\"response\" explicitly. type=\"response\", intervals symmetric may undesirable properties (e.g., stretching beyond [0,1] bounds binary outcome regression).","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/predictions.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Predictions — predictions","text":"avg_predictions(): Average predictions","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/predictions.html","id":"standard-errors-using-the-delta-method","dir":"Reference","previous_headings":"","what":"Standard errors using the delta method","title":"Predictions — predictions","text":"Standard errors quantities estimated marginaleffects can obtained via delta method. requires differentiating function respect coefficients model using finite difference approach. models, delta method standard errors can sensitive various aspects numeric differentiation strategy, including step size. default, step size set 1e-8, 1e-4 times smallest absolute model coefficient, whichever largest. marginaleffects can delegate numeric differentiation numDeriv package, allows flexibility. , users can pass arguments numDeriv::jacobian function global option. example: options(marginaleffects_numDeriv = list(method = \"simple\", method.args = list(eps = 1e-6))) options(marginaleffects_numDeriv = list(method = \"Richardson\", method.args = list(eps = 1e-5))) options(marginaleffects_numDeriv = NULL) See \"Standard Errors Confidence Intervals\" vignette marginaleffects website details computation standard errors: https://vincentarelbundock.github.io/marginaleffects/articles/uncertainty.html Note inferences() function can used compute uncertainty estimates using bootstrap simulation-based inference. See vignette: https://vincentarelbundock.github.io/marginaleffects/articles/bootstrap.html","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/predictions.html","id":"model-specific-arguments","dir":"Reference","previous_headings":"","what":"Model-Specific Arguments","title":"Predictions — predictions","text":"model types allow model-specific arguments modify nature marginal effects, predictions, marginal means, contrasts. Please report package-specific predict() arguments Github can add table . https://github.com/vincentarelbundock/marginaleffects/issues","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/predictions.html","id":"bayesian-posterior-summaries","dir":"Reference","previous_headings":"","what":"Bayesian posterior summaries","title":"Predictions — predictions","text":"default, credible intervals bayesian models built equal-tailed intervals. can changed highest density interval setting global option: options(\"marginaleffects_posterior_interval\" = \"eti\") options(\"marginaleffects_posterior_interval\" = \"hdi\") default, center posterior distribution bayesian models identified median. Users can use different summary function setting global option: options(\"marginaleffects_posterior_center\" = \"mean\") options(\"marginaleffects_posterior_center\" = \"median\") estimates averaged using argument, tidy() function, summary() function, posterior distribution marginalized twice . First, take average across units within iteration MCMC chain, according user requested argument tidy()/summary() functions. , identify center resulting posterior using function supplied \"marginaleffects_posterior_center\" option (median default).","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/predictions.html","id":"equivalence-inferiority-superiority","dir":"Reference","previous_headings":"","what":"Equivalence, Inferiority, Superiority","title":"Predictions — predictions","text":"\\(\\theta\\) estimate, \\(\\sigma_\\theta\\) estimated standard error, \\([, b]\\) bounds interval supplied equivalence argument. Non-inferiority: \\(H_0\\): \\(\\theta \\leq \\) \\(H_1\\): \\(\\theta > \\) \\(t=(\\theta - )/\\sigma_\\theta\\) p: Upper-tail probability Non-superiority: \\(H_0\\): \\(\\theta \\geq b\\) \\(H_1\\): \\(\\theta < b\\) \\(t=(\\theta - b)/\\sigma_\\theta\\) p: Lower-tail probability Equivalence: Two One-Sided Tests (TOST) p: Maximum non-inferiority non-superiority p values. Thanks Russell V. Lenth excellent emmeans package documentation inspired feature.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/predictions.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Predictions — predictions","text":"Greenland S. 2019. \"Valid P-Values Behave Exactly : Misleading Criticisms P-Values Resolution S-Values.\" American Statistician. 73(S1): 106–114. Cole, Stephen R, Jessie K Edwards, Sander Greenland. 2020. \"Surprise!\" American Journal Epidemiology 190 (2): 191–93. https://doi.org/10.1093/aje/kwaa136.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/predictions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predictions — predictions","text":"","code":"if (FALSE) { # Adjusted Prediction for every row of the original dataset mod <- lm(mpg ~ hp + factor(cyl), data = mtcars) pred <- predictions(mod) head(pred)  # Adjusted Predictions at User-Specified Values of the Regressors predictions(mod, newdata = datagrid(hp = c(100, 120), cyl = 4))  m <- lm(mpg ~ hp + drat + factor(cyl) + factor(am), data = mtcars) predictions(m, newdata = datagrid(FUN_factor = unique, FUN_numeric = median))  # Average Adjusted Predictions (AAP) library(dplyr) mod <- lm(mpg ~ hp * am * vs, mtcars)  avg_predictions(mod)  predictions(mod, by = \"am\")  # Conditional Adjusted Predictions plot_predictions(mod, condition = \"hp\")  # Counterfactual predictions with the `variables` argument # the `mtcars` dataset has 32 rows  mod <- lm(mpg ~ hp + am, data = mtcars) p <- predictions(mod) head(p) nrow(p)  # average counterfactual predictions avg_predictions(mod, variables = \"am\")  # counterfactual predictions obtained by replicating the entire for different # values of the predictors p <- predictions(mod, variables = list(hp = c(90, 110))) nrow(p)   # hypothesis test: is the prediction in the 1st row equal to the prediction in the 2nd row mod <- lm(mpg ~ wt + drat, data = mtcars)  predictions(     mod,     newdata = datagrid(wt = 2:3),     hypothesis = \"b1 = b2\")  # same hypothesis test using row indices predictions(     mod,     newdata = datagrid(wt = 2:3),     hypothesis = \"b1 - b2 = 0\")  # same hypothesis test using numeric vector of weights predictions(     mod,     newdata = datagrid(wt = 2:3),     hypothesis = c(1, -1))  # two custom contrasts using a matrix of weights lc <- matrix(c(     1, -1,     2, 3),     ncol = 2) predictions(     mod,     newdata = datagrid(wt = 2:3),     hypothesis = lc)   # `by` argument mod <- lm(mpg ~ hp * am * vs, data = mtcars) predictions(mod, by = c(\"am\", \"vs\"))  library(nnet) nom <- multinom(factor(gear) ~ mpg + am * vs, data = mtcars, trace = FALSE)  # first 5 raw predictions predictions(nom, type = \"probs\") |> head()  # average predictions avg_predictions(nom, type = \"probs\", by = \"group\")  by <- data.frame(     group = c(\"3\", \"4\", \"5\"),     by = c(\"3,4\", \"3,4\", \"5\"))  predictions(nom, type = \"probs\", by = by)  # sum of predicted probabilities for combined response levels mod <- multinom(factor(cyl) ~ mpg + am, data = mtcars, trace = FALSE) by <- data.frame(     by = c(\"4,6\", \"4,6\", \"8\"),     group = as.character(c(4, 6, 8))) predictions(mod, newdata = \"mean\", byfun = sum, by = by) }"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/print.marginaleffects.html","id":null,"dir":"Reference","previous_headings":"","what":"Print marginaleffects objects — print.marginaleffects","title":"Print marginaleffects objects — print.marginaleffects","text":"function controls text printed console one core marginalefffects functions called object returned: predictions(), comparisons(), slopes(), marginal_means(), hypotheses(), avg_predictions(), avg_comparisons(), avg_slopes(). functions return standard data frames. Columns can extracted name, predictions(model)$estimate, usual data manipulation functions work ---box:  colnames(), head(), subset(), dplyr::filter(), dplyr::arrange(), etc. data columns printed default. can disable pretty printing print full results standard data frame using style argument applying .data.frame() object. See examples .","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/print.marginaleffects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print marginaleffects objects — print.marginaleffects","text":"","code":"# S3 method for marginaleffects print(   x,   digits = getOption(\"marginaleffects_print_digits\", default = 3),   p_eps = getOption(\"marginaleffects_print_p_eps\", default = 0.001),   topn = getOption(\"marginaleffects_print_topn\", default = 5),   nrows = getOption(\"marginaleffects_print_nrows\", default = 30),   ncols = getOption(\"marginaleffects_print_ncols\", default = 30),   style = getOption(\"marginaleffects_print_style\", default = \"summary\"),   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/print.marginaleffects.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print marginaleffects objects — print.marginaleffects","text":"x object produced one marginaleffects package functions. digits number digits display. p_eps p values smaller number printed \"<0.001\" style. topn number rows printed beginning end tables nrows rows. nrows number rows printed truncation. ncols maximum number column names display bottom printed output. style \"summary\" \"data.frame\" ... arguments currently ignored.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/print.marginaleffects.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print marginaleffects objects — print.marginaleffects","text":"","code":"library(marginaleffects) mod <- lm(mpg ~ hp + am + factor(gear), data = mtcars) p <- predictions(mod, by = c(\"am\", \"gear\")) p #>  #>  am gear Estimate Std. Error    z Pr(>|z|)     S 2.5 % 97.5 % #>   1    4     26.3      1.039 25.3   <0.001 466.1  24.2   28.3 #>   0    3     16.1      0.759 21.2   <0.001 329.6  14.6   17.6 #>   0    4     21.0      1.470 14.3   <0.001 152.1  18.2   23.9 #>   1    5     21.4      1.315 16.3   <0.001 195.2  18.8   24.0 #>  #> Columns: am, gear, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  #>   subset(p, am == 1) #>  #>  Estimate Std. Error    z Pr(>|z|)     S CI low CI high #>      26.3       1.04 25.3   <0.001 466.1   24.2    28.3 #>      21.4       1.31 16.3   <0.001 195.2   18.8    24.0 #>  #> Columns: am, gear, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  #>   print(p, style = \"data.frame\") #>   am gear estimate std.error statistic       p.value  s.value conf.low #> 1  1    4 26.27500 1.0392746  25.28206 5.032214e-141 466.0607 24.23806 #> 2  0    3 16.10667 0.7589789  21.22150 6.047008e-100 329.5966 14.61910 #> 3  0    4 21.05000 1.4697563  14.32210  1.592320e-46 152.1376 18.16933 #> 4  1    5 21.38000 1.3145900  16.26363  1.788333e-59 195.1551 18.80345 #>   conf.high #> 1  28.31194 #> 2  17.59424 #> 3  23.93067 #> 4  23.95655  data.frame(p) #>   am gear estimate std.error statistic       p.value  s.value conf.low #> 1  1    4 26.27500 1.0392746  25.28206 5.032214e-141 466.0607 24.23806 #> 2  0    3 16.10667 0.7589789  21.22150 6.047008e-100 329.5966 14.61910 #> 3  0    4 21.05000 1.4697563  14.32210  1.592320e-46 152.1376 18.16933 #> 4  1    5 21.38000 1.3145900  16.26363  1.788333e-59 195.1551 18.80345 #>   conf.high #> 1  28.31194 #> 2  17.59424 #> 3  23.93067 #> 4  23.95655"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. generics glance, tidy","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/sanitize_model_specific.html","id":null,"dir":"Reference","previous_headings":"","what":"Method to raise model-specific warnings and errors — sanitize_model_specific.glimML","title":"Method to raise model-specific warnings and errors — sanitize_model_specific.glimML","text":"Method raise model-specific warnings errors","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/sanitize_model_specific.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Method to raise model-specific warnings and errors — sanitize_model_specific.glimML","text":"","code":"# S3 method for glimML sanitize_model_specific(model, ...)  # S3 method for betareg sanitize_model_specific(model, ...)  sanitize_model_specific(model, ...)  # S3 method for default sanitize_model_specific(   model,   vcov = NULL,   calling_function = \"marginaleffects\",   ... )  # S3 method for brmsfit sanitize_model_specific(model, ...)  # S3 method for glmmTMB sanitize_model_specific(   model,   vcov = NULL,   calling_function = \"marginaleffects\",   ... )  # S3 method for inferences_simulation sanitize_model_specific(model, vcov = FALSE, ...)  # S3 method for mblogit sanitize_model_specific(model, calling_function = \"marginaleffects\", ...)  # S3 method for mlogit sanitize_model_specific(model, newdata, ...)  # S3 method for clm sanitize_model_specific(model, ...)  # S3 method for plm sanitize_model_specific(model, ...)  # S3 method for plm sanitize_model_specific(model, ...)  # S3 method for rqs sanitize_model_specific(model, ...)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/sanitize_model_specific.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Method to raise model-specific warnings and errors — sanitize_model_specific.glimML","text":"model Model object ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments. vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model)) newdata Grid predictor values evaluate slopes. NULL (default): Unit-level slopes observed value original dataset. See insight::get_data() data frame: Unit-level slopes row newdata data frame. datagrid() call specify custom grid regressors. example: newdata = datagrid(cyl = c(4, 6)): cyl variable equal 4 6 regressors fixed means modes. See Examples section datagrid() documentation. string: \"mean\": Marginal Effects Mean. Slopes predictor held mean mode. \"median\": Marginal Effects Median. Slopes predictor held median mode. \"marginalmeans\": Marginal Effects Marginal Means. See Details section . \"tukey\": Marginal Effects Tukey's 5 numbers. \"grid\": Marginal Effects grid representative numbers (Tukey's 5 numbers unique values categorical predictors).","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/sanitize_model_specific.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Method to raise model-specific warnings and errors — sanitize_model_specific.glimML","text":"warning, error, nothing","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/set_coef.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal function to set coefficients — set_coef","title":"Internal function to set coefficients — set_coef","text":"Set coefficients model different values return modified object (internal function)","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/set_coef.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal function to set coefficients — set_coef","text":"","code":"set_coef(model, coefs, ...)  # S3 method for default set_coef(model, coefs, ...)  # S3 method for polr set_coef(model, coefs, ...)  # S3 method for glmmPQL set_coef(model, coefs, ...)  # S3 method for hetprob set_coef(model, coefs, ...)  # S3 method for ivpml set_coef(model, coefs, ...)  # S3 method for afex_aov set_coef(model, coefs, ...)  # S3 method for glimML set_coef(model, coefs, ...)  # S3 method for betareg set_coef(model, coefs, ...)  # S3 method for multinom set_coef(model, coefs, ...)  # S3 method for crch set_coef(model, coefs, ...)  # S3 method for hxlr set_coef(model, coefs, ...)  # S3 method for gamlss set_coef(model, coefs, ...)  # S3 method for glmmTMB set_coef(model, coefs, ...)  # S3 method for glmx set_coef(model, coefs, ...)  # S3 method for merMod set_coef(model, coefs, ...)  # S3 method for lmerModLmerTest set_coef(model, coefs, ...)  # S3 method for lmerMod set_coef(model, coefs, ...)  # S3 method for mlm set_coef(model, coefs, ...)  # S3 method for lme set_coef(model, coefs, ...)  # S3 method for hurdle set_coef(model, coefs, ...)  # S3 method for zeroinfl set_coef(model, coefs, ...)  # S3 method for rlmerMod set_coef(model, coefs, ...)  # S3 method for selection set_coef(model, coefs, ...)  # S3 method for scam set_coef(model, coefs, ...)  # S3 method for glm set_coef(model, coefs, ...)  # S3 method for lm set_coef(model, coefs, ...)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/set_coef.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal function to set coefficients — set_coef","text":"model object modify coefs vector coefficients insert model object","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/set_coef.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal function to set coefficients — set_coef","text":"Model object class model argument, different stored coefficients.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/set_coef.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Internal function to set coefficients — set_coef","text":"compute variance marginal effects need take Jacobian ","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/slopes.html","id":null,"dir":"Reference","previous_headings":"","what":"Slopes (aka Partial derivatives, Marginal Effects, or Trends) — slopes","title":"Slopes (aka Partial derivatives, Marginal Effects, or Trends) — slopes","text":"Partial derivative regression equation respect regressor interest. slopes(): unit-level (conditional) estimates. avg_slopes(): average (marginal) estimates. newdata argument datagrid() function can used control statistics evaluated predictor space: \"observed values\", \"mean\", \"representative values\", etc. See slopes vignette package website worked examples case studies: https://vincentarelbundock.github.io/marginaleffects/articles/slopes.html https://vincentarelbundock.github.io/marginaleffects/","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/slopes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Slopes (aka Partial derivatives, Marginal Effects, or Trends) — slopes","text":"","code":"slopes(   model,   newdata = NULL,   variables = NULL,   type = NULL,   by = FALSE,   vcov = TRUE,   conf_level = 0.95,   slope = \"dydx\",   wts = NULL,   hypothesis = NULL,   equivalence = NULL,   p_adjust = NULL,   df = Inf,   eps = NULL,   ... )  avg_slopes(   model,   newdata = NULL,   variables = NULL,   type = NULL,   by = TRUE,   vcov = TRUE,   conf_level = 0.95,   slope = \"dydx\",   wts = NULL,   hypothesis = NULL,   equivalence = NULL,   p_adjust = NULL,   df = Inf,   eps = NULL,   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/slopes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Slopes (aka Partial derivatives, Marginal Effects, or Trends) — slopes","text":"model Model object newdata Grid predictor values evaluate slopes. NULL (default): Unit-level slopes observed value original dataset. See insight::get_data() data frame: Unit-level slopes row newdata data frame. datagrid() call specify custom grid regressors. example: newdata = datagrid(cyl = c(4, 6)): cyl variable equal 4 6 regressors fixed means modes. See Examples section datagrid() documentation. string: \"mean\": Marginal Effects Mean. Slopes predictor held mean mode. \"median\": Marginal Effects Median. Slopes predictor held median mode. \"marginalmeans\": Marginal Effects Marginal Means. See Details section . \"tukey\": Marginal Effects Tukey's 5 numbers. \"grid\": Marginal Effects grid representative numbers (Tukey's 5 numbers unique values categorical predictors). variables Focal variables NULL: compute slopes comparisons variables model object (can slow). Character vector: subset variables (usually faster). type string indicates type (scale) predictions used compute contrasts slopes. can differ based model type, typically string : \"response\", \"link\", \"probs\", \"zero\". unsupported string entered, model-specific list acceptable values returned error message. type NULL, default value used. default first model-related row marginaleffects:::type_dictionary dataframe. Aggregate unit-level estimates (aka, marginalize, average ). Valid inputs: FALSE: return original unit-level estimates. TRUE: aggregate estimates term. Character vector column names newdata data frame produced calling function without argument. Data frame column group labels, merging columns shared newdata data frame produced calling function without argument. See examples . vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model)) conf_level numeric value 0 1. Confidence level use build confidence interval. slope string indicates type slope (semi-)elasticity compute: \"dydx\": dY/dX \"eyex\": dY/dX * Y / X \"eydx\": dY/dX * Y \"dyex\": dY/dX / X Y predicted value outcome; X observed value predictor. wts string numeric: weights use computing average contrasts slopes. weights affect averaging avg_*() argument, unit-level estimates . Internally, estimates weights passed weighted.mean() function. string: column name weights variable newdata. supplying column name wts, recommended supply original data (including weights variable) explicitly newdata. numeric: vector length equal number rows original data newdata (supplied). hypothesis specify hypothesis test custom contrast using numeric value, vector, matrix, string, string formula. Numeric: Single value: null hypothesis used computation Z p (applying transform). Vector: Weights compute linear combination (custom contrast ) estimates. Length equal number rows generated function call, without hypothesis argument. Matrix: column vector weights, describe , used compute distinct linear combination (contrast ) estimates. column names matrix used labels output. String formula specify linear non-linear hypothesis tests. term column uniquely identifies rows, terms can used formula. Otherwise, use b1, b2, etc. identify position parameter. Examples: hp = drat hp + drat = 12 b1 + b2 + b3 = 0 String: \"pairwise\": pairwise differences estimates row. \"reference\": differences estimates row estimate first row. \"sequential\": difference estimate estimate next row. \"revpairwise\", \"revreference\", \"revsequential\": inverse corresponding hypotheses, described . See Examples section vignette: https://vincentarelbundock.github.io/marginaleffects/articles/hypothesis.html equivalence Numeric vector length 2: bounds used two-one-sided test (TOST) equivalence, non-inferiority non-superiority tests. See Details section . p_adjust Adjust p-values multiple comparisons: \"holm\", \"hochberg\", \"hommel\", \"bonferroni\", \"BH\", \"\", \"fdr\". See stats::p.adjust df Degrees freedom used compute p values confidence intervals. single numeric value 1 Inf. df Inf, normal distribution used. df finite, t distribution used. See insight::get_df convenient function extract degrees freedom. Ex: slopes(model, df = insight::get_df(model)) eps NULL numeric value determines step size use calculating numerical derivatives: (f(x+eps)-f(x))/eps. eps NULL, step size 0.0001 multiplied difference maximum minimum values variable respect taking derivative. Changing eps may necessary avoid numerical problems certain models. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/slopes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Slopes (aka Partial derivatives, Marginal Effects, or Trends) — slopes","text":"data.frame one row per observation (per term/group) several columns: rowid: row number newdata data frame type: prediction type, defined type argument group: (optional) value grouped outcome (e.g., categorical outcome models) term: variable whose marginal effect computed dydx: slope outcome respect term, given combination predictor values std.error: standard errors computed via delta method. p.value: p value associated estimate column. null determined hypothesis argument (0 default), p values computed applying transform argument. models class feglm, Gam, glm negbin, p values computed link scale default unless type argument specified explicitly. s.value: Shannon information tranforms p values. many consecutive \"heads\" tosses provide amount evidence (\"suprise\") null hypothesis coin fair? See Greenland (2019) Cole et al. (2020). conf.low: lower bound confidence interval (equal-tailed interval bayesian models) conf.high: upper bound confidence interval (equal-tailed interval bayesian models) See ?print.marginaleffects printing options.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/slopes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Slopes (aka Partial derivatives, Marginal Effects, or Trends) — slopes","text":"\"slope\" \"marginal effect\" partial derivative regression equation respect variable model. function uses automatic differentiation compute slopes vast array models, including non-linear models transformations (e.g., polynomials). Uncertainty estimates computed using delta method. Numerical derivatives slopes function calculated using simple epsilon difference approach: \\(\\partial Y / \\partial X = (f(X + \\varepsilon/2) - f(X-\\varepsilon/2)) / \\varepsilon\\), f predict() method associated model class, \\(\\varepsilon\\) determined eps argument.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/slopes.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Slopes (aka Partial derivatives, Marginal Effects, or Trends) — slopes","text":"avg_slopes(): Average slopes","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/slopes.html","id":"standard-errors-using-the-delta-method","dir":"Reference","previous_headings":"","what":"Standard errors using the delta method","title":"Slopes (aka Partial derivatives, Marginal Effects, or Trends) — slopes","text":"Standard errors quantities estimated marginaleffects can obtained via delta method. requires differentiating function respect coefficients model using finite difference approach. models, delta method standard errors can sensitive various aspects numeric differentiation strategy, including step size. default, step size set 1e-8, 1e-4 times smallest absolute model coefficient, whichever largest. marginaleffects can delegate numeric differentiation numDeriv package, allows flexibility. , users can pass arguments numDeriv::jacobian function global option. example: options(marginaleffects_numDeriv = list(method = \"simple\", method.args = list(eps = 1e-6))) options(marginaleffects_numDeriv = list(method = \"Richardson\", method.args = list(eps = 1e-5))) options(marginaleffects_numDeriv = NULL) See \"Standard Errors Confidence Intervals\" vignette marginaleffects website details computation standard errors: https://vincentarelbundock.github.io/marginaleffects/articles/uncertainty.html Note inferences() function can used compute uncertainty estimates using bootstrap simulation-based inference. See vignette: https://vincentarelbundock.github.io/marginaleffects/articles/bootstrap.html","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/slopes.html","id":"model-specific-arguments","dir":"Reference","previous_headings":"","what":"Model-Specific Arguments","title":"Slopes (aka Partial derivatives, Marginal Effects, or Trends) — slopes","text":"model types allow model-specific arguments modify nature marginal effects, predictions, marginal means, contrasts. Please report package-specific predict() arguments Github can add table . https://github.com/vincentarelbundock/marginaleffects/issues","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/slopes.html","id":"bayesian-posterior-summaries","dir":"Reference","previous_headings":"","what":"Bayesian posterior summaries","title":"Slopes (aka Partial derivatives, Marginal Effects, or Trends) — slopes","text":"default, credible intervals bayesian models built equal-tailed intervals. can changed highest density interval setting global option: options(\"marginaleffects_posterior_interval\" = \"eti\") options(\"marginaleffects_posterior_interval\" = \"hdi\") default, center posterior distribution bayesian models identified median. Users can use different summary function setting global option: options(\"marginaleffects_posterior_center\" = \"mean\") options(\"marginaleffects_posterior_center\" = \"median\") estimates averaged using argument, tidy() function, summary() function, posterior distribution marginalized twice . First, take average across units within iteration MCMC chain, according user requested argument tidy()/summary() functions. , identify center resulting posterior using function supplied \"marginaleffects_posterior_center\" option (median default).","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/slopes.html","id":"equivalence-inferiority-superiority","dir":"Reference","previous_headings":"","what":"Equivalence, Inferiority, Superiority","title":"Slopes (aka Partial derivatives, Marginal Effects, or Trends) — slopes","text":"\\(\\theta\\) estimate, \\(\\sigma_\\theta\\) estimated standard error, \\([, b]\\) bounds interval supplied equivalence argument. Non-inferiority: \\(H_0\\): \\(\\theta \\leq \\) \\(H_1\\): \\(\\theta > \\) \\(t=(\\theta - )/\\sigma_\\theta\\) p: Upper-tail probability Non-superiority: \\(H_0\\): \\(\\theta \\geq b\\) \\(H_1\\): \\(\\theta < b\\) \\(t=(\\theta - b)/\\sigma_\\theta\\) p: Lower-tail probability Equivalence: Two One-Sided Tests (TOST) p: Maximum non-inferiority non-superiority p values. Thanks Russell V. Lenth excellent emmeans package documentation inspired feature.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/slopes.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Slopes (aka Partial derivatives, Marginal Effects, or Trends) — slopes","text":"Greenland S. 2019. \"Valid P-Values Behave Exactly : Misleading Criticisms P-Values Resolution S-Values.\" American Statistician. 73(S1): 106–114. Cole, Stephen R, Jessie K Edwards, Sander Greenland. 2020. \"Surprise!\" American Journal Epidemiology 190 (2): 191–93. https://doi.org/10.1093/aje/kwaa136.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/reference/slopes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Slopes (aka Partial derivatives, Marginal Effects, or Trends) — slopes","text":"","code":"if (FALSE) { # interactive() }  # Unit-level (conditional) Marginal Effects mod <- glm(am ~ hp * wt, data = mtcars, family = binomial) mfx <- slopes(mod) head(mfx) #>  #>  Term Estimate Std. Error     z Pr(>|z|)   S     2.5 %   97.5 % #>    hp 0.006983   0.005848 1.194    0.232 2.1 -0.004478 0.018445 #>    hp 0.016404   0.012338 1.330    0.184 2.4 -0.007778 0.040586 #>    hp 0.002828   0.003764 0.751    0.452 1.1 -0.004549 0.010206 #>    hp 0.001935   0.002441 0.793    0.428 1.2 -0.002848 0.006718 #>    hp 0.002993   0.003203 0.934    0.350 1.5 -0.003285 0.009271 #>    hp 0.000148   0.000322 0.458    0.647 0.6 -0.000484 0.000779 #>  #> Columns: rowid, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, am, hp, wt  #>   # Average Marginal Effect (AME) avg_slopes(mod, by = TRUE) #>  #>  Term Estimate Std. Error     z Pr(>|z|)   S    2.5 %   97.5 % #>    hp  0.00265    0.00209  1.27  0.20539 2.3 -0.00145  0.00676 #>    wt -0.43578    0.14093 -3.09  0.00199 9.0 -0.71200 -0.15957 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  #>    # Marginal Effect at the Mean (MEM) slopes(mod, newdata = datagrid()) #>  #>  Term Estimate Std. Error     z Pr(>|z|)   S    2.5 % 97.5 %  hp   wt #>    hp  0.00853    0.00823  1.04    0.300 1.7 -0.00759 0.0246 147 3.22 #>    wt -1.74453    1.55734 -1.12    0.263 1.9 -4.79685 1.3078 147 3.22 #>  #> Columns: rowid, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, am, hp, wt  #>   # Marginal Effect at User-Specified Values # Variables not explicitly included in `datagrid()` are held at their means slopes(mod, newdata = datagrid(hp = c(100, 110))) #>  #>  Term Estimate Std. Error      z Pr(>|z|)   S    2.5 %  97.5 %   wt  hp #>    hp  0.00117    0.00171  0.684    0.494 1.0 -0.00218 0.00451 3.22 100 #>    hp  0.00190    0.00240  0.789    0.430 1.2 -0.00281 0.00661 3.22 110 #>    wt -0.19468    0.29925 -0.651    0.515 1.0 -0.78119 0.39184 3.22 100 #>    wt -0.33154    0.42925 -0.772    0.440 1.2 -1.17284 0.50977 3.22 110 #>  #> Columns: rowid, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, am, wt, hp  #>   # Group-Average Marginal Effects (G-AME) # Calculate marginal effects for each observation, and then take the average # marginal effect within each subset of observations with different observed # values for the `cyl` variable: mod2 <- lm(mpg ~ hp * cyl, data = mtcars) avg_slopes(mod2, variables = \"hp\", by = \"cyl\") #>  #>  Term    Contrast cyl Estimate Std. Error      z Pr(>|z|)   S   2.5 %  97.5 % #>    hp mean(dY/dX)   6  -0.0523     0.0204 -2.561  0.01044 6.6 -0.0923 -0.0123 #>    hp mean(dY/dX)   4  -0.0917     0.0353 -2.596  0.00942 6.7 -0.1610 -0.0225 #>    hp mean(dY/dX)   8  -0.0128     0.0143 -0.891  0.37280 1.4 -0.0409  0.0153 #>  #> Columns: term, contrast, cyl, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo  #>   # Marginal Effects at User-Specified Values (counterfactual) # Variables not explicitly included in `datagrid()` are held at their # original values, and the whole dataset is duplicated once for each # combination of the values in `datagrid()` mfx <- slopes(mod,               newdata = datagrid(hp = c(100, 110),               grid_type = \"counterfactual\")) head(mfx) #>  #>  rowidcf Term Estimate Std. Error     z Pr(>|z|)   S     2.5 %   97.5 %   wt #>        1   hp 0.012035   0.009939 1.211    0.226 2.1 -0.007446 0.031515 2.62 #>        2   hp 0.014161   0.010526 1.345    0.179 2.5 -0.006470 0.034791 2.88 #>        3   hp 0.001564   0.002196 0.712    0.476 1.1 -0.002739 0.005868 2.32 #>        4   hp 0.001191   0.001733 0.687    0.492 1.0 -0.002206 0.004587 3.21 #>        5   hp 0.000145   0.000321 0.453    0.651 0.6 -0.000484 0.000775 3.44 #>        6   hp 0.000120   0.000274 0.439    0.661 0.6 -0.000416 0.000657 3.46 #>   hp #>  100 #>  100 #>  100 #>  100 #>  100 #>  100 #>  #> Columns: rowid, rowidcf, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, am, wt, hp  #>   # Heteroskedasticity robust standard errors mfx <- slopes(mod, vcov = sandwich::vcovHC(mod)) head(mfx) #>  #>  Term Estimate Std. Error     z Pr(>|z|)   S     2.5 %   97.5 % #>    hp 0.006983   0.009052 0.771    0.440 1.2 -0.010759 0.024725 #>    hp 0.016404   0.012458 1.317    0.188 2.4 -0.008013 0.040821 #>    hp 0.002828   0.004877 0.580    0.562 0.8 -0.006731 0.012388 #>    hp 0.001935   0.002026 0.955    0.340 1.6 -0.002036 0.005906 #>    hp 0.002993   0.002907 1.030    0.303 1.7 -0.002704 0.008690 #>    hp 0.000148   0.000235 0.628    0.530 0.9 -0.000313 0.000609 #>  #> Columns: rowid, term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted, predicted_hi, predicted_lo, am, hp, wt  #>   # hypothesis test: is the `hp` marginal effect at the mean equal to the `drat` marginal effect mod <- lm(mpg ~ wt + drat, data = mtcars)  slopes(     mod,     newdata = \"mean\",     hypothesis = \"wt = drat\") #>  #>     Term Estimate Std. Error     z Pr(>|z|)    S 2.5 % 97.5 % #>  wt=drat    -6.23       1.05 -5.92   <0.001 28.2 -8.29  -4.16 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  #>   # same hypothesis test using row indices slopes(     mod,     newdata = \"mean\",     hypothesis = \"b1 - b2 = 0\") #>  #>     Term Estimate Std. Error     z Pr(>|z|)    S 2.5 % 97.5 % #>  b1-b2=0    -6.23       1.05 -5.92   <0.001 28.2 -8.29  -4.16 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  #>   # same hypothesis test using numeric vector of weights slopes(     mod,     newdata = \"mean\",     hypothesis = c(1, -1)) #>  #>    Term Estimate Std. Error     z Pr(>|z|)    S 2.5 % 97.5 % #>  custom    -6.23       1.05 -5.92   <0.001 28.2 -8.29  -4.16 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  #>   # two custom contrasts using a matrix of weights lc <- matrix(c(     1, -1,     2, 3),     ncol = 2) colnames(lc) <- c(\"Contrast A\", \"Contrast B\") slopes(     mod,     newdata = \"mean\",     hypothesis = lc) #>  #>        Term Estimate Std. Error      z Pr(>|z|)    S  2.5 % 97.5 % #>  Contrast A    -6.23       1.05 -5.919   <0.001 28.2  -8.29  -4.16 #>  Contrast B    -5.24       5.62 -0.931    0.352  1.5 -16.26   5.78 #>  #> Columns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high  #>"},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/news/index.html","id":"marginaleffects-development-version","dir":"Changelog","previous_headings":"","what":"marginaleffects (development version)","title":"marginaleffects (development version)","text":"New: s.value column output: Shannon transforms p values. See Greenland (2019). marginal_means supports mira (mice objects). comparisons(): variables arguments now accepts “revpairwise”, “revsequential”, “revreference” factor character variables. Performance: Computing elasticities linear models now 30% faster (#787, @etiennebacher).","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/news/index.html","id":"marginaleffects-0120","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.12.0","title":"marginaleffects 0.12.0","text":"CRAN release: 2023-05-20 Breaking change: Row order output changed many calls, especially using argument. may break hypothesis tests conducted indexing b1, b2, etc. necessary fix Issue #776. Thanks @marcora report. New: hypotheses(): Joint hypothesis tests (F Chi-square) joint joint_test arguments. vcov.hypotheses method. wts now available plot_predictions(), plot_comparisons(), plot_slopes(). Bug: Wrong order rows bayesian models argument. Thanks @shirdekel report #782.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/news/index.html","id":"marginaleffects-0112","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.11.2","title":"marginaleffects 0.11.2","text":"CRAN release: 2023-05-13 vcov() coef() methods marginaleffects objects. Strings wts accepted argument. predictions() avg_predictions() longer use automatic backtransformation GLM models unless hypothesis NULL. vcov() can used retrieve full variance-covariance matrix objects produced comparisons(), slopes(), predictions(), marginal_means() objects. processing objects obtained using mice multiple imputation, pooled model using mice::pool attached model attribute output. means functions like modelsummary::modelsummary() erroneously report goodness--fit statistics just single model instead appropriately report statistics pooled model. Thanks @Tristan-Siegfried PR #740. informative error messages prediction problems. Thanks @andymilne Report #751. Performance: inferences() now 17x faster much memory-efficient method \"boot\" \"rsample\" (#770, #771, @etiennebacher). Bugs: brms models nl=TRUE single predictor generated error. Thanks @Tristan-Siegried Report #759. avg_predictions(): Incorrect group-wise averaging predictors categorical, variables variable used, averaging avg_ argument. Thanks BorgeJorge report #766. Bug datagrid() called inside user-written function. Thanks @NickCH-K report #769 @capnrefsmmat diagnostics.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/news/index.html","id":"marginaleffects-0111","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.11.1","title":"marginaleffects 0.11.1","text":"CRAN release: 2023-03-31 Breaking change: Row orders now consistent, may changed previous version. affect results hypothesis b1, b2, … indexing. Support new models: nlme::lme() phylolm::phylolm() phylolm::phyloglm() New: Vignette 2x2 experimental designs. Thanks Demetri Pananos. comparisons() accepts data frames two numeric columns (“low” “high”) specify fully customizable contrasts. datagrid() gets new argument create apply grid-making functions within groups. plot_*() gain newdata argument use . Bug: comparisons(comparison = \"lnratioavg\") ignored wts argument. Thanks Demetri Pananos report #737. ordinal::clm(): incorrect standard errors location scale parameters . Thanks MrJerryTAO report #718. Incorrect label “2sd” comparisons. Thanks Andy Milne report #720. Invalid factor levels datagrid() means newdata argument gets ignored. Thanks Josh Errickson report #721. Error models categorical predictors argument. Thanks Sam Brilleman report #723. Elasticities now supported ordinal::clm() models. Thanks MrJerryTAO report #729. glmmTMB models zero-inflated components supported. Thanks @Helsinki-Ronan @strengejacke report #734.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/news/index.html","id":"marginaleffects-0110","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.11.0","title":"marginaleffects 0.11.0","text":"CRAN release: 2023-03-10 Breaking changes: type column replaced type attribute. predictions() works officially supported model types (list comparisons() slopes()). Renamed arguments (backward compatibility preserved): transform_pre -> comparison transform_post -> transform New: p_adjust argument: Adjust p-values multiple comparisons. equivalence argument available everywhere. Performance: Much faster results avg_*() functions models categorical predictors many rows data, using deduplication weights instead unit-level estimates. Faster predictions lm() glm() models using RcppEigen. Bayesian models many rows. Thanks Etienne Bacher. #694 Faster predictions, especially standard errors large datasets. Bugs: Multiple imputation mira objects pooling datasets. Thanks @Generalized report #711. Support models offsets. Thanks @mariofiorini report #705. Error predictions() wts. Thanks Noah Greifer report #695. afex: models generated errors. Thanks Daniel Lüdecke report #696. group column name always forbidden. Thanks Daniel Lüdecke report #697. Blank graphs plot_comparisons() list variables. type=\"link\" produced error categorical brms models. Thanks @shirdekel report #703. Error predictions(variables = ...) glmmTMB models. Thanks Daniel Lüdecke report #707. user-specified function comparison factor predictor aggregate correctly. Thanks @joaotedde report #715. ordinal::clm: Support cum.prob linear.predictor prediction types. Thanks @MrJerryTAO report #717.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/news/index.html","id":"marginaleffects-0100","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.10.0","title":"marginaleffects 0.10.0","text":"CRAN release: 2023-02-22 Performance: 2-4x faster execution many calls. Thanks Etienne Bacher. New models supported: MCMCglmm::MCMCglmm Rchoice::hetprob Rchoice::ivpml Multiple imputation using mice package can return list imputed data frames (e.g., Amelia, missRanger, etc.) Plot improvements: New argument display marginal estimates subgroup. New rug argument display tick marks margins. New points argument plot_predictions() display scatter plot. New gray argument plot grayscale using line types shapes instead color. effect argument renamed variables plot_slopes() plot_comparisons(). improves consistency analogous slopes() comparisons() functions. plotting vignette re-written. : Support multiple imputation mice mira objects. multiple imputation vignette rewritten. variables_grid argument marginal_means() renamed newdata. Backward compatibility maintained. avg_*() returns informative error vcov “satterthwaite” “kenward-roger” “satterthwaite” “kenward-roger” now supported newdata NULL Informative error hypothesis includes b# larger available number estimates. avg_predictions(model, variables = \"x\") computes average counterfactual predictions subgroups x datagrid() plot_*() functions faster datasets many extraneous columns. predictions(type = NULL) glm() Gam() first make predictions link scale backtransform . Setting type=\"response\" explicitly makes predictions directly response scale without backtransformation. Standard errors now supported glmmTMB models. options(marginaleffects_numDeriv = list(method = \"simple\", method.args = list(eps = 1e-6))) options(marginaleffects_numDeriv = list(method = \"Richardson\", method.args = list(eps = 1e-6))) options(marginaleffects_numDeriv = NULL) Print fewer significant digits. print.marginaleffects now prints columns supplied newdata Less redundant labels using hypothesis Many improvements documentation. Bugfixes: Standard errors inaccurate models non-linear components (interactions) coefficients small. related step size used numerical differentiation delta method. Issue #684. avg_predictions(=) work dataset included column named term. Issue #683. brms models multivariate outcome collapsed categories comparisons(). Issue #639. hypotheses() now works lists calls lapply(), purrr::map(), etc. Issue #660.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/news/index.html","id":"marginaleffects-090","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.9.0","title":"marginaleffects 0.9.0","text":"CRAN release: 2023-02-01 Breaking changes: functions return estimate column instead function-specific predicted, comparisons, dydx, etc. change affects unit-level estimates, average estimates, already used estimate column name. transform_avg argument tidy() deprecated. Use transform_post instead. plot_*(draw=FALSE) now return actual variable names supplied condition argument, rather opaque “condition1”, “condition2”, etc. New models supported: blme package. New features: New functions: avg_predictions(), avg_comparisons(), avg_slopes() Equivalence, non-inferiority, non-superiority tests hypotheses() function equivalence argument. New experimental inferences() function: simulation-based inferences bootstrap using boot, rsample, fwb package. New df argument set degrees freedom manually p CI. Pretty print() objects. TRUE returns average (marginal) predictions, comparisons, slopes. Supports bayesian models. Numeric value sets null used calculating Z p. Example: comparisons(mod, transform_pre = \"ratio\", hypothesis = 1) arguments main functions now available tidy(), summary(): conf_level, transform_post, etc. Bayesian posterior distribution summaries (median, mean, HDI, quantiles) can customized using global options. See ?comparisons Renamed functions (backward-compatibility maintained keeping old function names aliases): marginaleffects() -> slopes() posteriordraws() -> posterior_draws() marginalmeans() -> marginal_means() plot_cap() -> plot_predictions() plot_cme() -> plot_slopes() plot_cco() -> plot_comparisons() Bug fixes: Incorrect results: 0.8.1, plot_*() threenum minmax labels correspond correct numeric values. Fix corner case slopes dataset includes infinite values. mlogit error factors. vcov argument now accepts functions models. : Removed major performance bottleneck slopes()","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/news/index.html","id":"marginaleffects-081","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.8.1","title":"marginaleffects 0.8.1","text":"CRAN release: 2022-11-23 deltamethod() can run hypothesis tests objects produced comparisons(), marginaleffects(), predictions(), marginalmeans() functions. feature relies match.call(), means may always work used programmatically, inside functions nested environments. generally safer efficient use hypothesis argument. plot_cme() plot_cco() accept lists user-specified values regressors, can display nice labels shortcut string-functions like “threenum” “quartile”. posterior_draws: new shape argument return MCMC draws various formats, including new rvar structure posterior package. transform_avg function gets printed summary() output. transform_post transform_avg support string shortcuts: “exp” “ln” Added support mlm models lm(). Thanks Noah Greifer. Bug fixes: hypothesis argument bayesian models tidy() used raise error. Missing values regressors comparisons() output brms models.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/news/index.html","id":"marginaleffects-080","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.8.0","title":"marginaleffects 0.8.0","text":"CRAN release: 2022-11-02 Breaking change: interaction argument deprecated replaced cross argument. reduce ambiguity respect interaction argument emmeans, something completely different, akin difference--differences illustrated Interactions vignette. 71 classes models supported, including new: rms::ols rms::lrm rms::orm New features: Plots: plot_cme(), plot_cap(), plot_cco() now much flexible specifying comparisons display. condition argument accepts lists, functions, shortcuts common reference values, “minmax”, “threenum”, etc. Accepts functions specify custom differences numeric variables (e.g., forward backward differencing). Can specify pairs factors compare variables argument comparisons function. Accepts shortcut strings, functions, vectors arbitrary length. Integrate random effects bayesian brms models (see Bayesian analysis vignette) New vignettes: Experiments Extending marginal effects Integrating random effects bayesian models Bug fixes minor improvements: default value conf_level summary() tidy() now NULL, inherits conf_level value original comparisons/marginaleffects/predictions calls. Fix typo function names missing “lnratioavgwts” Interactions fixest::() parsed properly categorical variables betareg objects, inference can now done coefficients using deltamethod(). previously location coefficients available. objects crch package, number bugs fixed; standard errors now correct deltamethod(), marginaleffects(), etc. Fixed bug tidy() function glmmTMB models without random effects, caused t statistics identical.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/news/index.html","id":"marginaleffects-071","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.7.1","title":"marginaleffects 0.7.1","text":"CRAN release: 2022-09-25 New supported model class: gamlss. Thanks Marcio Augusto Diniz. marginalmeans() accepts wts argument values: “equal”, “proportional”, “cells”. accepts data frames complex groupings. marginalmeans accepts data frames. accepts “group” group response level. works bayesian models. byfun argument predictions() function aggregate using different functions. matrix column names used labels hypothesis tests. Better labels “sequential”, “reference”, “pairwise”. new shortcuts “revpairwise”, “revsequential”, “revreference” wts argument respected argument *avg shortcuts transform_pre argument. tidy.predictions() tidy.marginalmeans() get new transform_avg argument. Unit-level contrasts logistic regressions. Thanks @arthur-albuquerque. Python Numpy models marginaleffects. Thanks @timpipeseek. Bootstrap example standard errors vignette.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/news/index.html","id":"marginaleffects-070","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.7.0","title":"marginaleffects 0.7.0","text":"CRAN release: 2022-08-06 Breaking changes: deprecated summary() tidy(). Use argument main functions instead: comparisons(), marginaleffects(), predictions() Character vectors longer supported variables argument predictions() function. Use newdata=\"fivenum\" “grid”, “mean”, “median” instead. Critical bug fix: Contrasts interactions incorrect version 0.6.0. error obvious analysts cases (weird-looking alignment). Thanks @vmikk. New supported packages models: survival::clogit biglm: main quantities can computed, delta method standard errors. See https://github.com/vincentarelbundock/marginaleffects/issues/387 New vignette: Elasticity Frequently Asked Questions New features: Elasticity semi-elasticity using new slope argument marginaleffects(): eyex, dyex, eydx datagrid() accepts functions: datagrid(newdata = mtcars, hp = range, mpg = fivenum, wt = sd) New datagridcf() function create counterfactual datasets. shortcut datagrid() function default grid_type = \"counterfactual\" New arguments predictions(), comparisons(), marginaleffects() New newdata shortcuts: “tukey”, “grid” New string shortcuts transform_pre comparisons() marginalmeans() now back transforms confidence intervals possible. vcov argument string shortcuts now case-insensitive default contrast comparisons() binary predictors now difference 1 0, rather +1 relative baseline. documentation improvements","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/news/index.html","id":"marginaleffects-060","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.6.0","title":"marginaleffects 0.6.0","text":"CRAN release: 2022-06-20 New supported packages models: tidymodels objects class tidy_model supported fit engine supported marginaleffects. New function: deltamethod(): Hypothesis tests functions parameters plot_cco(): Plot conditional contrasts New arguments: hypothesis hypothesis tests custom contrasts transform_post predictions() wts argument predictions() affects average predictions tidy() summary(). New improved vignettes: Hypothesis Tests Custom Contrasts using Delta Method: https://vincentarelbundock.github.io/marginaleffects/articles/hypothesis.html Multiple Imputation: https://vincentarelbundock.github.io/marginaleffects/articles/multiple_imputation.html Causal Inference g-Formula: https://vincentarelbundock.github.io/marginaleffects/articles/gformula.html (Thanks Rohan Kapre idea) Deprecated renamed arguments: contrast_factor contrast_numeric arguments deprecated comparisons(). Use named list variables argument instead. Backward compatibility maintained. transform_post argument tidy() summary() renamed transform_avg disambiguate argument name comparisons(). Backward compatibility preserved. Misc: tidy.predictions() computes standard errors using delta method average predictions Support gam models matrix columns. eps marginaleffects() now “adaptive” default: equals 0.0001 multiplied range predictor variable comparisons() now supports “log marginal odds ratio” transform_pre argument. Thanks Noah Greifer. New transform_pre shortcuts: dydx, expdydx tidy.predictions() computes standard errors confidence intervals linear models GLM link scale.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/news/index.html","id":"marginaleffects-050","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.5.0","title":"marginaleffects 0.5.0","text":"CRAN release: 2022-05-17 Breaking changes: type longer accepts character vector. Must single string. conf.int argument deprecated. Use vcov = FALSE instead. New supported packages models: mlogit mhurdle tobit1 glmmTMB New features: interaction argument comparisons() compute interactions contrasts (cross-contrasts). argument tidy() summary() computes group-average marginal effects comparisons. transform_pre argument can define custom contrasts adjusted predictions (e.g., log adjusted risk ratios). Available comparisons(). transform_post argument allows back transformation returning final results. Available comparisons(), marginalmeans(), summary(), tidy(). variables argument comparisons() function accepts named list specify variable-specific contrast types. sandwich package shortcuts: vcov = \"HC3\", \"HC2\", \"NeweyWest\", . Mixed effects models: vcov = \"satterthwaite\" \"kenward-roger\" One-sided formula clusters: vcov = ~cluster_variable Variance-covariance matrix Function returns named squared matrix marginalmeans() allows interactions Bayesian Model Averaging brms models using type = \"average\". See vignette marginaleffects website. eps argument step size numerical derivative marginaleffects comparisons now report confidence intervals default. New dependency data.table package yields substantial performance improvements. informative error messages warnings Bug fixes performance improvements New pages marginaleffects website: https://vincentarelbundock.github.io/marginaleffects/ Alternative software packages Robust standard errors () Performance tips Tables plots Multinomial Logit Discrete Choice Models Generalized Additive Models Mixed effects models (Bayesian Frequentist) Transformations Custom Contrasts: Adjusted Risk Ratio Example Argument name changes (backward compatibility preserved: conf.level -> conf_level FUN.factor -> FUN_factor (related arguments) grid.type -> grid_type","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/news/index.html","id":"marginaleffects-041","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.4.1","title":"marginaleffects 0.4.1","text":"CRAN release: 2022-03-27 New supported packages models: stats::loess sampleSelection::selection sampleSelection::heckit Misc: mgcv::bam models allow exclude argument. Gam models allow include_smooth argument. New tests Bug fixes","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/news/index.html","id":"marginaleffects-040","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.4.0","title":"marginaleffects 0.4.0","text":"CRAN release: 2022-03-13 New function: comparisons() computes contrasts Misc: Speed optimizations predictions() plot_cap() include confidence intervals linear models robust handling -formula functions: factor(), strata(), mo() overwrite user’s ggplot2::theme_set() call","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/news/index.html","id":"marginaleffects-034","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.3.4","title":"marginaleffects 0.3.4","text":"CRAN release: 2022-03-03 Bug fixes","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/news/index.html","id":"marginaleffects-033","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.3.3","title":"marginaleffects 0.3.3","text":"CRAN release: 2022-01-26 New supported models: mclogit::mclogit robust::lmRob robustlmm::rlmer fixest confidence intervals predictions Misc: Support modelbased::visualisation_matrix newdata without specify x explicitly. tidy.predictions() summary.predictions() methods. Documentation improvements. CRAN test fixes","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/news/index.html","id":"marginaleffects-032","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.3.2","title":"marginaleffects 0.3.2","text":"CRAN release: 2022-01-18 Support new models packages: brglm2::bracl mclogit::mblogit scam::scam lmerTest::lmer Misc: Drop numDeriv dependency, make available via global option: options(“marginaleffects_numDeriv” = list(method = “Richardson”, method.args = list(eps = 1e-5, d = 0.0001))) Bugfixes Documentation improvements CRAN tests","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/news/index.html","id":"marginaleffects-031","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.3.1","title":"marginaleffects 0.3.1","text":"CRAN release: 2022-01-09 documentation bugfix","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/news/index.html","id":"marginaleffects-030","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.3.0","title":"marginaleffects 0.3.0","text":"CRAN release: 2022-01-08 Breaking changes: predictions returns predictions every observation original dataset instead newdata=datagrid(). marginalmeans objects new column names, corresponding tidy summary outputs. New supported packages models: brms::brm rstanarm::stanglm brglm2::brmultinom MASS::glmmPQL aod::betabin Misc: datagrid function supersedes typical counterfactual grid.type argument. typical counterfactual functions remain available exported, use encouraged. posterior_draws function can applied predictions marginaleffects object extract draws posterior distribution. marginalmeans standard errors now computed using delta method. predictions standard errors now computed using delta method available insight::get_predicted. New vignette Bayesian models brms New vignette Mixed effects models lme4 data.table package installed, marginaleffects automatically use speed things . Contrast definition reported separate column marginaleffects output. Safer handling type argument. Comprehensive list supported tests models website. Many bug fixes Many new tests, including several emmeans","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/news/index.html","id":"marginaleffects-020","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.2.0","title":"marginaleffects 0.2.0","text":"CRAN release: 2021-10-18 Breaking change: data argument becomes newdata functions. New supported packages models: lme4:glmer.nb mgcv::gam ordinal::clm mgcv marginalmeans: New variables_grid argument predictions: Support mgcv plot_cap New type argument Misc: New validity checks tests","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/dev/news/index.html","id":"marginaleffects-010","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.1.0","title":"marginaleffects 0.1.0","text":"CRAN release: 2021-09-29 First release. Bravo! Thanks Marco Avina Mendoza, Resul Umit, offered comments suggestions.","code":""}]
